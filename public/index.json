[{"authors":["JC"],"categories":null,"content":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585582766,"objectID":"9b5dd807a92ef9cf578125f1957a7629","permalink":"/authors/kjhealy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kjhealy/","section":"authors","summary":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.","tags":null,"title":"Juan Castillo","type":"authors"},{"authors":null,"categories":null,"content":" Índice  Instrucciones generales para las prácticas Reportes de progreso Notas sobre trabajo con software R Tutorial de instalación de R Tutorial RCloud    Esta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas  Las prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 8:30 a 10:00); ver detalles en la planificación del curso.\n Estas sesiones acompañarán el desarrollo de las guías prácticas disponibles en este sitio.\n Los contenidos de las guías refieren a aplicaciones de análisis de datos de lo visto en clases la semana anterior\n En las prácticas vamos a trabajar con el software R, Versión 4.0. Para su instalación consultar el video-tutorial disponible en la página de la práctica 1 (click aquí)\n Para poder tener una asesoría y monitoreo más cercano en el desarrollo de las guías, los estudiantes han sido divididos en grupos asignados a un/a ayudante (ver en UCursos)\n El trabajo con estas guías se organiza en los siguientes momentos:\n cada estudiante realiza la guía de manera autónoma durante la semana correspondiente, antes de la sesión de práctica en caso de dudas, las realizan en los foros disponibles o se contactan directamente con su ayudante durante las sesiones prácticas, cada ayudante se reunirá con su grupo de estudiantes asignado para revisar la guía paso a paso y resolver dudas cada semana se completa un reporte de progreso (detalles abajo) que va a ser implementado en la plataforma de UCursos    Reportes de progreso Este curso se caracteriza por el desarrollo secuencial y acumulativo de aprendizajes. En otras palabras, va a ser muy difícil poder lograr los objetivos de aprendizaje posteriores sin haber logrado los objetivos de contenidos previos. Y nuevamente en otras palabras: es muy difícil aprender a multiplicar sin saber sumar. Por lo tanto, como equipo a cargo del curso nos interesa poder monitorear permanentemente el cumplimiento de objetivos de aprendizaje semana a semana para así poder prestar asesoría oportuna.\nEl sistema de monitoreo de cumplimiento de objetivos se llevará a cabo mediante reportes de progreso. Un ejemplo de este reporte se ve así:\nLos reportes consisten en completar una encuesta simple y breve, donde se preguntará por el cumplimiento de los objetivos de las prácticas respectivas. La idea es que los puedan completar durante la semana en que se desarrolla la guía, a más tardar los días viernes.\nActualización (22/05)\n1- El primer reporte (Praćtica 1) se generó en la función Test de UCursos, pero lamentablemente la forma en que se entregan los resultados no nos permitió un análisis desagregado por pregunta, que es importante para poder monitorear distintos objetivos. Por eso, desde la práctica 2 hay disponible una encuesta formato web (Forms), a la que se accede directamente la final de la página de cada práctica. 2- Como incentivo para completar los reportes de progreso, se entregarán dos décimas adicionales a cada evaluación para quienes tengan sus reportes completados.\n Notas sobre trabajo con software R Para los análisis estadísticos de este curso usamos el programa R, principalmente porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n trabajar con la misma y última versión de R, que es la 4.0\n evitar uso de tilde, ñ, espacios y mayusculas tanto en carpetas y archivos, así como también en los nombres de las variable\n al momento de hacer consultas sobre problemas en la ejecución del código, adjuntar archivo con:\nCódigo completo hasta que se produce el problema Indicar línea del código donde se produce el problema Adjuntar el resultado del output de la información de la sesión (sessionInfo())   Tutorial de instalación de R  Para quienes no trabajan en R constantemente, abajo un primer tutorial sobre instalación de R y RStudio, necesarios para poder desarrollar esta práctica: Actualizado a versión 4.0      Tutorial RCloud RCloud permite trabajar con RStudio en línea, sin necesidad de instalar localmente. Puede ser muy útil para quienes tengan problemas de instalación, así como también para trabajo colaborativo.\n    ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1594088024,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"Índice  Instrucciones generales para las prácticas Reportes de progreso Notas sobre trabajo con software R Tutorial de instalación de R Tutorial RCloud    Esta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas  Las prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 8:30 a 10:00); ver detalles en la planificación del curso.","tags":null,"title":"Material","type":"docs"},{"authors":null,"categories":null,"content":" If I assign readings, you really should read them.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585568956,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"If I assign readings, you really should read them.","tags":null,"title":"Reading","type":"docs"},{"authors":null,"categories":null,"content":" Aquí se accede a las distintas guías prácticas desde el menú de la izquierda  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585568305,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":" Aquí se accede a las distintas guías prácticas desde el menú de la izquierda  ","tags":null,"title":"Prácticas","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase (próximamente aquí)   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase (próximamente aquí)   ","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596153600,"objectID":"6fce0ded8aa03d77081bcdf32570ef18","permalink":"/class/09-class/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/class/09-class/","section":"class","summary":" Índice  Documento presentación Video de la clase (próximamente aquí)   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase (próximamente aquí)   ","tags":null,"title":"9: Regresión logística (1)","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Librerías Datos Ajustes y descriptivos Modelos de regresión Lógica de presentación de modelos Estimación Interpretación Ajuste global del modelo  Referencias Foro práctica 8    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  En el siguiente documento se presenta un ejemplo de análisis e interpretación de una tabla de regresión múltiple, para que sea considerado como referencia en la entrega de los informes 2 y 3. El ejemplo está adaptado de https://stats.idre.ucla.edu/stata/output/regression-analysis/\nLibrerías pacman::p_load(dplyr,readxl, summarytools, stargazer, equatiomatic)  Datos Los datos a utilizar corresponden a resultados de pruebas de conocimiento en distintas areas de 200 estudiantes de educación secundaria.\ndata \u0026lt;-read_excel(\u0026quot;https://multivariada.netlify.app/assignment/data/hsb2.xls\u0026quot;)  Ajustes y descriptivos Primero seleccionamos las variables que vamos a usar en el ejemplo y cambiamos las etiquetas de las variables a español.\nnames(data) ## [1] \u0026quot;id\u0026quot; \u0026quot;female\u0026quot; \u0026quot;race\u0026quot; \u0026quot;ses\u0026quot; \u0026quot;schtyp\u0026quot; \u0026quot;prog\u0026quot; \u0026quot;read\u0026quot; ## [8] \u0026quot;write\u0026quot; \u0026quot;math\u0026quot; \u0026quot;science\u0026quot; \u0026quot;socst\u0026quot; data \u0026lt;-data %\u0026gt;%select (science,math,female, socst, read) data \u0026lt;-data %\u0026gt;%rename(ciencia=science, matematicas =math, mujer=female, status=socst, lectura=read) print(dfSummary(data, headings = FALSE), method = \u0026quot;render\u0026quot;)   No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing     1 ciencia [numeric] Mean (sd) : 51.9 (9.9) min 34 distinct values  200 (100%) 0 (0%)   2 matematicas [numeric] Mean (sd) : 52.6 (9.4) min 40 distinct values  200 (100%) 0 (0%)   3 mujer [numeric] Min : 0 Mean : 0.5 Max : 1 0:91(45.5%)1:109(54.5%)  200 (100%) 0 (0%)   4 status [numeric] Mean (sd) : 52.4 (10.7) min 22 distinct values  200 (100%) 0 (0%)   5 lectura [numeric] Mean (sd) : 52.2 (10.3) min 30 distinct values  200 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.0)2020-07-15\n  Modelos de regresión Lógica de presentación de modelos La forma en que se presentan los modelos en regresión múltiple depende de las hipótesis que se estan contrastando, y de la definición del/a investigador/a sobre cuáles son los predictores principales y cuáles son las variables de control. Pensemos en este caso que nuestra hipótesis principal es que el puntaje de ciencias se puede predecir con los puntajes de matemáticas y lectura, pero queremos controlar estas asociaciones por sexo y estatus. En este caso, podríamos presentar dos modelos, uno solamente con los predictores principales, y luego un segundo modelo con los controles para ver si los efectos se mantienen. También podríamos pensar en tres modelos: uno con matemáticas, otro con ciencias, y otro con ambos y además controles. La decisión de cómo presentar los modelos depende principalmente de las hipótesis que se están contrastando, y también de que los resultados permitan hacer la mejor discusión posible.\n Estimación Vamos a estimar un primer modelo con las variables asociadas a la hipótesis principal, y luego un segundo con las variables control:\n\\[ \\text{ciencia} = \\alpha + \\beta_{1}(\\text{matematicas}) + \\beta_{2}(\\text{lectura}) + \\epsilon \\]\\[ \\text{ciencia} = \\alpha + \\beta_{1}(\\text{matematicas}) + \\beta_{2}(\\text{lectura}) + \\beta_{3}(\\text{mujer}) + \\beta_{4}(\\text{status}) + \\epsilon \\]\nPara estimar estos modelos en R:\nreg1 \u0026lt;-lm(ciencia ~matematicas +lectura, data=data) reg2 \u0026lt;-lm(ciencia ~matematicas +lectura +mujer +status, data=data) Para presentar los resultados de regresión existen diferentes librerías en R, como stargazer, texreg, sjPlot. En este caso vamos a utilizar la función tab_model de sjPlot:\nsjPlot::tab_model(list(reg1,reg2))   ciencia  ciencia    Predictors  Estimates  CI  p  Estimates  CI  p    (Intercept)  11.62  5.59 – 17.64  \u0026lt;0.001  12.33  6.03 – 18.62  \u0026lt;0.001    matematicas  0.40  0.26 – 0.54  \u0026lt;0.001  0.39  0.24 – 0.54  \u0026lt;0.001    lectura  0.37  0.23 – 0.50  \u0026lt;0.001  0.34  0.19 – 0.48  \u0026lt;0.001    mujer     -2.01  -4.03 – 0.01  0.051    status     0.05  -0.07 – 0.17  0.424    Observations  200  200    R2 / R2 adjusted  0.478 / 0.473  0.489 / 0.479    Esta tabla tiene las opciones por defecto. En general, para cada predictor hay dos piezas de información importante: la estimación del coeficiente de regresión \\(\\beta\\) (estimates), y una estimación referida a inferencia/significación estadística (en este caso CI, intervalo de confianza). Esta segunda información es en general el error estándar, pero también puede ser t (que es el coeficiente dividido por el error estándar), o el intervalo de confianza, dado usualmente por el \\(\\beta\\) +/- 1.96 SE para un 95% de confianza (como aparece en esta tabla). Según el output, la información de inferencia puede aparecer abajo del coeficiente, o al lado como en esta tabla.\nAbajo vamos a hacer algunos ajustes en la tabla, presentando el error estándar en lugar del intervalo, y reemplazando la columna del nivel de probabilidad de error (p) por asteriscos que indican el nivel de significación de cada coeficiente, lo cual hace más rápida la interpretación. También cambiamos algunas etiquetas de la tabla para que sea más fácil de leer:\nsjPlot::tab_model(list(reg1,reg2), show.se=TRUE, show.ci=FALSE, digits=3, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;), string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2    Predictores  β  std. Error  β  std. Error    (Intercept)  11.616 ***  3.054  12.325 ***  3.194    matematicas  0.402 ***  0.073  0.389 ***  0.074    lectura  0.365 ***  0.066  0.335 ***  0.073    mujer    -2.010   1.023    status    0.050   0.062    Observations  200  200    R2 / R2 adjusted  0.478 / 0.473  0.489 / 0.479     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Y para presentar en forma de ecuaciones, quedaría de la siguiente manera:\n\\[ \\text{ciencia} = 11.62 + 0.4(\\text{matematicas}) + 0.37(\\text{lectura}) + \\epsilon \\]\\[ \\text{ciencia} = 12.33 + 0.39(\\text{matematicas}) + 0.34(\\text{lectura}) - 2.01(\\text{mujer}) + 0.05(\\text{status}) + \\epsilon \\]\nPara transformar automáticamente las estimaciones de regresión en R a ecuaciones:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\nInstalar librería equatiomatic. No está en CRAN, así que para instalar:remotes::install_github(\"datalorax/equatiomatic\")\n La función para extraer la ecuación es extract_eq, por ejemplo: extract_eq(reg1)\n Para que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n  ```{r results=\u0026#39;asis\u0026#39;, echo=FALSE} extract_eq(reg1) extract_eq(reg2) ``` Para presentar las ecuaciones con los coeficientes ya estimados, extract_eq(reg1, use_coefs = TRUE)    Interpretación Los coeficientes nos hablan de la relación entre las variables independientes y la variable dependiente. Nos muestran la magnitud del cambio predicho en el puntaje de ciencia por cada 1 unidad en que aumenta el predictor.\nPara matematica el coeficiente es de 0.402 en el modelo 1 y baja a 0.389 en el modelo 2. Entonces, por cada punto adicional en la prueba de matemáticas en el modelo 2 se presenta un incremento de 0.389 en el puntaje de ciencia, manteniendo todas las demás variables constantes. Respecto a la inferencia, existen distintas maneras de dar cuenta de la significación estadística. Por ejemplo, se puede decir que este valor es estadísticamente significativo con un 99,9% de confianza, o con una probabilidad de error p\u0026lt;0.001.\nPara reportar estos resultados de manera más resumida siguiendo las indicaciones de reporte de APA (American Psychological Association): El puntaje en matemáticas predice significativamente el puntaje de ciencias (modelo 1), b = -.40, SE = .07, p \u0026lt; .001, controlando por el puntaje en lectura. Al agregar los controles de sexo y estatus (modelo 2), el puntaje en matemáticas disminuye levemente pero mantiene su nivel de significación, b = -.39, SE = .07, p \u0026lt; .001.\n Con respecto a lectura, en el modelo 2 es posible observar un coeficiente de 0.335. Esto implica que por cada unidad que aumenta el puntaje de lectura se predice un incremento de 0.335 puntos en ciencia, manteniendo todas las demás variables contantes. El coeficiente es estadísticamente significativo con una probabilidad de error p\u0026lt;0.001.\nPara la variable mujer podemos observar que el coeficiente tiene un valor de -2.010 en el modelo 2. Al ser mujer una variable dicotómica donde 1 es mujer y 0 es hombre, la estimación nos indica que para las mujeres el puntaje predicho promedio en ciencias es -2.010 puntos más bajo con respecto al promedio de los hombres, manteniendo todas las demás variables constantes. En términos exclusivamente estadísticos, la variable mujer no es significativamente distinta de 0 cuando empleamos un nivel de confianza del 95%, debido a que el valor \\(p\\) es mayor a 0.05.\nSi observamos el coeficiente de status tenemos un valor de 0.050. Entonces, por cada unidad en que incrementa el estatus se predice un incremento de 0.050 puntos en ciencia, manteniendo todas las demás variables constantes. Sin embargo, no es estadísticamente significativo a un 95% de confianza.\nStd Error: Esta columna corresponde a los errores estándar de los coeficientes de regresión (Estimate). Estos errores estándar son empleados para testear en qué medida los coeficientes son distintos de 0. El procedimiento es dividir el coeficiente por su error estándar para obstener el valor \\(t\\), los que luego se contrastan con la tabla de valores críticos t para obtener la probabilidad de error (que ya aparece automáticamente en la tabla) . Además, los errores estándar pueden ser utilizados para calcular los intervalos de confianza.\nUna manera de presentar los resultados de un modelo de regresión es a través de la visualización de los coeficientes de regresión con sus respectivos intervalos de confianza. La ventaja de este tipo de gráficos es que podemos observar la magnitud del coeficiente y las “barras de error” que representan el intervalo de confianza inferior y superior. Utilizando un intervalo de confianza de 95% de confianza:\nsjPlot::plot_model(reg2,ci.lvl = c(0.95), title = \u0026quot;\u0026quot;,vline.color = \u0026quot;grey\u0026quot;,line.size = 1)  Figure 1: Modelo 2  Lo que nos muestra este gráfico es el valor del coeficiente en el punto, y en las líneas que salen del punto se extienden según su intervalo de confianza. De acuerdo a las reglas de inferencia en regresión, lo que estamos contrastando es que el valor de este coeficiente es distinto de 0 en la población, con un cierto valor de probabilidad. Por lo tanto, si agregamos un intervalo de confianza (valores probables) asociado a una probabilidad de error, entonces podemos decir que este coeficiente es estadísticamente distinto de 0 en la población. Y en el gráfico, esto sucede cuando los intervalos no tocan el 0.\n Ajuste global del modelo R2: El R2 (R-cuadrado) es la proporción de la varianza de la variable dependiente (ciencias) la cual puede ser predicha por las variables independientes (matemáticas, mujer, estatus, lectura). En la Tabla 1 tenemos que para el Modelo (1), este valor nos indica que un 47,7% de la varianza en el puntaje de ciencias se asocia a matemáticas. Luego, en el Modelo (2), el R-cuadrado nos indica que el 48,9% de la varianza de ciencias puede ser predicha conjuntamente por las variables independientes matemáticas, lectura, mujer y status. Como vemos, la incorporación de controles aporta levemente al R2, lo cual se relaciona con que estos predictores no son estadísticamente significativos.\nAdjusted R2: En la medida que se incorporan predictores al modelo, cada uno va contribuyendo a explicar la varianza de la variable dependiente. Así, se podría continuar agregando predictores al modelo, incrementando la capacidad explicativa pero también de cierto modo debido a la variabilidad adicional en una muestra particular con la que estemos trabajando. Por esta razón, el R-cuadrado ajustado busca demostrar un valor estimado más realista del R-cuadrado para la población bajo análisis, penalizando por la inclusión de predictores adicionales. En el caso del Modelo (2) de la Tabla 1, el valor del R-cuadrado es de 0.489, mientras que el R-cuadrado ajustado es de 0.479, el cual es calculado a través de la fórmula \\(1 – ((1 – R^2)((N – 1) /( N – k – 1))\\).\nEntonces, si el número de observaciones (\\(N\\)) es pequeño y el número de predictores (\\(k\\))es grande, tendremos una mayor discrepancia entre el R-cuadrado y el R-cuadrado ajustado. Por otro lado, cuando el número de observaciones es grande en contraste con el número de predictores tendremos que el valor del R-cuadrado y el R-cuadrado ajustado serán mucho más similares debido.\nPor lo tanto, al momento de realizar la intepretación corresponde basarse en los coeficientes del R2 ajustado.\n  Referencias Bruin, J. 2006. newtest: command to compute new test. UCLA: Statistical Consulting Group. https://stats.idre.ucla.edu/stata/ado/analysis/.\n Regression analysis annotated output\n   Foro práctica 8  ","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594831796,"objectID":"e65d602e49caf322a4b3b2cc0350e50c","permalink":"/assignment/08-code/","publishdate":"2020-07-13T00:00:00Z","relpermalink":"/assignment/08-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 8. Tabla de regresión múltiple","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594685672,"objectID":"a696c93d764e2bfb447300660fcf2be7","permalink":"/class/08-class/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/class/08-class/","section":"class","summary":" Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","tags":null,"title":"8: Inferencia en regresión (2)","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    ","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594087749,"objectID":"026700f4d4068083b37f98f89edf4682","permalink":"/class/07-class/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/class/07-class/","section":"class","summary":" Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    ","tags":null,"title":"7: Categóricos / inferencia (1)","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Predictores categóricos Predictores dicotómicos Librerías Datos Explorar base de datos Relacion entre variables Predictores con más de una categoría Interpretación Variables dummy   Inferencia Resumen Práctica 7 Reporte de progreso Foro práctica 7    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Es esta práctica vamos a abordar dos temas:\nPredictores categóricos en regresión\n Inferencia estadística\n  Ambos temas corresponden a dos ámbitos independientes en el estudio de la regresión. Sin embargo, la inclusión de predictores categóricos de dos niveles (o variables dicotómicas) nos permitirá una aproximación a inferencia estadística que es directamente vinculable a los conocimientos sobre diferencia de promedios mediante la prueba t.\nPredictores categóricos Hasta ahora hemos trabajado solamente con predictores a los que asumimos un nivel de medición contínua (es decir, al menos intervalar). ¿Qué sucede con predictores donde se asume un distinto nivel de medición, como nominal u ordinal? En general este tipo de predictores requiere una interpretación y tratamiento distinto que los predictores continuos.\n Predictores dicotómicos Las variables dicotómicas son aquellas variables nominales u ordinales que poseen solo dos categorías de respuesta, por ejemplo hombre/mujer, sano/enfermo, deportista/sedentario. La inclusión de estas variables en un modelo de regresión no requiere un tratamiento especial, solo hay que considerar que su interpretación tiene un sentido distinto. A continuación, veremos un ejemplo respecto a cómo predictores categóricos (de dos o más niveles) permiten modelar el Estatus Social Subjetivo\n Librerías pacman::p_load(dplyr, #manipulacion de datos sjPlot, #tablas summarytools, #estadisticos descriptivos fastDummies, # Crear variable dummy sjlabelled, #etiquetas variables ggplot2, #graficos coefplot # graficos de coeficientes )  Datos Primero, se cargará la base de datos\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\u0026quot;)) # Cargar base de datos Los datos a utilizar corresponden a la base de datos ELSOC 2018 que incluye una muestra de 3784 mujeres y hombres adultos entre 18 y 75 años.\nVariables\n [ess]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\n [edcine]: ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente) - CINE 2011 (UNESCO).\n  [edad]: ¿Cuáles su edad? (años cumplidos).\n  view_df(elsoc_18,encoding = \u0026quot;\u0026quot;)  Data frame: elsoc_18   ID  Name  Label  Values  Value Labels    1  ess  Estatus Social Subjetivo  0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10  0 El nivel mas bajo\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10 El nivel mas alto    2  sexo  Sexo (1=Mujer)  0\n1  Hombre\nMujer    3  edad  Edad  range: 18-90    4  edcine  Educación  1\n2\n3\n4\n5  Primaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado     Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(elsoc_18, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 ess [numeric] Estatus Social Subjetivo Mean (sd) : 4.4 (1.6) min 11 distinct values  3703 (100%) 0 (0%)   2 sexo [numeric] Sexo (1=Mujer) Min : 0 Mean : 0.4 Max : 1 0:2277(61.5%)1:1426(38.5%)  3703 (100%) 0 (0%)   3 edad [numeric] Edad Mean (sd) : 47 (15.5) min 70 distinct values  3703 (100%) 0 (0%)   4 edcine [numeric] Educaci\u0026#0243;n Mean (sd) : 3.2 (1.2) min 1:442(11.9%)2:365(9.9%)3:1589(42.9%)4:592(16.0%)5:715(19.3%)  3703 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.0)2020-07-08\n  Relacion entre variables Visualizar la asociación entre variables puede ser informativo. Sin embargo, en ocasiones es necesario prestar mayor atención al tipo de gráfico que utilizamos para esto. Por ejemplo, veamos un scatter de Estatus social Subjetivo \\(Y_\\text{estatus}\\) con sexo como independiente \\(X_\\text{sexo}\\) para comparar sus distribuciones y sus pendientes\nplot_scatter(data = elsoc_18,x = sexo,y = ess,fit.grps = \u0026quot;lm\u0026quot;) El scatterplot no es muy informativo debido a que nuestra variable independiente solamente posee dos niveles, de modo tal que la distribución de Estatus Social Subjetivo se separa en dos grandes grupos. Por esta razón, una alternativa para visualizar la distirbución es elaborar un gráfico de cajas para ambas categorías:\nplot_grpfrq(var.cnt = elsoc_18$ess,var.grp = elsoc_18$sexo,type = \u0026quot;box\u0026quot;) En este sentido, al tener solamente dos niveles en los valores de la variable X: 0 (Hombre) y 1 (Mujer). Obtenemos solamente dos medias condicionales.\nEntonces, si calculamos el promedio simple para Estatus Social Subjetivo por sexo tenemos:\nelsoc_18 %\u0026gt;% group_by(sexo) %\u0026gt;% summarise(mean_ess=mean(ess,na.rm = T)) ## # A tibble: 2 x 2 ## sexo mean_ess ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 4.34 ## 2 1 4.47 Segun esto el promedio para las mujeres es de 4.47 puntos en la escala de Estatus Social Subjetivo, mientras para los hombres es de 4.34.\nRealizando ahora la regresión:\nreg1\u0026lt;-lm(ess ~sexo, data=elsoc_18) sjPlot::tab_model(list(reg1), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3, dv.labels = c(\u0026quot;Modelo 1\u0026quot;))   Modelo 1    Predictores  β    (Intercept)  4.339 ***    Sexo(1=Mujer)  0.133 *    Observations  3703    R2 / R2 adjusted  0.002 / 0.001     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Entonces:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + \\beta_1 \\times \\text{Sexo} + \\epsilon \\] Tenemos que las mujeres (Sexo = 1) tienen un promedio 0.133 puntos más alto que los hombres (Sexo = 0) en la escala de estatus social subjetivo. En este caso, el grupo de los hombres corresponde a la categoría de referencia.\nPor lo tanto, ¿cuál es la predicción de estatus social subjetivo para la variable sexo?\nPara el caso de los hombres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 0 = 4.339\\] En cambio, para las mujeres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 1 = 4.472\\]\nEntonces cuando calculamos el promedio de Estatus social Subjetivo \\(Y_\\text{estatus}\\) para hombre (\\(X_\\text{sexo=0}\\)) mujer (\\(X_\\text{sexo=1}\\)), podemos observar que son los mismos valores que nos entrega la estimación de la regresión simple empleando Sexo como predictor de Estatus Social Subjetivo. Es decir:\n Al ingresar un regresor dicotómico en regresión simple lo que se obtiene es una estimación de la diferencia de promedios de ambas categorías en relación a la variable dependiente -en regresión múltiple esta diferencia se ajusta o controla por la presencia de otras variables, por ejemplo:  reg2\u0026lt;-lm(ess ~sexo+edad, data=elsoc_18) sjPlot::tab_model(list(reg1,reg2), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;))   Modelo 1  Modelo 2    Predictores  β  β    (Intercept)  4.339 ***  4.602 ***    Sexo(1=Mujer)  0.133 *  0.126 *    Edad   -0.006 ***    Observations  3703  3703    R2 / R2 adjusted  0.002 / 0.001  0.005 / 0.004     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{Y}_\\text{estatus} = 4.602 + 0.126 \\times \\text{Sexo} + -0.006 \\times \\text{Edad} + \\epsilon \\] Al controlar por la Edad de las personas, las mujeres tienen un promedio 0.126 más alto que el de los hombres en la escala de Estatus Social Subjetivo. Vemos que, en comparación con el Modelo 1, la diferencia en el promedio de estatus subjetivo de mujeres respecto de hombres se ajusta al incorporar la Edad. En este sentido, ¿por qué la diferencia en el promedio de estatus subjetivo entre mujeres y hombres puede verse afectada por la Edad?. Revisemos el promedio de Edad para hombres y mujeres:\nelsoc_18 %\u0026gt;% group_by(sexo) %\u0026gt;% summarise(mean_ess=mean(edad,na.rm = T)) ## # A tibble: 2 x 2 ## sexo mean_ess ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 47.5 ## 2 1 46.3 Esta información nos permite observar que los hombres tienen un promedio de edad de 1.2 años mayor que el de las mujeres. En este sentido, lo que vemos es que la diferencia promedio de estatus subjetivo entre hombres y mujeres disminuye de 0.136 a 0.126, es decir, se ajusta al considerar (controlar por) la edad de las personas.\n Predictores con más de una categoría Una de las características de estatus más importante es el nivel educacional de las personas. En este sentido, el nivel educacional puede considerarse como una variable contínua (p.ej: años de educación) o categórica (nivel/grado educacional), lo cual depende no solo de la distribución empírica de la variable sino que también del criterio de quien investiga.\nPara este ejercicio consideraremos la variable educación en base a las categorías de la Clasificación Internacional Normalizada de la Educación (UNESCO). La cual posee 5 niveles:\nsjmisc::frq(x = elsoc_18$edcine,show.na = F) ## ## Educación (x) \u0026lt;numeric\u0026gt; ## # total N=3703 valid N=2988 mean=3.21 sd=1.21 ## ## Value | Label | N | Raw % | Valid % | Cum. % ## -------------------------------------------------------------------- ## 1 | Primaria incompleta menos | 442 | 11.94 | 11.94 | 11.94 ## 2 | Primaria y secundaria baja | 365 | 9.86 | 9.86 | 21.79 ## 3 | Secundaria alta | 1589 | 42.91 | 42.91 | 64.70 ## 4 | Terciaria ciclo corto | 592 | 15.99 | 15.99 | 80.69 ## 5 | Terciaria y Postgrado | 715 | 19.31 | 19.31 | 100.00 Y se distribuye de esta manera:\nplot_frq(data = elsoc_18$edcine) Para poder incluir esta variable en la regresión como categórica en R la manera más simple es definirla como un factor. Primero necesitamos conocer la estructura de la variable, ya que puede venir previamente definida como factor:\nclass(elsoc_18$edcine) ## [1] \u0026quot;numeric\u0026quot; str(elsoc_18$edcine) ## num [1:3703] 2 3 3 4 3 3 3 4 5 2 ... ## - attr(*, \u0026quot;labels\u0026quot;)= Named num [1:5] 1 2 3 4 5 ## ..- attr(*, \u0026quot;names\u0026quot;)= chr [1:5] \u0026quot;Primaria incompleta menos\u0026quot; \u0026quot;Primaria y secundaria baja\u0026quot; \u0026quot;Secundaria alta\u0026quot; \u0026quot;Terciaria ciclo corto\u0026quot; ... ## - attr(*, \u0026quot;label\u0026quot;)= chr \u0026quot;Educación\u0026quot; Vemos que al emplear class, R nos indica que edcine es una variable numérica con 5 valores distintos. Además, al correr str se nos indica que dichos valores numéricos poseen atributos en forma de etiquetas (labels). Entonces, si estimamos la regresión con la variable tal cual como está, obtenemos lo siguiente:\nreg3\u0026lt;-lm(ess~edcine,data = elsoc_18) sjPlot::tab_model(list(reg3), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3, dv.labels = c(\u0026quot;Modelo 3\u0026quot;))   Modelo 3    Predictores  β    (Intercept)  3.329 ***    Educación  0.331 ***    Observations  3703    R2 / R2 adjusted  0.064 / 0.064     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     El coeficiente de regresión nos indica que por cada nivel adicional de educación, hay un aumento de 0.331 puntos en la escala de estatus social subjetivo. Sin embargo, dada la naturaleza de nuestra variable, decir “por cada nivel educacional” es poco informativo, por lo tanto la manera más adecuada de utilizar nuestra variable en la estimación de una regresión es transformarla en un factor empleando la función as_factor() De la librería sjlabelled .\nelsoc_18$edcine\u0026lt;-as_factor(elsoc_18$edcine) Nota: en R existe la función as.factor(), sin embargo, en esa ocasión usamos as_factor() debido a que es compatible los vectores numéricos etiquetados y nos permite matener todos los atributos de las variables, tales como las etiquetas de variable y valores.\n Teniendo nuestra variable transformada a factor, estimamos nuevamente la regresión:\nreg4 \u0026lt;-lm(ess~edcine,data = elsoc_18) sjPlot::tab_model(list(reg3,reg4), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3, dv.labels = c(\u0026quot;Modelo 3\u0026quot;,\u0026quot;Modelo 4\u0026quot;))   Modelo 3  Modelo 4    Predictores  β  β    (Intercept)  3.329 ***  3.794 ***    Educación  0.331 ***     Educación: Primaria y\nsecundaria baja   0.151     Educación: Secundaria\nalta   0.476 ***    Educación: Terciaria\nciclo corto   0.811 ***    Educación: Terciaria y\nPostgrado   1.279 ***    Observations  3703  3703    R2 / R2 adjusted  0.064 / 0.064  0.066 / 0.065     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Interpretación Al igual que en el modelo empleando Educación como variable continua, el modelo con Educación categórica muestra que a medida que aumenta el nivel educacional, el promedio de estatus subjetivo tiende a ser más alto. Por otro lado, en este caso la categoría de referenca es Primaria Incompleta o menos. Entonces:\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Primaria y Secundaria baja es 0.151 puntos más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Secundaria Alta es 0.476 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria ciclo corto es 0.811 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria y Postgrado es de 1.279 más alto con respecto a las personas con educación Primaria Incompleta o menos.\n Alternativamente es posible cambiar la categoría de referencia. Por ejemplo, si quisieramos que la referencia fuera el nivel educativo más alto “Terciaria y Postgrado” (5) debemos usar relevel(edcine, ref =5):  reg4.1 \u0026lt;-lm(ess~relevel(edcine,ref=5),data = elsoc_18) summary(reg4.1) ## ## Call: ## lm(formula = ess ~ relevel(edcine, ref = 5), data = elsoc_18) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.0727 -0.7941 0.0548 0.7300 6.2059 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.07273 0.05710 88.833 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)1 -1.27861 0.09239 -13.839 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)2 -1.12752 0.09823 -11.479 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)3 -0.80275 0.06876 -11.674 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)4 -0.46800 0.08485 -5.516 3.71e-08 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.527 on 3698 degrees of freedom ## Multiple R-squared: 0.06634, Adjusted R-squared: 0.06533 ## F-statistic: 65.69 on 4 and 3698 DF, p-value: \u0026lt; 2.2e-16  Variables dummy La manera tradicional de incluir predictores categóricos de más de dos niveles (variable politómica) es a través de las denominadas variables dummy. Tal como vimos en el ejemplo anterior, se incluyen n-1 categorías en el modelo dado que siempre se mantiene una como categoría de referencia.\nPara explorar nuestra base de datos, usaremos la función head() que nos mostrará las primeras 6 filas de nuestra base de datos para observar la variable Educación.\nhead(elsoc_18) ## ess sexo edad edcine ## 1 9 0 66 2 ## 2 5 0 62 3 ## 3 5 0 28 3 ## 4 5 1 53 4 ## 5 5 1 63 3 ## 6 5 0 56 3 Para la construcción de las variables dummy, usaremos la función dummy_cols() de la librería fastDummies. En el argumento select_columns, le indicamos cuál es la variable que usaremos para construir las variables dummy:\nlibrary(fastDummies) elsoc_18 \u0026lt;-dummy_cols(elsoc_18,select_columns = \u0026quot;edcine\u0026quot;) Revisamos nuestra base de datos:\nhead(elsoc_18) ## ess sexo edad edcine edcine_1 edcine_2 edcine_3 edcine_4 edcine_5 ## 1 9 0 66 2 0 1 0 0 0 ## 2 5 0 62 3 0 0 1 0 0 ## 3 5 0 28 3 0 0 1 0 0 ## 4 5 1 53 4 0 0 0 1 0 ## 5 5 1 63 3 0 0 1 0 0 ## 6 5 0 56 3 0 0 1 0 0 Tal como se estimó en el modelo anterior, ahora lo que haremos es seleccionar cada dummy para las categorías 2, 3, 4 y 5 de la variable edcine. Esto implica que el nivel 1 (Primaria incompleta o menos) será la categoría de referencia.\nreg5 \u0026lt;-lm(ess~edcine_2+edcine_3+edcine_4+edcine_5,data = elsoc_18) sjPlot::tab_model(list(reg4, reg5), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3, dv.labels = c(\u0026quot;Modelo 4\u0026quot;,\u0026quot;Modelo 5\u0026quot;))   Modelo 4  Modelo 5    Predictores  β  β    (Intercept)  3.794 ***  3.794 ***    Educación: Primaria y\nsecundaria baja  0.151      Educación: Secundaria\nalta  0.476 ***     Educación: Terciaria\nciclo corto  0.811 ***     Educación: Terciaria y\nPostgrado  1.279 ***     edcine 2   0.151     edcine 3   0.476 ***    edcine 4   0.811 ***    edcine 5   1.279 ***    Observations  3703  3703    R2 / R2 adjusted  0.066 / 0.065  0.066 / 0.065     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Si observamos la tabla de arriba, vemos que las estimaciones para el modelo 4 y 5 son idénticas. La única diferencia es que en el Modelo 5 empleamos dummies para cada categoría en vez de utilizar la variable como un factor.\n   Inferencia Una de las ideas fundamentales de la inferencia es determinar si nuestros análisis estadísticos pueden ser extrapolados a la población que estamos estudiando. En el contexto de regresión, queremos conocer la significación estadística del coeficiente \\(\\beta\\).\nQueremos saber :\n¿Es significativo el coeficiente del modelo de regresión?.\n Para ello, buscamos determinar la probabilidad de que \\(\\beta \\neq 0\\)\n El concepto fundamental es el Error.\n  Conceptos clave:\nDispersión Curva normal Error estándar  Ejemplo\nSupongamos que nuestra muestra de 3703 casos corresponde a la Población, de modo tal que vamos a extraer una serie de muestras aleatorias de esta “Población” a modo de ilustrar cambios en la dispersión de los datos en la medida que aumenta el tamaño muestral.\n Recordemos que la fórmula del Error Estándar para una muestra es : \\(\\frac{s}{\\sqrt{N}}\\) donde \\(s\\) es la desviación estándar y \\(N\\) es el tamaño de la muestra.\n Bajo el supuesto de que el promedio calculado para la muestra \\(\\bar{x}\\) posee una distribución normal con una \\(s = \\text{Error Estándar (SE)}\\), es posible calcular la probabilidad de error siguiendo dicha distribución. Donde \\(\\bar{x} \\pm 2\\text{ SE}\\) abarca el 95% de la distribución.\n  set.seed(123) elsoc_n30 \u0026lt;-sample_n(tbl = elsoc_18,size = 30 ) %\u0026gt;%mutate(dataset=30 ,mean_ess=mean(ess,na.rm = T)) elsoc_n50 \u0026lt;-sample_n(tbl = elsoc_18,size = 50 ) %\u0026gt;%mutate(dataset=50 ,mean_ess=mean(ess,na.rm = T)) elsoc_n75 \u0026lt;-sample_n(tbl = elsoc_18,size = 75 ) %\u0026gt;%mutate(dataset=75 ,mean_ess=mean(ess,na.rm = T)) elsoc_n100 \u0026lt;-sample_n(tbl = elsoc_18,size = 100) %\u0026gt;%mutate(dataset=100,mean_ess=mean(ess,na.rm = T)) elsoc_n200 \u0026lt;-sample_n(tbl = elsoc_18,size = 200) %\u0026gt;%mutate(dataset=200,mean_ess=mean(ess,na.rm = T)) elsoc_n300 \u0026lt;-sample_n(tbl = elsoc_18,size = 300) %\u0026gt;%mutate(dataset=300 ,mean_ess=mean(ess,na.rm = T)) elsoc_n400 \u0026lt;-sample_n(tbl = elsoc_18,size = 400) %\u0026gt;%mutate(dataset=400,mean_ess=mean(ess,na.rm = T)) elsoc_n700 \u0026lt;-sample_n(tbl = elsoc_18,size = 700) %\u0026gt;%mutate(dataset=700,mean_ess=mean(ess,na.rm = T)) elsoc_n800 \u0026lt;-sample_n(tbl = elsoc_18,size = 800) %\u0026gt;%mutate(dataset=800,mean_ess=mean(ess,na.rm = T)) elsoc_n900 \u0026lt;-sample_n(tbl = elsoc_18,size = 900) %\u0026gt;%mutate(dataset=900,mean_ess=mean(ess,na.rm = T)) elsoc_n1000\u0026lt;-sample_n(tbl = elsoc_18,size = 1000) %\u0026gt;%mutate(dataset=1000,mean_ess=mean(ess,na.rm = T)) elsoc_n1500\u0026lt;-sample_n(tbl = elsoc_18,size = 1500) %\u0026gt;%mutate(dataset=1500,mean_ess=mean(ess,na.rm = T)) elsoc_n2000\u0026lt;-sample_n(tbl = elsoc_18,size = 2000) %\u0026gt;%mutate(dataset=2000,mean_ess=mean(ess,na.rm = T)) elsoc_n2500\u0026lt;-sample_n(tbl = elsoc_18,size = 2500) %\u0026gt;%mutate(dataset=2500,mean_ess=mean(ess,na.rm = T)) # elsoc \u0026lt;- elsoc_18 %\u0026gt;% mutate(dataset=3703,mean_ess=mean(ess,na.rm = T))  fullmat\u0026lt;-bind_rows(elsoc_n30 ,elsoc_n50 ,elsoc_n75 ,elsoc_n100,elsoc_n200,elsoc_n300,elsoc_n400,elsoc_n700,elsoc_n800,elsoc_n900,elsoc_n1000,elsoc_n1500,elsoc_n2000,elsoc_n2500) fullmat \u0026lt;-fullmat %\u0026gt;%mutate(mean_ssta=mean(elsoc_18$ess,na.rm = T)) Luego de obtener las muestras, calculamos la media, desviación estándar y Error estándar:\ntab_full\u0026lt;-fullmat %\u0026gt;%group_by(dataset) %\u0026gt;%summarise(mean=mean(ess,na.rm = T), sd=sd(ess,na.rm = T),SE=sd/sqrt(n())) tab_full ## # A tibble: 14 x 4 ## dataset mean sd SE ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 30 4.07 1.41 0.258 ## 2 50 4.58 1.59 0.225 ## 3 75 4.39 1.60 0.185 ## 4 100 4.4 1.49 0.149 ## 5 200 4.46 1.47 0.104 ## 6 300 4.3 1.55 0.0893 ## 7 400 4.36 1.58 0.0789 ## 8 700 4.35 1.62 0.0611 ## 9 800 4.38 1.54 0.0544 ## 10 900 4.36 1.58 0.0525 ## 11 1000 4.40 1.57 0.0498 ## 12 1500 4.39 1.56 0.0403 ## 13 2000 4.42 1.56 0.0349 ## 14 2500 4.38 1.58 0.0317  Es posible observar que tanto la media como la desviación estándar van cambiando en la medida que aumenta el tamaño de la muestra, pero si observamos el Error Estándar, este va sistemáticamente disminuyendo en la medida que aumenta el tamaño muestral.  Para ilustrar cómo va cambiando la dispersión y la media “muestral” (rojo) con respecto a la “poblacional” (verde), se puede observar el siguiente gráfico:\n Este ejemplo sirve para ilustrar de qué manera el Error Estándar de la media \\(\\bar{x}\\) nos permite determinar la significancia estadística de un coeficiente de regresión \\(\\beta\\).\n En regresión nos interesa saber si las diferencias en Y con respecto a los distintos niveles o valores de X son significativas, es decir estadisticamente distintas de 0.\n  Volviendo nuestro ejemplo inicial: Estatus Social subjetivo según Sexo.\n Estimamos una regresión para cuatro de las muestras de distinto tamaño usando Sexo como predictor de Estatus subjetivo.  reg100 \u0026lt;-lm(ess~sexo,data=elsoc_n100) reg1500\u0026lt;-lm(ess~sexo,data=elsoc_n1500) reg2000\u0026lt;-lm(ess~sexo,data=elsoc_n2000) reg2500\u0026lt;-lm(ess~sexo,data=elsoc_n2500)  Nos interesa saber si el promedio de Mujeres respecto de Hombres es distinto de 0.\n La estimación de la regresión realiza este procedimiento a través del cálculo de la significación estadística. Los modelos entregan el resultado ya calculado en base al Error Estándar del \\(\\beta\\).\n Para determinar esto, se realiza una prueba de hipótesis nula. En regresión la hipótesis nula es:\n  \\[ H_0: \\beta =0\\] En relación a la hipótesis alternativa:\n\\[ H_1: \\beta \\neq 0\\]\n Este contraste se basa en el cálculo de un invervalo de confianza para el coeficiente, asumiendo +/- 2 SE (o al 95% de confianza). Entonces, si este intervalo no pasa por cero, entonces rechazamos \\(H_0\\).\n Entonces, ¿es estadísticamente significativa la diferencia del promedio de Estatus Subjetivo entre hombres y mujeres?. Revisemos para nuestras muestras de distinto tamaño:\n  rbind(broom::tidy(reg100)[2,1:3], # n=100 broom::tidy(reg1500)[2,1:3], # n=1500 broom::tidy(reg2000)[2,1:3], # n=2000 broom::tidy(reg2500)[2,1:3]) # n=2500 ## # A tibble: 4 x 3 ## term estimate std.error ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 sexo 0.0440 0.314 ## 2 sexo 0.0489 0.0829 ## 3 sexo 0.145 0.0715 ## 4 sexo 0.196 0.0649  Al igual que en ejemplo anterior, el error estándar va sistematicamente disminuyendo en la medida que empleamos una muestra más grande. Ahora, ¿son estas diferencias en el promedio entre mujeres respecto de hombres estadísticamente signifciativas al 95% de confianza?. Calculemos los intervalos de confianza:\n Para el caso de la muestra de 100 casos tenemos:\n  #Beta +/- 2*SE = IC 0.0440 -2*0.314 #intervalo confianza inferior 0.0440 +2*0.314 #intervalo confianza superior ## [1] -0.584 ## [1] 0.672  Para el caso de la muestra de 1500 casos tenemos:  0.0489 -2*0.0829 #intervalo confianza inferior 0.0489 +2*0.0829 #intervalo confianza superior ## [1] -0.1169 ## [1] 0.2147  Para el caso de la muestra de 2000 casos tenemos:  0.145 -2*0.0715 #intervalo confianza inferior 0.145 +2*0.0715 #intervalo confianza superior ## [1] 0.002 ## [1] 0.288  Para el caso de la muestra de 2500 casos tenemos:  0.196 -2*0.0649 #intervalo confianza inferior 0.196 +2*0.0649 #intervalo confianza superior ## [1] 0.0662 ## [1] 0.3258  Vemos que para las muestras de 100 y 1500, el intervalo inferior cruza el valor 0, por tanto no rechazamos \\(H_0\\). Lo cual implica que no hay diferencias estadísticamente significativas en el promedio de estatus social subjetivo de mujeres respecto de hombres.\n Por otro lado, en muestras de 2000 y 2500, el intervalo inferior no cruza el valor 0, por tanto rechazamos \\(H_0\\). Lo cual implica que la diferencia en el promedio de estatus social subjetivo de mujeres respecto de hombres es estadísticamente signficativa a un 95% de confianza.\n  Visualmente lo podemos ver en el siguiente gráfico usando la librería coefplot.\n Cada punto representa el coeficiente de Sexo (Mujer=1) para cada modelo. Las líneas horizontales representan los intervalos de confianza.  coefplot::multiplot(reg2500,reg2000,reg1500,reg100, shorten = T, intercept = F, xlab = \u0026quot;\u0026quot;,title = \u0026quot;Modelos según tamaño de muestra\u0026quot;, zeroColor = \u0026quot;black\u0026quot;, linetype = 1) + scale_y_discrete(\u0026quot;\u0026quot;,labels = c(\u0026quot;Sexo (mujer=1)\u0026quot;)) + theme_bw() De manera resumida en una tabla podemos verlo así:\nsjPlot::tab_model(list(reg100,reg1500,reg2000,reg2500), dv.labels = c(\u0026quot;n=100\u0026quot;,\u0026quot;n=1500\u0026quot;,\u0026quot;n=2000\u0026quot;,\u0026quot;n=2500\u0026quot;), show.se = T,digits = 3, string.est = \u0026quot;β\u0026quot;,show.intercept = F, string.ci = \u0026quot;CI 95%\u0026quot;,string.se = \u0026quot;SE\u0026quot;, show.p = F)   n=100  n=1500  n=2000  n=2500    Predictors  β  SE  CI 95%  β  SE  CI 95%  β  SE  CI 95%  β  SE  CI 95%    Sexo(1=Mujer)  0.044  0.314  -0.579 – 0.667  0.049  0.083  -0.114 – 0.212  0.145  0.072  0.004 – 0.285  0.196  0.065  0.069 – 0.323    Observations  100  1500  2000  2500    R2 / R2 adjusted  0.000 / -0.010  0.000 / -0.000  0.002 / 0.002  0.004 / 0.003     Resumen Práctica 7 En esta práctica revisamos los siguientes contenidos:\n Predictores categóricos Variables dummy Inferencia estadística Inferencia en Regresión   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica [https://forms.gle/ACUm93yHPQQpLco4A]\n Foro práctica 7  ","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594262039,"objectID":"48f42589bcb94587b7dfcb568ba66719","permalink":"/assignment/07-code/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/assignment/07-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 7. Inferencia y predictores categóricos","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593230635,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"/class/06-class/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Librerías Datos Explorar base de datos Modelo de regresión simple Relacion entre variables Modelo de regresión multiple Interpretación Intercepto Coeficientes de regresion  Comparando el modelo de regresión simple con múltiple ¿Por qué utilizar R^2 ajustado?  Resumen Práctica 5: Reporte de progreso Foro práctica 5    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica nos enfocaremos en el concepto de regresión múltiple, a partir de la incorporación de dos o más predictores en el modelo. Para ello utilizaremos el ejemplo 3.1 de Wooldridge (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías pacman::p_load(ggpubr, #graficos dplyr, #manipulacion de datos sjPlot, #tablas gridExtra, #unir graficos texreg, #mostrar regresion multiple summarytools, #estadisticos descriptivos wooldridge) #paquete con los ejemplos del libro  Datos Los datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables - [\\(colGPA\\)]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos. - [\\(hsGPA\\)]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos - [\\(ACT\\)]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos Primero, se cargará la base de datos que contiene la librería wooldridge y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos gpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables  Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026#39;render\u0026#39;)) ## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 * ## graph.magnif, : X cannot set locale modifiers ## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 * ## graph.magnif, : X cannot set locale modifiers ## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 * ## graph.magnif, : X cannot set locale modifiers  Modelo de regresión simple Si solo nos centramos en el análisis de regresión simple, intuitivamente partiremos por predecir las calificaciones de la universidad a partir del puntaje obtenido en la prueba de admisión a esta. Formalmente\n\\[\\widehat{colGPA} = b_{0} +b_{1}ACT \\]\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) #Crear regresion simple summary(col_actmodel) ## ## Call: ## lm(formula = colGPA ~ ACT, data = gpa1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.85251 -0.25251 -0.04426 0.26400 0.89336 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.40298 0.26420 9.095 8.8e-16 *** ## ACT 0.02706 0.01086 2.491 0.0139 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.3656 on 139 degrees of freedom ## Multiple R-squared: 0.04275, Adjusted R-squared: 0.03586 ## F-statistic: 6.207 on 1 and 139 DF, p-value: 0.0139 En formato publicable:\nsjPlot::tab_model(col_actmodel, show.ci=FALSE) #Tabla resumen de resultados   col GPA    Predictors  Estimates  p    (Intercept)  2.40  \u0026lt;0.001    ACT  0.03  0.014    Observations  141    R2 / R2 adjusted  0.043 / 0.036    En consecuencia, nuestro modelo que relaciona el promedio de calificaciones en la universidad solo con el puntaje obtenido en el examen de admisión señala que por cada punto adicional que se obtiene en la prueba de admisión, el promedio de la universidad aumenta en 0.027 (aproximado en la tabla de sjPlot a 0.03) puntos promedio.\n\\[\\widehat{colGPA} = 2.40 +0.0271ACT \\]\nAhora bien, si miramos nuestro \\(R^2\\) notaremos que \\(ACT\\) solo explica en un 4.3% la varianza de \\(colGPA\\). Por ello, incluiremos el promedio de las calificaciones de la enseñanza media (\\(hsGPA\\)) para intentar predecir mejor el promedio general de las calificaciones en la universidad.\n Relacion entre variables Se grafican las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus respectivas regresiones simples.\n#Grafico x1 = ACT gact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;, shape = 21, size = 3, # Forma y tamaño de puntos add = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion cor.coef = TRUE)# Agregar coeficiente correlacion #Grafico x2 = hsGPA ghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;, shape = 21, size = 3, add = \u0026quot;reg.line\u0026quot;, cor.coef = TRUE)  grid.arrange(gact, ghsGPA, nrow = 1) # Unir graficos Con el gráfico anterior podemos notar que si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente. Ahora bien, ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?\n Modelo de regresión multiple Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nGrabar / exportar tablas :Exportar tablas  modelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n col_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) col_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1) col_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1) sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3    Predictores  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***    ACT  0.03 *   0.01     hsGPA   0.48 ***  0.45 ***    Observations  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{colGPA} = 1.29 +0.0094 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n Interpretación ¿Cómo se interpreta esta ecuación general de \\(colGPA\\) con dos predictores?\nIntercepto  El intercepto 1.20 indica la predicción del promedio general de calificaciones en la universidad (\\(colGPA\\)) si \\(hsGPA\\) y \\(ACT\\) son ambos cero. Este intercepto no tiene mucho significado debido a que eso implica un individuo ficticio que no haya ni asistido a la universidad ni haya asistido a la enseñanza media, por lo cual no es parte de nuestra pregunta por las determinantes del promedio en la universidad.   Coeficientes de regresion  Fijémonos en los coeficientes de regresión de \\(hsGPA\\). Como era de esperar en función de los gráficos que habíamos presentado, existe una relación positiva entre \\(hsGPA\\) y \\(colGPA\\): con \\(ACT\\) constante, cada punto más en \\(hsGPA\\) se relaciona con un aumento en 0.453 puntos adicionales en \\(colGPA\\), es decir, casi medio punto.  En otras palabras, si se eligen dos estudiantes, A y B, y estos tienen la misma puntación en el exámen de admisión (\\(ACT\\)), pero el promedio en la enseñanza media de A es mayor al de B (\\(hsGPA\\)), entonces se predice que en la universidad el estudiante A tendrá un promedio general de 0.453 puntos más altos que el estudiante B.\n Fijémonos ahora en el coeficiente de regresión de \\(ACT\\): si \\(hsGPA\\) permanece constante, un aumento en un punto de \\(ACT\\) solo produce un aumento en 0.0094 puntos en \\(colGPA\\), es decir, un cambio muy pequeño.  De hecho, un cambio de 10 puntos en el examen de admisión \\(ACT\\) tendrá un efecto sobre \\(colGPA\\) de menos de una décima de punto, es decir, menor al cambio que tiene \\(hsGPA\\). Además, la posibilidad de tener un cambio de 10 puntos en \\(ACT\\) es muy grande pues como mostramos en los estadísticos descriptivos de nuestras variables el promedio de puntaje en \\(colGPA\\) es 24 puntos con una desviación estándar de 2.8, lo que hace poco posible ese cambio en la realidad.\nCon esto podemos decir que el puntaje en el examen de admisión \\(ACT\\) no es un fuerte predictor del promedio de calificaciones en la universidad \\(colGPA\\).\n  Comparando el modelo de regresión simple con múltiple Iniciamos este práctico mostrando un análisis de regresión simple con un predictor para el promedio de calificaciones en la universidad: el promedio en el examen de admisión (\\(ACT\\)).\nObtuvimos que por cada punto de aumento de \\(ACT\\), \\(colGPA\\) aumentaba en 0.0271 puntos sus calificaciones, es decir, casi el triple de lo que fue estimado en el modelo de regresión múltiple (tal como se señala en Modelo 1)\n¿Cuál de los dos modelos es más certero?\nEsto lo podemos definir a partir de la bondad de ajuste de nuestros modelos. Por un lado, el \\(R^2\\) del modelo 1 es de 4.3% mientras que en el modelo 3 el \\(R^2ajustado\\) es de 16%, es decir, las variables que se contienen en el modelo explican más la varianza de nuestra variable dependiente.\n ¿Por qué utilizar R^2 ajustado? Hasta ahora habíamos utilizado \\(R^2\\) que nos señalaba qué porcentaje de la variación de la variable dependiente es explicada por la variable independiente.\nAhora bien, es esperable que a medida que añadimos más variables a una regresión, el \\(R^2\\) tiende a aumentar a pesar de que la contribución de cada una de las variables nuevas no tenga relevancia estadística.\nPor ello, el \\(R^2\\) ajustado se utiliza en la regresión múltiple para analizar en conjunto la intensidad que tienen las variables independientes en explicar la variable dependiente. Es decir, el \\(R^2\\) ajustado nos dice qué porcentaje de variación de la variable dependiente es explicado colectivamente por todas las variables independientes.\nEn consecuencia, \\(R^2\\) ajustado nos permite determinar mejor si añadir una nueva variable al modelo permite explicar una mayor parte de la variación de la variable dependientE.\nEn el ejercicio anterior bien podemos hacer este análisis comparando los \\(R^2\\) de nuestros modelos 1 y 2 para luego mirar el resultado de nuestro \\(R^2\\) ajustado en nuestro modelo 3. Como podremos notar el \\(R^2\\) del modelo 2 es de 17%, mientras que el \\(R^2\\) es de 18% y el \\(R^2\\) ajustado de 16%.\nEn palabras más simples, si solo miramos el \\(R^2\\) llegaremos a la conclusión de que aunque por mínimo que sea, nuestro modelo 3 ajusta mejor que el modelo 2 pues la variable \\(ACT\\) permitiría predecir mejor \\(colGPA\\) en conjunto a \\(hsGPA\\). Sin embargo, \\(R^2 ajustado\\) del modelo 3 (16%) es menor que la del modelo 2 (17%) por lo que la incorporación de \\(ACT\\) al modelo múltiple no tiene un aporte significativo.\nDe hecho, un punto no menor es que \\(ACT\\) pierde significancia estadística en el modelo 3, mientras que \\(hsGPA\\) sigue siendo significativa con un 99% confianza (la significancia estadística lo revisaremos más adelante).\n  Resumen Práctica 5: En esta práctica revisamos los siguientes contenidos\n Repaso de regresión lineal simple Estimación de regresión lineal múltiple Interpretar regresión lineal múltiple Comparar regresión múltiple y simple Diferencia entre \\(R^2\\) ajustado y \\(R^2\\)   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí.\n Foro práctica 5  ","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592791125,"objectID":"e933840b45d355c28b7bb0057d254a85","permalink":"/assignment/05-code/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/assignment/05-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 5. Regresión múltiple 1 ","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Librerías Datos Explorar base de datos Relacion entre variables Modelo de regresión multiple Interpretación ¿Porqué se alteran los coeficientes de regresión?  Parcialización Parcializar \\(ACT\\) de \\(hsGPA\\)  Control estadístico ¿Qué significa mantener todos los demás factores constantes?  Resumen Práctica 6: Reporte de progreso Foro práctica 6    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica nos enfocaremos en el significado de las parcializaciones en la regresión múltiple. Para ello utilizaremos el ejemplo 3.1 de Wooldrige (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías pacman::p_load(ggpubr, #graficos dplyr, #manipulacion de datos sjPlot, #tablas gridExtra, #unir graficos texreg, #mostrar regresion multiple summarytools, #estadisticos descriptivos wooldridge) #paquete con los ejemplos del libro library(wooldridge)  Datos Los datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene variables:\n \\(colGPA\\): promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\n \\(hsGPA\\) : promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\n \\(ACT\\) : puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\n  Primero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos gpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables  Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing     1 colGPA [numeric] Mean (sd) : 3.1 (0.4) min 19 distinct values  141 (100%) 0 (0%)   2 hsGPA [numeric] Mean (sd) : 3.4 (0.3) min 16 distinct values  141 (100%) 0 (0%)   3 ACT [integer] Mean (sd) : 24.2 (2.8) min 15 distinct values  141 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.0)2020-06-30\n  Relacion entre variables Se grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n#Grafico x1 = ACT y= colGPA gact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;, shape = 21, size = 3, # Forma y tamaño de puntos add = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion cor.coef = TRUE)# Agregar coeficiente correlacion #Grafico x2 = hsGPA y= colGPA ghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;, shape = 21, size = 3, add = \u0026quot;reg.line\u0026quot;, cor.coef = TRUE)  #Grafico x2 = hsGPA x1 = ACT gact_hs \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;ACT\u0026quot;, shape = 21, size = 3, add = \u0026quot;reg.line\u0026quot;, cor.coef = TRUE)  grid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos Con el gráfico anterior podemos notar dos puntos relevantes:\n Si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\n Como es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\n  En la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo\n Modelo de regresión multiple Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nRegresión múltiple  modelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n Por fines de comparación, se estimaran primero dos regresiones simples con cada predictor, y luego la regresión múltiple en el Modelo 3:\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) col_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1) col_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1) sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3    Predictores  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***    ACT  0.03 *   0.01     hsGPA   0.48 ***  0.45 ***    Observations  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{colGPA} = 1.29 +0.01 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n Interpretación ¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante Por otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n¿Porqué se alteran los coeficientes de regresión? Como vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).\n  Parcialización La forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en compun \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{2}\\triangle{hsGPA} \\]\nParcializar \\(ACT\\) de \\(hsGPA\\) ¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado po \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\nPaso 1: Estimar modelo model_act_hs =lm(ACT ~hsGPA, data = gpa1) #Crear regresion con predictores coef(model_act_hs) ## (Intercept) hsGPA ## 13.696763 3.074331 En consecuencia tenemos que \\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\n Paso 2: calcular valores predichos y residuos Sabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos res_act_hs=residuals(model_act_hs) #Calcular residuos gpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos head(gpa1) #Mostrar los primeros elementos de la base de datos ## colGPA hsGPA ACT fit_act_hs res_act_hs ## 1 3.0 3.0 21 22.91975 -1.9197550 ## 2 3.4 3.2 24 23.53462 0.4653787 ## 3 3.0 3.6 26 24.76435 1.2356469 ## 4 3.5 3.5 27 24.45692 2.5430797 ## 5 3.6 3.9 28 25.68665 2.3133472 ## 6 3.0 3.4 25 24.14949 0.8505125 Podemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n Paso 3: Crear regresión con variable parcializada Ahora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\nact_hs_model \u0026lt;-lm(colGPA ~res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3  Modelo 4    Predictores  β  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***  3.06 ***    ACT  0.03 *   0.01      hsGPA   0.48 ***  0.45 ***     res_act_hs     0.01     Observations  141  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164  0.005 / -0.003     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Lo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.\n   Control estadístico ¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\nplot_model(col_model, show.values = TRUE)+theme_sjplot() Como podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de qué variable enfatizar: esto dependen de las hipótesis que queremos probar con nuestros modelos.\n ¿Qué significa mantener todos los demás factores constantes? En la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recoltados de manera constante. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\). Más bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.\n  Resumen Práctica 6: En esta práctica revisamos los siguientes contenidos - Repaso de regresión lineal múltiple - Parcialización - Control estadístico\n Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica [https://forms.gle/mMmR8qZxVJ1uYeUw8]\n Foro práctica 6  ","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593527720,"objectID":"c721292a113c2490ec6624b75af80b46","permalink":"/assignment/06-code/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/assignment/06-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 6. Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592524913,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"/class/05-class/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión múltiple 1","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590861193,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"/class/04-class/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":" Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Librerías Datos Residuos Modelo y cálculo de parámetros Bondad de Ajuste: Residuos y \\(R^{2}\\) Suma de cuadrados y \\(R^{2}\\) Visualización El coeficiente de Regresión versus el coeficiente de correlación Reporte de progreso Foro    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Basados en el cálculo de parámetros del modelo de regresión en la práctica anterior (intercepto y coeficiente de regresión o pendiente), en esta práctica nos abocamos a temas de ajuste, residuos y relación entre correlación y regresión. La práctica está basada en el ejemplo de Darlington \u0026amp; Hayes cap. 2 (The simple regression model), que utilizamos en clases.\n Librerías pacman::p_load(stargazer, ggplot2, dplyr,webshot)  Datos Los datos a utilizar son los mismos que los de la práctica 3, corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego: el número de veces que se ha jugado antes (X) y el número de puntos ganados (Y).\ndatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;) datos ## id juegos_x puntos_y ## 1 1 0 2 ## 2 2 0 3 ## 3 3 1 2 ## 4 4 1 3 ## 5 5 1 4 ## 6 6 2 2 ## 7 7 2 3 ## 8 8 2 4 ## 9 9 2 5 ## 10 10 3 2 ## 11 11 3 3 ## 12 12 3 4 ## 13 13 3 5 ## 14 14 3 6 ## 15 15 4 3 ## 16 16 4 4 ## 17 17 4 5 ## 18 18 4 6 ## 19 19 5 4 ## 20 20 5 5 ## 21 21 5 6 ## 22 22 6 5 ## 23 23 6 6 También desde esta misma dirección web se pueden bajar los datos y llamarlos localmente\nDirectorio de trabajo :Directorio de trabajo \nPara el trabajo de análisis de datos se recomienda establecer claramente el directorio de trabajo, es decir, la carpeta que contiene los archivos de datos, los códigos y los resultados. Esta carpeta es el lugar donde uno se posiciona para hacer los análisis, llamar otros archivos y exportar archivos.\nPara esto, varias opciones:\n en RStudio, Session \u0026gt; Set Working Directory \u0026gt; Choose Directory o también vía consola con el comando setwd(ruta-hacia-la-carpeta-local)  Si se quiere verificar en qué carpeta se está trabajando, comando getwd()\nCon esto entonces, si los datos están guardados en la misma carpeta, entonces se llaman simplemente datos \u0026lt;- read.csv(\"tacataca.txt\", sep=\"\"). No se requiere dar la ruta completa justamente porque el programa ya sabe dónde uno está posicionado. Asimísmo, al momento de guardar/exportar algún resultado, automáticamente quedará en la carpeta de trabajo.\n Recordando la distribución de los datos y la recta de regresión:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() + geom_smooth(method=lm, se=FALSE) g2 Grabar / exportar gráficos :Exportar gráficos  Si se quiere grabar un gráfico para luego utilizarlo en algún documento fuera del entorno R, algunas alternativas:\n utilizar la función ggsave (para gráficos ggplot)  ggsave(\u0026quot;g2.png\u0026quot;, g2)  más genéricamente, para guardar como imagen cualquier cosa que aparece en el visor de RStudio:  png(file = \u0026quot;g2.png\u0026quot;) # se abre un archivo vacío g2 # se genera el gráfico a guardar en el archivo dev.off() # se cierra el archivo  El gráfico quedará grabado en el directorio de trabajo (ver arriba). Si se desea que se grabe en otra parte, dar la ruta completa hacia la carpeta correspondiente (“C:/[ruta-hacia-carpeta]/g2.png”)\n  Residuos En el gráfico anterior vemos que la línea resume la relación entre X e Y que se denomina recta de regresión, caracterizada por un intercepto y una pendiente.\nClaramente, esta recta es una simplificación que no abarca toda la variabilidad de los datos. Por ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exactamente su puntaje basado en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje.\nLo anterior tiene que ver con el concepto de residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\). Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina suma de residuos al cuadrado o \\(SS_{residual}\\) ya que como hay residuos positivos y negativos unos se cancelan a otros y la suma es 0. De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: residuos cuadrados ordinarios, o OLS (Ordinary Least Squares).\n Modelo y cálculo de parámetros Como vimos la práctica anterior, el modelo de regresión entonces se relaciona con una ecuación de la recta, o recta de regresión, que se puede definir en términos simples de la siguiente manera:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos) reg1 ## ## Call: ## lm(formula = puntos_y ~ juegos_x, data = datos) ## ## Coefficients: ## (Intercept) juegos_x ## 2.5 0.5 Podemos generar una tabla en un formato más publicable:\nstargazer(reg1, type=\u0026quot;text\u0026quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## puntos_y ## ----------------------------------------------- ## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## ----------------------------------------------- ## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## =============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 También es posible generar una tabla más resumida en formato publicable y visible en RStudio:\nsjPlot::tab_model(reg1, show.ci=FALSE)   puntos y    Predictors  Estimates  p    (Intercept)  2.50  \u0026lt;0.001    juegos_x  0.50  0.001    Observations  23    R2 / R2 adjusted  0.405 / 0.376    Grabar / exportar tablas :Exportar tablas \nMuchas de las tablas producidas con R son en formato html, es decir, archivos para ser publicados en formato web. Por lo tanto, en general las tablas se graban primero como html, y luego se convierten a formato imagen con la librería webshot.\nPara tablas generadas con stargazer\nstargazer(reg1, type=\u0026quot;html\u0026quot;, out = \u0026quot;reg1.html\u0026quot;) webshot(\u0026quot;reg1.html\u0026quot;,\u0026quot;reg1.png\u0026quot;) Alternativamente, para tablas de regresión con sjPlot:\nsjPlot::tab_model(reg1, show.ci=FALSE, file = \u0026quot;reg1_tab.html\u0026quot;) webshot(\u0026quot;reg1_tab.html\u0026quot;,\u0026quot;reg1_tab.png\u0026quot;)    Bondad de Ajuste: Residuos y \\(R^{2}\\) A partir del método de Mínimos Cuadrados Ordinarios obtenemos una recta que describe un conjunto de datos minimizando las diferencias entre el modelo y la distribución de los datos mismos.\nNo obstante, incluso cuando se ajusta el mejor modelo siempre existirá un grado de imprecisión, representado por las diferencias entre los datos observados y los valores predichos por la recta de regresión.\nLa precisión de nuestro modelo se relaciona con el concepto de Bondad de Ajuste, y se evalúa a partir del estadístico \\(R^2\\).\nEn el siguiente apartado se puede observar la manera de calcular la predicción de Y (puntos_y) en base a X (juegos_x), y almacenarlos en la base de datos, con los respectivos residuos.\n#summary(lm(puntos_y~juegos_x, data=datos)) #beta=0.5 intercepto=2.5  #Variable de valores predichos datos$estimado\u0026lt;-(2.5 +datos$juegos_x*0.5)  # Alternativa por comando #datos$estimado \u0026lt;- predict(reg1)  #Estimamos el residuo datos$residuo \u0026lt;-datos$puntos_y -datos$estimado  # Alternativa por comando #datos$residuo \u0026lt;- residuals(reg1)  datos %\u0026gt;%select(id, estimado, residuo) ## id estimado residuo ## 1 1 2.5 -0.5 ## 2 2 2.5 0.5 ## 3 3 3.0 -1.0 ## 4 4 3.0 0.0 ## 5 5 3.0 1.0 ## 6 6 3.5 -1.5 ## 7 7 3.5 -0.5 ## 8 8 3.5 0.5 ## 9 9 3.5 1.5 ## 10 10 4.0 -2.0 ## 11 11 4.0 -1.0 ## 12 12 4.0 0.0 ## 13 13 4.0 1.0 ## 14 14 4.0 2.0 ## 15 15 4.5 -1.5 ## 16 16 4.5 -0.5 ## 17 17 4.5 0.5 ## 18 18 4.5 1.5 ## 19 19 5.0 -1.0 ## 20 20 5.0 0.0 ## 21 21 5.0 1.0 ## 22 22 5.5 -0.5 ## 23 23 5.5 0.5  Suma de cuadrados y \\(R^{2}\\) Usando la media como modelo podemos calcular las diferencias entre los valores observados y los valores predichos por la media.\n Suma Total de Cuadrados: La suma de las diferencias del promedio de Y al cuadrado (asociado al concepto de varianza de Y)  \\[SS_{tot} = \\sum(y-\\bar{y})^2 \\] Y calculamos\nss_tot\u0026lt;-sum((datos$puntos_y-mean(datos$puntos_y))^2); ss_tot ## [1] 42  Suma de cuadrados de la regresión: se refiere a la suma de diferencias (al cuadrado) entre el valor estimado por el modelo de regresión y la media. Expresa cuanto de la varianza de Y alcanzamos a predecir con X  \\[SS_{reg} = \\sum(\\hat{y}-\\bar{y})^2\\]\nss_reg\u0026lt;-sum((datos$estimado-mean(datos$puntos_y))^2) ; ss_reg ## [1] 17  Suma de residuos al cuadrado: al contrario de el cálculo anterior, los residuos representan la parte de la varianza de Y que no alcanzamos a abarcar con nuestro modelo de regresión. Es decir, reprsentan el error en la predicción (diferencia entre lo estimado por el modelo y el valor observado)  \\[SS_{error} = \\sum(y-\\hat{y})^2\\]\nss_err\u0026lt;-sum((datos$puntos_y -datos$estimado)^2);ss_err ## [1] 25 A partir de las sumas de cuadrados anteriores es posible calcular el estadístico \\(R^{2}\\)\n\\[R^2=\\frac{SS_{reg}}{SS_{tot}}= 1- \\frac{SS_{error}}{SS_{tot}}\\]\n#Opción 1 ss_reg/ss_tot ## [1] 0.4047619 #Opción 2 1-ss_err/ss_tot ## [1] 0.4047619 #por comando summary(lm(puntos_y~juegos_x, data=datos))$r.squared ## [1] 0.4047619  Visualización En la siguiente sección se presentan distintas formas de visualizar los residuos a partir del paquete ggplot2.\n#Visualizacion library(ggplot2)  ggplot(datos, aes(x=juegos_x, y=puntos_y))+ geom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion geom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas geom_point() +#Capa 1 geom_point(aes(y=estimado), shape =1) + theme_bw() En esta segunda opción, se agrega tamaño y color a los residuos mayores:\nggplot(datos, aes(x=juegos_x, y=puntos_y))+ geom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion geom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas geom_point(aes(color = abs(residuo), size = abs(residuo))) + scale_color_continuous(low = \u0026quot;black\u0026quot;, high = \u0026quot;red\u0026quot;) + guides(color = FALSE, size = FALSE) + geom_point(aes(y=estimado), shape =1) + theme_bw()  El coeficiente de Regresión versus el coeficiente de correlación Tanto \\(r_{xy}\\) y \\(\\beta_1\\) son medidas de la relación entre X e Y. Ellas estan relacionadas con la formula de:\n\\[\\beta_1= r_{xy}(S_y/S_x)\\]\nEs decir:\nbeta\u0026lt;-cor(datos$juegos_x,datos$puntos_y)*(sd(datos$puntos_y)/sd(datos$juegos_x));beta ## [1] 0.5 reg1$coefficients[2] #llamamos al coeficiente beta (en posición 2) en el objeto reg1 ## juegos_x ## 0.5 Del mismo modo existe una relación entre \\(r_{xy}\\) y \\(R^2\\)\n#Correlación (Pearson) entre juegos_x y puntos_y (r) cor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 #Correlación entre juegos_x y puntos_y al cuadrado. (cor(datos$juegos_x,datos$puntos_y))^2 ## [1] 0.4047619 La correlación entre X e Y es la misma que entre Y e X,\ncor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 cor(datos$puntos_y,datos$juegos_x) ## [1] 0.636209 … mientras la regresión entre X e Y no es la misma que entre Y e X\nlm(datos$puntos_y~datos$juegos_x)$coefficients ## (Intercept) datos$juegos_x ## 2.5 0.5 lm(datos$juegos_x~datos$puntos_y)$coefficients ## (Intercept) datos$puntos_y ## -0.2380952 0.8095238  Reporte de progreso Completar el reporte de progreso aquí.\n Foro  ","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590853802,"objectID":"0b905da0b361a42246b0f7d03e970a84","permalink":"/assignment/04-code/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/assignment/04-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 4. Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Sobre hoja de código Librerías Datos Verificación y descriptivos Experiencia en juegos y puntuación Medias condicionales Residuos Modelo de regresión y cálculo de parámetros Cálculo de los parámetros del modelo de regresión  Estimación del modelo de regresión simple en R Reporte de progreso Archivo de código Foro práctica 3    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica se desarrollan ejercicios iniciales de regresión simple, que fueron presentados en la clase respectiva. El ejemplo a utilizar es del libro de Darlington \u0026amp; Hayes cap. 2 (The simple regression model).\n Sobre hoja de código Como vimos en la práctica anterior, al momento de analizar los datos separamos el trabajo en dos hojas de código distintas: preparacion.R (práctica 1) y analisis.R (práctica 2). Recordar nombres de archivos y directorios sin tildes, espacios ni ñEn este caso, los datos son simples y como es un ejemplo no realizaremos código de preparación, solo el correspondiente a análisis. Antes de comenzar, sugerimos crear un archivo de código en R con el nombre analisis: R: File-\u0026gt; New File -\u0026gt; RScript, o simplemente Ctrl + Shift + N.\n Librerías pacman::p_load(stargazer, ggplot2, dplyr)  Datos Los datos a utilizar corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego (originalmente de mini-golf en el texto de referencia … pero pensemos en un ejemplo más cercano, de taca-taca). Las dos variables de esta base de datos son el número de veces que se ha jugado antes (juegos_x) y el número de goles o puntos ganados (puntos_y). El archivo de datos es tacataca.txt.\nVamos a cargar estos datos en nuestro espacio de trabajo en R dándole el nombre simple de datos Dos opciones de cargar los datos en R:\n bajarlos al computador local desde este link y luego llamarlos desde el directorio respectivo donde se guardaron:  datos \u0026lt;-read.csv(\u0026quot;( ...ruta hacia el archivo ...)\\tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)  llamarlos directamente desde su ubicación en la web:  datos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;) Como es un archivo de texto simple (txt), los cargamos con la función read.csv, para datos guardados en texto simple separados por coma. Como en el caso de nuestros datos la separación es por espacios en lugar de comas, agregamos esta información con la instrucción sep=\"\" Para abrirlos datos recordemos que en la lógica de R se debe generar un objeto donde se guardan los datos. Este objeto puede tener cualquier nombre, en este caso lo llamaremos simplemente “datos”.\nRutas: ¿Cómo identifico la ruta hacia mi archivo? Dos maneras:\n Botón derecho sobre el archivo -\u0026gt; propiedades, ahí aparece la ruta completa. Copiar y pegar donde corresponde en el archivo de R, no olvidar agregar al final el nombre completo del archivo.  Más fácil: mouse sobre archivo, boton derecho, copiar (o ctrl+c); luego, en el archivo de R, en el lugar que corresponde dar la ruta pegar (o ctrl+v)    Verificación y descriptivos Verificamos si los datos fueron correctamente cargados:\nView(datos) Tenemos entonces tres columnas:}\n id: número único que identifica a cada sujeto\n juegos_x: número de veces que ha jugado previamente\n puntos_y: numero de puntos que obtuvo en el juego actual\n  Generamos una tabla de descriptivos básicos con lo aprendido en la práctica de descripción de datos:\nY para publicar, usando la librería stargazer\nstargazer(datos, type = \u0026quot;text\u0026quot;) ## ## ====================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## ------------------------------------------------------ ## id 23 12.000 6.782 1 6.5 17.5 23 ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## ------------------------------------------------------ En la tabla vemos los estadísticos básicos de las variables juegos y puntos, y además aparece la variable id, que es el identificador y por lo tanto no tiene sentido que salga en la tabla. Para corregir, seleccionamos las variables de interés de datos con el operador pipa %\u0026gt;% operador pipa %\u0026gt;%. Este operador permite unir distintas funciones en una misma línea de código, y es muy utilizado por librerías de manejo de datos como dplyr. Por ejemplo, ahora la instrucción es “de la base de datos datos” %\u0026gt;% “selecciona solo las columnas juegos y puntos”:\nstargazer(datos %\u0026gt;%select(juegos_x,puntos_y) , type = \u0026quot;text\u0026quot;) ## ## ===================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## ----------------------------------------------------- ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## -----------------------------------------------------  Experiencia en juegos y puntuación La pregunta que nos hacemos para este ejercicio de demostración es: ¿tiene relación la experiencia previa (juegos jugados previamente) con el desempeño actual (puntos obtenidos)?\nVeamos un gráfico de nube de puntos / scatter de ambas variables. Para eso, primero cargamos la librería ggplotde R. Recordar que hay que instalarla primero si es que no se ha hecho previamente con install.packages(\"ggplot\")ggplot.\ng=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() g Primero, sobre librerías y visualización: lo que hicimos fue crear un objeto gráfico scatterplot g con la librería ggplot..\nEn términos de correlación se observa una posible asociación positiva, que podemos corroborar con la función cor:\ncor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 Tenemos una correlación positiva (dirección de la relación) y de un tamaño de efecto grande (magnitud de la relación), para ciencias sociales. Es decir, existe una asociación positiva entre ambas variables: a medida que aumenta la experiencia en juegos, aumentan también los puntos obtenidos en el partido de taca taca. Ahora bien, ¿cómo se relaciona más específcamente la experiencia en juegos con los puntos obtenidos posteriormente?\n Medias condicionales Antes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nComo sabemos el promedio de Y (puntos) es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Como lo conocemos, si el sujeto nos dice que ha jugado antes 6 veces, dada la información que conocemos probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() + geom_smooth(method=lm, se=FALSE) g2  Residuos En el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\n De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n   Modelo de regresión y cálculo de parámetros El nombre regresión hace alusión a investigaciones sobre estaturas de padres e hij_s en el S.XIX. La estatura de hij_s de padres muy altos es en promedio menor, y si sus padres son baj_s, es mayor (en comparación con sus padres). Este fenómeno se conoce como “regresión hacia el promedio” \nEl modelo de regresión se representa con una ecuación de la recta, o recta de regresión. Esta recta representa los valores predichos para Y según los distintos valores de X:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nDonde\n \\(\\widehat{Y}\\) es el valor estimado/predicho de \\(Y\\) \\(b_{0}\\) es el intercepto de la recta (el valor de Y cuando X es 0) \\(b_{1}\\) es el coeficiente de regresión, que nos dice cuánto aumenta Y por cada punto que aumenta X (pendiente)   Cálculo de los parámetros del modelo de regresión \\(b_{1}\\), o comunmente llamado “beta de regresión” se obtiene de la siguiente manera:\n\\[b_{1}=\\frac{Cov(XY)}{VarX}\\] En términos más suntantivos se puede entender como qué parte de la covariación que hay entre X e Y se relaciona con (la varianza de) X. Especificando la fórmula:\n\\[b_{1}=\\frac{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {n-1}}{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} {n-1}}\\] Y simplificando\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}\\]\nComo sabemos, la base para todos estos cálculos es el valor de cada variable menos su promedio. Vamos a crear un vector en nuestra base de datos difx=\\(x-\\bar{x}\\) y dify=\\(y-\\bar{y}\\)\ndatos$difx=datos$juegos_x-mean(datos$juegos_x) datos$dify=datos$puntos_y-mean(datos$puntos_y) Y ahora con esto podemos obtener la diferencia de productos cruzados dif_cru=\\((x-\\bar{x})*(y-\\bar{y})\\), así como la diferencia de X de su promedio al cuadrado SSx=\\((x-\\bar{x})^2\\)\ndatos$difcru=datos$difx*datos$dify datos$difx2=datos$difx^2 datos ## id juegos_x puntos_y difx dify difcru difx2 ## 1 1 0 2 -3 -2 6 9 ## 2 2 0 3 -3 -1 3 9 ## 3 3 1 2 -2 -2 4 4 ## 4 4 1 3 -2 -1 2 4 ## 5 5 1 4 -2 0 0 4 ## 6 6 2 2 -1 -2 2 1 ## 7 7 2 3 -1 -1 1 1 ## 8 8 2 4 -1 0 0 1 ## 9 9 2 5 -1 1 -1 1 ## 10 10 3 2 0 -2 0 0 ## 11 11 3 3 0 -1 0 0 ## 12 12 3 4 0 0 0 0 ## 13 13 3 5 0 1 0 0 ## 14 14 3 6 0 2 0 0 ## 15 15 4 3 1 -1 -1 1 ## 16 16 4 4 1 0 0 1 ## 17 17 4 5 1 1 1 1 ## 18 18 4 6 1 2 2 1 ## 19 19 5 4 2 0 0 4 ## 20 20 5 5 2 1 2 4 ## 21 21 5 6 2 2 4 4 ## 22 22 6 5 3 1 3 9 ## 23 23 6 6 3 2 6 9 Y con esto podemos obtener la suma de productos cruzados y la suma de cuadrados de X\nsum(datos$difcru) ## [1] 34 sum(datos$difx2) ## [1] 68 Reemplazando en la fórmula\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}=\\frac{34}{68}=0.5\\]\nY con esto podemos obtener el valor de \\(b_{0}\\)\n\\[b_{0}=\\bar{Y}-b_{1}\\bar{X}\\] \\[b_{0}=4-(3 * 0.5)=2.5\\]\nCompletando la ecuación:\n\\[\\bar{Y}=2.5+0.5X\\]\nEsto nos permite estimar el valor de \\(Y\\) (o su media condicional) basado en el puntaje \\(X\\). Por ejemplo, cuál es el valor estimado de \\(Y\\) dado \\(X=5\\)?\n  Estimación del modelo de regresión simple en R La función para estimar regresión en R es lm (linear model). Su forma general es:\nobjeto=lm(dependiente ~ independiente, data=datos) Donde\n objeto: el nombre (cualquiera) que le damos al objeto donde se guardan los resultados de la estimación dependiente / independiente: los nombres de las variables en los datos data = el nombre del objeto de nuestros datos en R  Ejemplo con los datos de taca taca:\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos) Con esta operación ya estimamos nuestra primera regresión simple. Para ver la estimación de los parámetros principales (intercepto y pendiente) simplemente ejecutamos el nombre del objeto:\nreg1 ## ## Call: ## lm(formula = puntos_y ~ juegos_x, data = datos) ## ## Coefficients: ## (Intercept) juegos_x ## 2.5 0.5 Y obtenemos los valores que calculamos previamente.\nPodemos tener un output en un formato más apropiado utilizando la librería stargazer\nstargazer(reg1, type = \u0026quot;text\u0026quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## puntos_y ## ----------------------------------------------- ## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## ----------------------------------------------- ## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## =============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 Vemos que en la tabla aparecen una serie de elementos adicionales, además de \\(b_{1}\\) (juegos) y el intercepto o constante (“Constant”). Esto será tema de la siguiente sesión.\n Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí\n Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Foro práctica 3  ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"0c86205acf7811fbfe8648206a8418ff","permalink":"/assignment/03-code/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/assignment/03-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 3. Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase Este video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n   Lecturas  Linares (2018) La explicación en sociología   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586906392,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"/class/01-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase Este video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n   Lecturas  Linares (2018) La explicación en sociología   ","tags":null,"title":"Presentación","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase Próximamente aquí  ---    Lecturas  Moore: 1.Comprensión de los datos (1-54)   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589647555,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"/class/02-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase Próximamente aquí  ---    Lecturas  Moore: 1.Comprensión de los datos (1-54)   ","tags":null,"title":"Bases","type":"docs"},{"authors":null,"categories":null,"content":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase    Lecturas  Moore: 2. Análisis de relaciones (97-131)   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590425049,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"/class/03-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":" Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase    Lecturas  Moore: 2. Análisis de relaciones (97-131)   ","tags":null,"title":"Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Presentación Objetivo de la práctica Antecedentes de los datos a utilizar Video - Tutoriales  Preparación de datos ELSOC 2016 1. Librerías principales (de R) a utilizar en el análisis 2. Cargar base de datos 3. Selección de variables a utilizar 4. Procesamiento de variables 4.1 Percepción de meritocracia 4.3. Estatus subjetivo 4.4. Sexo 4.5 Edad  5. Generación de base de datos procesada para el análisis  Archivo de código Foro    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Presentación Objetivo de la práctica El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nEn este curso vamos a distinguir dos momentos del trabajo con datos: procesamiento y análisis.\n Preparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos procesados.\n Análisis: se relaciona principalmente con análisis descriptivos asociados a las preguntas de investigación y también modelamiento de datos para contrastar hipótesis de investigación.\n  Los procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema: Tanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados en un documento de código, en este caso de código RArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: menú File \u0026gt; Save, y darle nombre (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento Librerías: cargar librerías a utilizar Datos: carga de datos Selección de variables a utilizar Procesamiento de variables: en este punto, por cada variable se realiza lo siguiente: Descriptivo Recodificación: (datos perdidos y valores (en caso de ser necesario) Etiquetamiento: de variable y valores (en caso de ser necesario) Otros ajustes  Generación de base de datos procesada para el análisis.  Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de meritocracia y estatus (objetivo y subjetivo) utilizando los datos de la encuesta ELSOC .\n  Antecedentes de los datos a utilizar El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar longitudinalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades. Para ello, junto con variables de meritocracia, consideraremos también variables de estatus (educación y estatus subjetivo), y variables de caracterización sociodemográfica (sexo y edad).\n Video - Tutoriales  Si se requiere instalar R, ir al siguiente tutorial en la página de descripción del uso de R en las prácticas haciendo click aquí.\n También se agrega un segundo tutorial con instrucciones paso a paso para poder comenzar a realizar esta Práctica 1 usando RStudio:\n      Preparación de datos ELSOC 2016 1. Librerías principales (de R) a utilizar en el análisis Como sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\ninstall.packages(\u0026quot;pacman\u0026quot;) Y en adelante, las librerías se cargan así:\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer) Para esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n dplyr: ajuste general de datos sjmisc: descripción y exploración de base de datos car: principalmente la función recode para recodificar/agrupar valores de variable stargazer: para tabla descriptiva   2. Cargar base de datos Ajustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\nrm(list=ls()) # borrar todos los objetos en el espacio de trabajo options(scipen=999) # valores sin notación científica La función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: ELSOC_W01_v3.10.RData.\n#cargamos la base de datos desde internet load(url(\u0026quot;https://multivariada.netlify.com/assignment/data/original/ELSOC_W01_v3.10.RData\u0026quot;)) La base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 2927 casos y 383 variables).\ndim(elsoc_2016) # dimension de la base ## [1] 2927 383 Y si se quiere revisar en formato de planilla de datos:\nView(elsoc_2016)  3. Selección de variables a utilizar Este paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto esfuerzo:  find_var(data = elsoc_2016,\u0026quot;esfuerzo\u0026quot;) ## col.nr var.name ## 1 158 c18_09 ## var.label ## 1 Grado de acuerdo: Las personas son recompensadas por sus esfuerzos Nos informa que esta variable es la c18_09.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_elsoc, donde “proc” hace referencia a base procesada:\nproc_elsoc \u0026lt;-elsoc_2016 %\u0026gt;%select(c18_09, # percepción meritocracia esfuerzo c18_10, # percepción meritocracia talento d01_01, # estatus social subjetivo m01, # nivel educacional m0_sexo,# sexo m0_edad)# edad  # Comprobar names(proc_elsoc) ## [1] \u0026quot;c18_09\u0026quot; \u0026quot;c18_10\u0026quot; \u0026quot;d01_01\u0026quot; \u0026quot;m01\u0026quot; \u0026quot;m0_sexo\u0026quot; \u0026quot;m0_edad\u0026quot; Mediante el comando get_label obtenemos el atributo label de las variables.\nsjlabelled::get_label(proc_elsoc) ## c18_09 ## \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; ## c18_10 ## \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; ## d01_01 ## \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; ## m01 ## \u0026quot;Nivel educacional\u0026quot; ## m0_sexo ## \u0026quot;Sexo del entrevistado\u0026quot; ## m0_edad ## \u0026quot;Edad del entrevistado\u0026quot; Podemos ver que son muy largas, por lo tanto, es necesario cambiarlas por etiquetas más cortas.\n 4. Procesamiento de variables Para el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\nDescriptivo general Recodificación: de casos perdidos y otros valores (en caso necesario) Etiquetado: cambio de nombres de variables y valores (en caso necesario) Otros ajustes  Y se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n4.1 Percepción de meritocracia En ELSOC, las variables que permiten medir la percepción de las personas con respecto al funcionamiento de la meritocracia en Chile son las siguientes:\n [c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo) [c18_10]: “Grado de acuerdo: Las personas son recompensadas por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)  a. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\nfrq(proc_elsoc$c18_09) ## ## Grado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=-3.06 sd=71.66 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 4 0.14 0.14 0.14 ## -888 No Sabe (no leer) 14 0.48 0.48 0.61 ## 1 Totalmente en desacuerdo 357 12.20 12.20 12.81 ## 2 En desacuerdo 1331 45.47 45.47 58.28 ## 3 Ni de acuerdo ni en desacuerdo 497 16.98 16.98 75.26 ## 4 De acuerdo 646 22.07 22.07 97.34 ## 5 Totalmente de acuerdo 78 2.66 2.66 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA frq(proc_elsoc$c18_10) ## ## Grado de acuerdo: Las personas son recompensada por su inteligencia (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=-3.42 sd=74.36 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 2 0.07 0.07 0.07 ## -888 No Sabe (no leer) 18 0.61 0.61 0.68 ## 1 Totalmente en desacuerdo 288 9.84 9.84 10.52 ## 2 En desacuerdo 1163 39.73 39.73 50.26 ## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.10 69.35 ## 4 De acuerdo 814 27.81 27.81 97.16 ## 5 Totalmente de acuerdo 83 2.84 2.84 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA En ambas variables vemos valores asociados a la opción “No responde” (-999) y “No sabe” (-888), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en orden, así que en la recodificiación solo nos haremos cargo de los casos perdidos.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\nproc_elsoc$c18_09 \u0026lt;-recode(proc_elsoc$c18_09, \u0026quot;c(-888,-999)=NA\u0026quot;) proc_elsoc$c18_10 \u0026lt;-recode(proc_elsoc$c18_10, \u0026quot;c(-888,-999)=NA\u0026quot;) c - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\nproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;mesfuerzo\u0026quot;=c18_09, # meritocracia esfuerzo \u0026quot;mtalento\u0026quot; =c18_10) # meritocracia talento Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$mesfuerzo) ## [1] \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; proc_elsoc$mesfuerzo \u0026lt;-set_label(x = proc_elsoc$mesfuerzo,label = \u0026quot;Recompensa: esfuerzo\u0026quot;)  get_label(proc_elsoc$mtalento) ## [1] \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; proc_elsoc$mtalento \u0026lt;-set_label(x = proc_elsoc$mtalento, label = \u0026quot;Recompensa: talento\u0026quot;) d. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los dos items de meritocracia.\nproc_elsoc$pmerit \u0026lt;-(proc_elsoc$mesfuerzo+proc_elsoc$mtalento)/2 summary(proc_elsoc$pmerit) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 2.000 2.500 2.654 3.500 5.000 29 get_label(proc_elsoc$pmerit) ## [1] \u0026quot;Recompensa: esfuerzo\u0026quot; Vemos que todavía tiene la etiqueta de la variable “Recompensa: esfuerzo”\nproc_elsoc$pmerit \u0026lt;-set_label(x = proc_elsoc$pmerit, label = \u0026quot;Meritocracia promedio\u0026quot;) Revisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\nfrq(proc_elsoc$mesfuerzo) ## ## Recompensa: esfuerzo (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2909 mean=2.57 sd=1.05 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1 Totalmente en desacuerdo 357 12.20 12.27 12.27 ## 2 En desacuerdo 1331 45.47 45.75 58.03 ## 3 Ni de acuerdo ni en desacuerdo 497 16.98 17.08 75.11 ## 4 De acuerdo 646 22.07 22.21 97.32 ## 5 Totalmente de acuerdo 78 2.66 2.68 100.00 ## NA \u0026lt;NA\u0026gt; 18 0.61 NA NA frq(proc_elsoc$mtalento) ## ## Recompensa: talento (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2907 mean=2.74 sd=1.06 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1 Totalmente en desacuerdo 288 9.84 9.91 9.91 ## 2 En desacuerdo 1163 39.73 40.01 49.91 ## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.23 69.14 ## 4 De acuerdo 814 27.81 28.00 97.14 ## 5 Totalmente de acuerdo 83 2.84 2.86 100.00 ## NA \u0026lt;NA\u0026gt; 20 0.68 NA NA frq(proc_elsoc$pmerit) ## ## Meritocracia promedio (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2898 mean=2.65 sd=0.97 ## ## val label frq raw.prc valid.prc cum.prc ## -999.0 No Responde (no leer) 0 0.00 0.00 0.00 ## -888.0 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1.0 Totalmente en desacuerdo 243 8.30 8.39 8.39 ## 1.5 1.5 79 2.70 2.73 11.11 ## 2.0 En desacuerdo 1041 35.57 35.92 47.03 ## 2.5 2.5 222 7.58 7.66 54.69 ## 3.0 Ni de acuerdo ni en desacuerdo 536 18.31 18.50 73.19 ## 3.5 3.5 169 5.77 5.83 79.02 ## 4.0 De acuerdo 528 18.04 18.22 97.24 ## 4.5 4.5 38 1.30 1.31 98.55 ## 5.0 Totalmente de acuerdo 42 1.43 1.45 100.00 ## NA \u0026lt;NA\u0026gt; 29 0.99 NA NA 4.2. Educación  [m01] = ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente).  a. Descriptivo\nfrq(proc_elsoc$m01) ## ## Nivel educacional (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=4.57 sd=26.34 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 2 0.07 0.07 0.07 ## -888 No Sabe (no leer) 0 0.00 0.00 0.07 ## 1 Sin estudios 37 1.26 1.26 1.33 ## 2 Educacion Basica o Preparatoria incompleta 322 11.00 11.00 12.33 ## 3 Educacion Basica o Preparatoria completa 297 10.15 10.15 22.48 ## 4 Educacion Media o Humanidades incompleta 394 13.46 13.46 35.94 ## 5 Educacion Media o Humanidades completa 857 29.28 29.28 65.22 ## 6 Tecnica Superior incompleta 102 3.48 3.48 68.71 ## 7 Tecnica Superior completa 381 13.02 13.02 81.72 ## 8 Universitaria incompleta 186 6.35 6.35 88.08 ## 9 Universitaria completa 303 10.35 10.35 98.43 ## 10 Estudios de posgrado (magister o doctorado) 46 1.57 1.57 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación\n Datos perdidos:  proc_elsoc$m01 \u0026lt;-recode(proc_elsoc$m01, \u0026quot;c(-888,-999)=NA\u0026quot;)  Valores  Recodificación de acuerdo a las categorías CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1 2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1 3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2 4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3 5. Educacion Media o Humanidades completa = [CINE 3 ] = 3 6. Tecnico Superior incompleta = [CINE 5 ] = 4 7. Tecnico Superior completa = [CINE 5 ] = 4 8. Universitaria incompleta = [CINE 6 ] = 5 9. Universitaria completa = [CINE 6 ] = 6 10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6 # recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car proc_elsoc$m01 \u0026lt;-car::recode(proc_elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) Comprobar con un nuevo descriptivo:\nfrq(proc_elsoc$m01) ## ## Nivel educacional (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2925 mean=3.18 sd=1.21 ## ## val label frq raw.prc valid.prc ## -999 No Responde (no leer) 0 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 ## 1 Sin estudios 359 12.27 12.27 ## 2 Educacion Basica o Preparatoria incompleta 297 10.15 10.15 ## 3 Educacion Basica o Preparatoria completa 1251 42.74 42.77 ## 4 Educacion Media o Humanidades incompleta 483 16.50 16.51 ## 5 Educacion Media o Humanidades completa 535 18.28 18.29 ## 6 Tecnica Superior incompleta 0 0.00 0.00 ## 7 Tecnica Superior completa 0 0.00 0.00 ## 8 Universitaria incompleta 0 0.00 0.00 ## 9 Universitaria completa 0 0.00 0.00 ## 10 Estudios de posgrado (magister o doctorado) 0 0.00 0.00 ## NA \u0026lt;NA\u0026gt; 2 0.07 NA ## cum.prc ## 0.00 ## 0.00 ## 12.27 ## 22.43 ## 65.20 ## 81.71 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## NA Se observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 5), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\nproc_elsoc$m01 \u0026lt;-set_labels(proc_elsoc$m01, labels=c( \u0026quot;Primaria incompleta menos\u0026quot;=1, \u0026quot;Primaria y secundaria baja\u0026quot;=2, \u0026quot;Secundaria alta\u0026quot;=3, \u0026quot;Terciaria ciclo corto\u0026quot;=4, \u0026quot;Terciaria y Postgrado\u0026quot;=5)) Luego renombramos la variable con un nombre más sustantivo\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edcine\u0026quot;=m01) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edcine) ## [1] \u0026quot;Nivel educacional\u0026quot; proc_elsoc$edcine \u0026lt;-set_label(x = proc_elsoc$edcine,label = \u0026quot;Educación\u0026quot;)   4.3. Estatus subjetivo a. Descriptivo\n [d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)  frq(proc_elsoc$d01_01) summary(proc_elsoc$d01_01) ## ## Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=0.63 sd=57.67 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 1 0.03 0.03 0.03 ## -888 No Sabe (no leer) 11 0.38 0.38 0.41 ## 0 0 El nivel mas bajo 44 1.50 1.50 1.91 ## 1 1 84 2.87 2.87 4.78 ## 2 2 207 7.07 7.07 11.86 ## 3 3 439 15.00 15.00 26.85 ## 4 4 677 23.13 23.13 49.98 ## 5 5 975 33.31 33.31 83.29 ## 6 6 310 10.59 10.59 93.88 ## 7 7 116 3.96 3.96 97.85 ## 8 8 37 1.26 1.26 99.11 ## 9 9 4 0.14 0.14 99.25 ## 10 10 El nivel mas alto 22 0.75 0.75 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA ## ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -999.0000 3.0000 5.0000 0.6338 5.0000 10.0000 b. Recodificación\nproc_elsoc$d01_01 \u0026lt;-recode(proc_elsoc$d01_01, \u0026quot;c(-888,-999)=NA\u0026quot;) c. Etiquetado\n Cambio de nombre de variable a etiqueta más sustantiva ess (estatus social subjetivo)  proc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;ess\u0026quot;=d01_01) # estatus social subjetivo Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$ess) ## [1] \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; proc_elsoc$ess \u0026lt;-set_label(x = proc_elsoc$ess,label = \u0026quot;Estatus Social Subjetivo\u0026quot;)  4.4. Sexo  [m0_sexo] = Indicar el sexo del entrevistado.  a. Descriptivo\nfrq(proc_elsoc$m0_sexo) ## ## Sexo del entrevistado (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=1.60 sd=0.49 ## ## val label frq raw.prc valid.prc cum.prc ## 1 Hombre 1163 39.73 39.73 39.73 ## 2 Mujer 1764 60.27 60.27 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\nproc_elsoc$m0_sexo \u0026lt;-car::recode(proc_elsoc$m0_sexo, \u0026quot;1=0;2=1\u0026quot;) c. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\nproc_elsoc$m0_sexo \u0026lt;-set_labels(proc_elsoc$m0_sexo, labels=c( \u0026quot;Hombre\u0026quot;=0, \u0026quot;Mujer\u0026quot;=1)) También el nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;sexo\u0026quot;=m0_sexo) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$sexo) ## [1] \u0026quot;Sexo del entrevistado\u0026quot; proc_elsoc$sexo \u0026lt;-set_label(x = proc_elsoc$sexo,label = \u0026quot;Sexo\u0026quot;) Revisar con un nuevo descriptivo:\nfrq(proc_elsoc$sexo) ## ## Sexo (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=0.60 sd=0.49 ## ## val label frq raw.prc valid.prc cum.prc ## 0 Hombre 1163 39.73 39.73 39.73 ## 1 Mujer 1764 60.27 60.27 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA  4.5 Edad  [m0_edad] = ¿Cuáles su edad? (años cumplidos).  a. Descriptivo\nfrq(proc_elsoc$m0_edad) ## ## Edad del entrevistado (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=46.09 sd=15.29 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 18 18 19 0.65 0.65 0.65 ## 19 19 32 1.09 1.09 1.74 ## 20 20 26 0.89 0.89 2.63 ## 21 21 39 1.33 1.33 3.96 ## 22 22 49 1.67 1.67 5.64 ## 23 23 44 1.50 1.50 7.14 ## 24 24 51 1.74 1.74 8.88 ## 25 25 46 1.57 1.57 10.45 ## 26 26 44 1.50 1.50 11.96 ## 27 27 51 1.74 1.74 13.70 ## 28 28 58 1.98 1.98 15.68 ## 29 29 47 1.61 1.61 17.29 ## 30 30 66 2.25 2.25 19.54 ## 31 31 48 1.64 1.64 21.18 ## 32 32 64 2.19 2.19 23.37 ## 33 33 55 1.88 1.88 25.25 ## 34 34 55 1.88 1.88 27.13 ## 35 35 67 2.29 2.29 29.42 ## 36 36 70 2.39 2.39 31.81 ## 37 37 46 1.57 1.57 33.38 ## 38 38 57 1.95 1.95 35.33 ## 39 39 37 1.26 1.26 36.59 ## 40 40 57 1.95 1.95 38.54 ## 41 41 58 1.98 1.98 40.52 ## 42 42 67 2.29 2.29 42.81 ## 43 43 54 1.84 1.84 44.65 ## 44 44 45 1.54 1.54 46.19 ## 45 45 53 1.81 1.81 48.00 ## 46 46 77 2.63 2.63 50.63 ## 47 47 56 1.91 1.91 52.55 ## 48 48 72 2.46 2.46 55.01 ## 49 49 53 1.81 1.81 56.82 ## 50 50 69 2.36 2.36 59.17 ## 51 51 55 1.88 1.88 61.05 ## 52 52 69 2.36 2.36 63.41 ## 53 53 57 1.95 1.95 65.36 ## 54 54 76 2.60 2.60 67.95 ## 55 55 72 2.46 2.46 70.41 ## 56 56 76 2.60 2.60 73.01 ## 57 57 53 1.81 1.81 74.82 ## 58 58 57 1.95 1.95 76.77 ## 59 59 44 1.50 1.50 78.27 ## 60 60 57 1.95 1.95 80.22 ## 61 61 33 1.13 1.13 81.35 ## 62 62 33 1.13 1.13 82.47 ## 63 63 49 1.67 1.67 84.15 ## 64 64 39 1.33 1.33 85.48 ## 65 65 60 2.05 2.05 87.53 ## 66 66 39 1.33 1.33 88.86 ## 67 67 39 1.33 1.33 90.19 ## 68 68 35 1.20 1.20 91.39 ## 69 69 32 1.09 1.09 92.48 ## 70 70 37 1.26 1.26 93.75 ## 71 71 29 0.99 0.99 94.74 ## 72 72 28 0.96 0.96 95.70 ## 73 73 42 1.43 1.43 97.13 ## 74 74 39 1.33 1.33 98.46 ## 75 75 37 1.26 1.26 99.73 ## 77 77 1 0.03 0.03 99.76 ## 78 78 3 0.10 0.10 99.86 ## 80 80 1 0.03 0.03 99.90 ## 81 81 1 0.03 0.03 99.93 ## 88 88 2 0.07 0.07 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio del nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edad\u0026quot;=m0_edad) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edad) ## [1] \u0026quot;Edad del entrevistado\u0026quot; proc_elsoc$edad \u0026lt;-set_label(x = proc_elsoc$edad,label = \u0026quot;Edad\u0026quot;)   5. Generación de base de datos procesada para el análisis Antes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nstargazer(proc_elsoc, type=\u0026quot;text\u0026quot;) ## ## ============================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## -------------------------------------------------------------- ## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000 ## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------  Guardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como \"C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar  save(proc_elsoc,file = \u0026quot;[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\u0026quot;) En este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\nsave(proc_elsoc,file = \u0026quot;content/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)   Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Foro  ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"9f719bf107561ff88768da3264c94b73","permalink":"/assignment/01-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/01-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 1. Preparación de datos en R","type":"docs"},{"authors":null,"categories":null,"content":"   a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; left: -4em; } pre.numberSource a.sourceLine::before { content: attr(title); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Código de análisis 1. Librerías 2. Cargar base de datos 3. Descripción de variables 3.1 Tabla descriptiva de variables para sección metodológica 3.2 Exploración de asociación entre variables  Nota final: Información de la sesión de R  Resumen Práctica 2: Descripción de variables Reporte de progreso Archivo de código Foro práctica 2    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Esta segunda práctica tiene por objetivo repasar algunos conceptos básicos de los cursos anteriores de Estadística Descriptiva y Estadística Correlacional. Asume como base el desarrollo de la Práctica 1, a la cual se hará referencia permanente.\nEn la Práctica 1 se desarrolló un código de preparación de datos que generó una base de datos procesada para el análisis. En esta Práctica 2 comenzamos con el segundo momento de procesamiento de datos, que es el análisis propiamente tal. El análisis se divide en descripción de variables y contraste de hipótesis. En esta práctica nos enfocaremos en la primera fase, que llega hasta el punto 3 del código de análisis:\nAl igual que el Código de Preparación, el Código de Análisis posee una estructura definida. En este caso son 4 partes, donde las primeras son similares al código de preparación:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento Librerías principales (de R) a utilizar en el análisis Datos (que provienen de los preparados en la fase anterior) Descripción de variables  Tabla general de variables para la sección metodológica del reporte Exploración descriptiva de relaciones entre variables  Contraste de hipótesis / inferencia estadística según la técnica que corresponda  Al final de esta práctica la idea es que cada un_ pueda avanzar hasta el punto 3 del Código de Análisis. El punto 4 (contraste de hipótesis) se desarrollará más adelante en este curso con énfasis en la técnica de regresión.\n Código de análisis 1. Librerías La explicación de esta parte del código se encuentra en la sección correspondiente de la práctica 1.pacman::p_load\npacman::p_load(dplyr, #Manipulacion de datos stargazer, #Tablas sjmisc, # Tablas summarytools, # Tablas kableExtra, #Tablas sjPlot, #Tablas y gráficos corrplot, # Correlaciones sessioninfo) # Información de la sesión de trabajo  2. Cargar base de datos Vamos a cargar la base de datos ELSOC_ess_merit2016.Rproc_elsoc, que generamos durante la práctica 1. Se puede llamar desde el directorio en que la guardaron dando la ruta completa, o también para esta práctica la podemos llamar directamente desde nuestro sitio web:\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)) #Cargar base de datos  Exploración inicial general de la base de datos  names(proc_elsoc) # Muestra los nombres de las variables de la base de datos ## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot; dim(proc_elsoc) # Dimensiones ## [1] 2927 7 En el caso de esta base, 2927 casos y 7 variables\nRecordando el contenido de cada variable preparada en la práctica 1:\n [merit] = Indice promedio de percepción de meritocracia.\n [ess] = Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\" (0 = el nivel mas bajo; 10 = el nivel mas alto)\n [edcine] = Nivel educacional(1 = Primaria incompleta menos, 2 = Primaria y secundaria baja, 3 = Secundaria alta, 4 = Terciaria ciclo corto, 5 = Terciaria y Postgrado)\n [sexo] = Sexo (O = Hombre; 1 = Mujer)\n [edad] = ¿Cuáles su edad? (años cumplidos)\n   3. Descripción de variables Los resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n en la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\n en la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n  3.1 Tabla descriptiva de variables para sección metodológica A continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\nstargazer(proc_elsoc,type = \u0026quot;text\u0026quot;) ## ## ============================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## -------------------------------------------------------------- ## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000 ## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## -------------------------------------------------------------- Algunas observaciones sobre esta tabla:\n La opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\n Una distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.60) es la proporción de mujeres vs hombres. En otras palabras, hay un 60% de mujeres y 40% de hombres en la muestra.\n  b. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\nsjmisc::descr(proc_elsoc) ## ## ## Basic descriptive statistics ## ## var type label n NA.prc mean sd se md ## mesfuerzo numeric Recompensa: esfuerzo 2909 0.61 2.57 1.05 0.02 2.0 ## mtalento numeric Recompensa: talento 2907 0.68 2.74 1.06 0.02 3.0 ## ess numeric Estatus Social Subjetivo 2915 0.41 4.33 1.57 0.03 5.0 ## edcine numeric Educación 2925 0.07 3.18 1.21 0.02 3.0 ## sexo numeric Sexo 2927 0.00 0.60 0.49 0.01 1.0 ## edad numeric Edad 2927 0.00 46.09 15.29 0.28 46.0 ## pmerit numeric Meritocracia promedio 2898 0.99 2.65 0.97 0.02 2.5 ## trimmed range skew ## 2.56 4 (1-5) 0.42 ## 2.76 4 (1-5) 0.18 ## 4.36 10 (0-10) -0.01 ## 3.23 4 (1-5) -0.15 ## 0.63 1 (0-1) -0.42 ## 45.90 70 (18-88) 0.07 ## 2.66 4 (1-5) 0.26 En este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en una práctica posterior):\nsjmisc::descr(proc_elsoc, show = c(\u0026quot;label\u0026quot;,\u0026quot;range\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;n\u0026quot;))%\u0026gt;% kable(.,\u0026quot;markdown\u0026quot;)    var label n NA.prc mean sd range    4 mesfuerzo Recompensa: esfuerzo 2909 0.6149641 2.5727054 1.0466874 4 (1-5)  5 mtalento Recompensa: talento 2907 0.6832935 2.7389061 1.0596182 4 (1-5)  3 ess Estatus Social Subjetivo 2915 0.4099761 4.3300172 1.5666965 10 (0-10)  2 edcine Educación 2925 0.0683293 3.1839316 1.2066058 4 (1-5)  7 sexo Sexo 2927 0.0000000 0.6026648 0.4894300 1 (0-1)  1 edad Edad 2927 0.0000000 46.0908780 15.2867983 70 (18-88)  6 pmerit Meritocracia promedio 2898 0.9907755 2.6538992 0.9694792 4 (1-5)    c. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\ndfSummary(proc_elsoc, plain.ascii = FALSE) ## ### Data Frame Summary ## #### proc_elsoc ## **Dimensions:** 2927 x 7 ## **Duplicates:** 396 ## ## ---------------------------------------------------------------------------------------------------------------------------------------- ## No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing ## ---- ------------ -------------------------- -------------------------- ---------------------- -------------------- ---------- --------- ## 1 mesfuerzo\\ Recompensa: esfuerzo Mean (sd) : 2.6 (1)\\ 1 : 357 (12.3%)\\ II \\ 2909\\ 18\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1331 (45.8%)\\ IIIIIIIII \\ (99.39%) (0.61%) ## 1 \u0026lt; 2 \u0026lt; 5\\ 3 : 497 (17.1%)\\ III \\ ## IQR (CV) : 1 (0.4) 4 : 646 (22.2%)\\ IIII \\ ## 5 : 78 ( 2.7%) ## ## 2 mtalento\\ Recompensa: talento Mean (sd) : 2.7 (1.1)\\ 1 : 288 ( 9.9%)\\ I \\ 2907\\ 20\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1163 (40.0%)\\ IIIIIIII \\ (99.32%) (0.68%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 559 (19.2%)\\ III \\ ## IQR (CV) : 2 (0.4) 4 : 814 (28.0%)\\ IIIII \\ ## 5 : 83 ( 2.9%) ## ## 3 ess\\ Estatus Social Subjetivo Mean (sd) : 4.3 (1.6)\\ 11 distinct values \\ 2915\\ 12\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ \\ \\ \\ \\ \\ \\ :\\ (99.59%) (0.41%) ## 0 \u0026lt; 5 \u0026lt; 10\\ \\ \\ \\ \\ \\ \\ . :\\ ## IQR (CV) : 2 (0.4) \\ \\ \\ \\ . : :\\ ## \\ \\ \\ \\ : : : .\\ ## . : : : : : . ## ## 4 edcine\\ Educación Mean (sd) : 3.2 (1.2)\\ 1 : 359 (12.3%)\\ II \\ 2925\\ 2\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 297 (10.2%)\\ II \\ (99.93%) (0.07%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 1251 (42.8%)\\ IIIIIIII \\ ## IQR (CV) : 1 (0.4) 4 : 483 (16.5%)\\ III \\ ## 5 : 535 (18.3%) III ## ## 5 sexo\\ Sexo Min : 0\\ 0 : 1163 (39.7%)\\ IIIIIII \\ 2927\\ 0\\ ## [numeric] Mean : 0.6\\ 1 : 1764 (60.3%) IIIIIIIIIIII (100%) (0%) ## Max : 1 ## ## 6 edad\\ Edad Mean (sd) : 46.1 (15.3)\\ 63 distinct values \\ 2927\\ 0\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ . . . : :\\ (100%) (0%) ## 18 \u0026lt; 46 \u0026lt; 88\\ . : : : : : .\\ ## IQR (CV) : 25 (0.3) : : : : : : : :\\ ## : : : : : : : :\\ ## : : : : : : : : . ## ## 7 pmerit\\ Meritocracia promedio Mean (sd) : 2.7 (1)\\ 1.00 : 243 ( 8.4%)\\ I \\ 2898\\ 29\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 1.50 : 79 ( 2.7%)\\ \\ (99.01%) (0.99%) ## 1 \u0026lt; 2.5 \u0026lt; 5\\ 2.00 : 1041 (35.9%)\\ IIIIIII \\ ## IQR (CV) : 1.5 (0.4) 2.50 : 222 ( 7.7%)\\ I \\ ## 3.00 : 536 (18.5%)\\ III \\ ## 3.50 : 169 ( 5.8%)\\ I \\ ## 4.00 : 528 (18.2%)\\ III \\ ## 4.50 : 38 ( 1.3%)\\ \\ ## 5.00 : 42 ( 1.5%) ## ---------------------------------------------------------------------------------------------------------------------------------------- Es muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\nview(dfSummary(proc_elsoc, headings=FALSE))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 mesfuerzo [numeric] Recompensa: esfuerzo Mean (sd) : 2.6 (1) min 1:357(12.3%)2:1331(45.8%)3:497(17.1%)4:646(22.2%)5:78(2.7%)  2909 (99.39%) 18 (0.61%)   2 mtalento [numeric] Recompensa: talento Mean (sd) : 2.7 (1.1) min 1:288(9.9%)2:1163(40.0%)3:559(19.2%)4:814(28.0%)5:83(2.9%)  2907 (99.32%) 20 (0.68%)   3 ess [numeric] Estatus Social Subjetivo Mean (sd) : 4.3 (1.6) min 11 distinct values  2915 (99.59%) 12 (0.41%)   4 edcine [numeric] Educaci\u0026#0243;n Mean (sd) : 3.2 (1.2) min 1:359(12.3%)2:297(10.2%)3:1251(42.8%)4:483(16.5%)5:535(18.3%)  2925 (99.93%) 2 (0.07%)   5 sexo [numeric] Sexo Min : 0 Mean : 0.6 Max : 1 0:1163(39.7%)1:1764(60.3%)  2927 (100%) 0 (0%)   6 edad [numeric] Edad Mean (sd) : 46.1 (15.3) min 63 distinct values  2927 (100%) 0 (0%)   7 pmerit [numeric] Meritocracia promedio Mean (sd) : 2.7 (1) min 1.00:243(8.4%)1.50:79(2.7%)2.00:1041(35.9%)2.50:222(7.7%)3.00:536(18.5%)3.50:169(5.8%)4.00:528(18.2%)4.50:38(1.3%)5.00:42(1.5%)  2898 (99.01%) 29 (0.99%)    Generated by summarytools 0.9.6 (R version 3.6.0)2020-04-23\n Nota sobre casos perdidos (NAs)na.omit(data)\nHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n respaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_elsoc_original. contamos el número de casos con el comando dim contamos el número de casos perdidos con sum(is.na(proc_elsoc)) borramos los casos perdidos con proc_elsoc \u0026lt;-na.omit(proc_elsoc) contamos nuevamente con dim para asegurarnos que se borraron y por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.  proc_elsoc_original \u0026lt;-proc_elsoc dim(proc_elsoc) ## [1] 2927 7 sum(is.na(proc_elsoc)) ## [1] 81 proc_elsoc \u0026lt;-na.omit(proc_elsoc) dim(proc_elsoc) ## [1] 2887 7 proc_elsoc \u0026lt;-sjlabelled::copy_labels(proc_elsoc,proc_elsoc_original)  3.2 Exploración de asociación entre variables Dado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivio que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n Variables categóricas: tabla de contingencia Variable categórica y continua: tabla de promedios por cada categoría Variables continuas: correlaciones.  En esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\nTablas de contingencia para variables categóricas Para tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo)  Educación  Sexo  Total    Hombre  Mujer    Primaria incompleta\nmenos  102  247  349    Primaria y\nsecundaria baja  105  186  291    Secundaria alta  511  727  1238    Terciaria ciclo\ncorto  186  292  478    Terciaria y\nPostgrado  245  286  531    Total  1149  1738  2887   χ2=28.154 · df=4 · Cramer’s V=0.099 · p=0.000    Al ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo, show.col.prc=TRUE, show.summary=FALSE )  Educación  Sexo  Total    Hombre  Mujer    Primaria incompleta\nmenos  102\n8.9 %  247\n14.2 %  349\n12.1 %    Primaria y\nsecundaria baja  105\n9.1 %  186\n10.7 %  291\n10.1 %    Secundaria alta  511\n44.5 %  727\n41.8 %  1238\n42.9 %    Terciaria ciclo\ncorto  186\n16.2 %  292\n16.8 %  478\n16.6 %    Terciaria y\nPostgrado  245\n21.3 %  286\n16.5 %  531\n18.4 %    Total  1149\n100 %  1738\n100 %  2887\n100 %     Tablas de promedio de variable continua por una categóricas En ejemplo vamos a explorar datos de nuestra variable de percepción de meritocracia pmerit por los niveles educacionales edcine.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\ntapply(proc_elsoc$pmerit, proc_elsoc$edcine, mean) ## 1 2 3 4 5 ## 2.968481 2.697595 2.662763 2.479079 2.559322 Aquí vemos en promedio de pmerit para cada uno de los 5 niveles de la variable educación edcine. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %\u0026gt;%. El sentido de cada función aparece comentado abajo:\nproc_elsoc %\u0026gt;%# se especifica la base de datos select(pmerit,edcine) %\u0026gt;%# se seleccionan las variables dplyr::group_by(Educación=sjlabelled::as_label(edcine)) %\u0026gt;%# se agrupan por la variable categórica y se usan sus etiquetas con as_label dplyr::summarise(Obs.=n(),Promedio=mean(pmerit),SD=sd(pmerit)) %\u0026gt;%# se agregan las operaciones a presentar en la tabla kable(, format = \u0026quot;markdown\u0026quot;) # se genera la tabla   Educación Obs. Promedio SD    Primaria incompleta menos 349 2.968481 0.9828315  Primaria y secundaria baja 291 2.697595 1.0041093  Secundaria alta 1238 2.662762 0.9685655  Terciaria ciclo corto 478 2.479080 0.9431323  Terciaria y Postgrado 531 2.559322 0.9223446    Esta asocación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función plot_grpfrq de sjPlot:sjPlot::plot_grpfrq\nplot_grpfrq(proc_elsoc$pmerit,proc_elsoc$edcine, type = \u0026quot;box\u0026quot;)  Correlaciones (variables continuas) Algunas notas sobre correlación:\n El coeficiente de correlación mide la fuerza de la relación lineal entre dos variable continuas. Esta puede ser:\n positiva: a medida que aumenta una, aumenta la otra (ej: estatura y edad) negativa: a medida que una aumenta, disminuye la otra (ej: tiempo dedicado al estudio y probabilidad de reprobar) neutra: no hay asociación entre variables.  El rango de variación del coeficiente de correlación va desde -1 (correlación negativa perfecta) y 1 (correlación positiva perfecta).\n Existen diferentes formas de cálculo del coeficiente de correlación (Spearman, Kendall, Pearson).\n En el coeficiente de correlación se analiza tanto su tamaño como su significación estadística.\n  En lo que sigue nos concentraremos en el coeficiente de correlación más utilizado que es el de Pearson, que se aplica cuando las variables son de naturaleza continua.\nTablas/matrices de correlación\nLas correlaciones entre variables se presentan en general en modo de matrices, es decir, las variables se presentan en las filas y las columnas y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a lacor base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\nM \u0026lt;-cor(proc_elsoc) M ## mesfuerzo mtalento ess edcine sexo ## mesfuerzo 1.000000000 0.69768811 -0.004312135 -0.12167659 -0.04480502 ## mtalento 0.697688106 1.00000000 0.018447696 -0.10582754 -0.03759340 ## ess -0.004312135 0.01844770 1.000000000 0.28959248 -0.03745546 ## edcine -0.121676591 -0.10582754 0.289592479 1.00000000 -0.08682644 ## sexo -0.044805024 -0.03759340 -0.037455462 -0.08682644 1.00000000 ## edad 0.096495547 0.07383771 -0.066031873 -0.37660283 0.06121699 ## pmerit 0.920404032 0.92224547 0.007740598 -0.12341680 -0.04469515 ## edad pmerit ## mesfuerzo 0.09649555 0.920404032 ## mtalento 0.07383771 0.922245465 ## ess -0.06603187 0.007740598 ## edcine -0.37660283 -0.123416804 ## sexo 0.06121699 -0.044695146 ## edad 1.00000000 0.092369792 ## pmerit 0.09236979 1.000000000 Este es el reporte simple, pero no muy amigable a la vista. Para una versión más amable utilizamos la función sjt.corrsjPlot::sjt.corr:NOTA: sjPlot actualizó su librería a fines de Mayo (versión 2.8.4); para quienes hayan actualizado a esta versión, la función para tabla de correlaciones ahora es tab_corr\nsjt.corr(proc_elsoc)   Recompensa: esfuerzo  Recompensa: talento  Estatus Social Subjetivo  Educación  Sexo  Edad  Meritocracia promedio    Recompensa: esfuerzo   0.698***  -0.004  -0.122***  -0.045*  0.096***  0.920***    Recompensa: talento  0.698***   0.018  -0.106***  -0.038*  0.074***  0.922***    Estatus Social Subjetivo  -0.004  0.018   0.290***  -0.037*  -0.066***  0.008    Educación  -0.122***  -0.106***  0.290***   -0.087***  -0.377***  -0.123***    Sexo  -0.045*  -0.038*  -0.037*  -0.087***   0.061**  -0.045*    Edad  0.096***  0.074***  -0.066***  -0.377***  0.061**   0.092***    Meritocracia promedio  0.920***  0.922***  0.008  -0.123***  -0.045*  0.092***     Computed correlation used pearson-method with listwise-deletion.    Con esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n En esta matriz las variables están representadas en las filas y en las columnas. Cada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de recompensa por esfuerzo y recompensa por inteligencia es 0.698. La información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno. En la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva. En esta tabla se omiten y aparece la diagonal vacía, ya que es información redundante. Por lo mismo, también se recomienda eliminar el triangulo superior de la tabla (redundante) de la siguiente manera:  sjt.corr(proc_elsoc, triangle = \u0026quot;lower\u0026quot;)   Recompensa: esfuerzo  Recompensa: talento  Estatus Social Subjetivo  Educación  Sexo  Edad  Meritocracia promedio    Recompensa: esfuerzo           Recompensa: talento  0.698***          Estatus Social Subjetivo  -0.004  0.018         Educación  -0.122***  -0.106***  0.290***        Sexo  -0.045*  -0.038*  -0.037*  -0.087***       Edad  0.096***  0.074***  -0.066***  -0.377***  0.061**      Meritocracia promedio  0.920***  0.922***  0.008  -0.123***  -0.045*  0.092***     Computed correlation used pearson-method with listwise-deletion.    Una segunda forma de presentar matrices de correlaciones es de manera gráfica con la librería corrplot, cuya función corrplot.mixed corrplot::corrplot.mixedse aplica al objeto que generamos con la función cor (M):\ncorrplot.mixed(M) Este gráfico/matriz representa el grado de asociación entre variables mediante el tamaño de los círculos e intensidad de colores, y el signo de la asociación se representa con una gradiente de colores que va del azul (positivo) al rojo (negativo). Bajo la diagonal aparecen los indices de correlación entre pares de variables.\nFinalmente, también se puede representar la correlación entre dos variables en un gráfico de nube de puntos o scatterplot:sjPlot::plot_scatter\nnames(proc_elsoc) ## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot; plot_scatter(proc_elsoc, edad, ess) Donde:\n cada punto representa un caso la forma de la nube indica si la asociación es positiva, negativa o neutra:  En el caso de nuestra nube de puntos entre edad y estatus social subjetivo, observamos que no hay asociación (lo que ya era indicado por su correlación de -0.07 observada en la matriz de correlaciones).\n   Nota final: Información de la sesión de R R y sus librerías tienen distintas versiones. Esto puede representar algunos problemas de compatibilidad entre usuarios, por ejemplo, dos personas que trabajan en el mismo proyecto pero con distintas versiones (librerías y/o de R), pueden tener ocasionalmente complicaciones. Por eso, una buena práctica es registrar al final del código la información de la sesión. Y como siempre en R, varias maneras de hacer esto. Vamos con la más genérica que es muy simple: sessionInfo() sessionInfo()\nsessionInfo() ## R version 4.0.0 (2020-04-24) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 16.04.6 LTS ## ## Matrix products: default ## BLAS: /usr/lib/libblas/libblas.so.3.6.0 ## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=es_CL.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=es_CL.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=es_CL.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=es_CL.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] sessioninfo_1.1.1 corrplot_0.84 sjmisc_2.8.4 summarytools_0.9.6 ## [5] sjstats_0.18.0 psych_1.9.12.31 Publish_2019.12.04 prodlim_2019.11.13 ## [9] ggpubr_0.3.0 magrittr_1.5 car_3.0-7 carData_3.0-3 ## [13] scales_1.1.1 gridExtra_2.3 ggplot2_3.3.0 stargazer_5.2.2 ## [17] sjPlot_2.8.3 kableExtra_1.1.0 Rmisc_1.5 plyr_1.8.6 ## [21] lattice_0.20-41 dplyr_0.8.5 knitr_1.28 pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] TH.data_1.0-10 minqa_1.2.4 colorspace_1.4-1 pryr_0.1.4 ## [5] ggsignif_0.6.0 ellipsis_0.3.0 rio_0.5.16 sjlabelled_1.1.4 ## [9] estimability_1.3 parameters_0.6.1 base64enc_0.1-3 rstudioapi_0.11 ## [13] fansi_0.4.1 mvtnorm_1.1-0 lubridate_1.7.8 xml2_1.3.2 ## [17] codetools_0.2-16 splines_4.0.0 mnormt_1.5-7 nloptr_1.2.2.1 ## [21] ggeffects_0.14.3 broom_0.5.6 effectsize_0.3.0 readr_1.3.1 ## [25] compiler_4.0.0 httr_1.4.1 emmeans_1.4.6 backports_1.1.7 ## [29] assertthat_0.2.1 Matrix_1.2-18 cli_2.0.2 htmltools_0.4.0 ## [33] tools_4.0.0 coda_0.19-3 gtable_0.3.0 glue_1.4.1 ## [37] Rcpp_1.0.4.6 cellranger_1.1.0 vctrs_0.3.0 nlme_3.1-147 ## [41] blogdown_0.18 insight_0.8.4 xfun_0.13 stringr_1.4.0 ## [45] openxlsx_4.1.5 lme4_1.1-23 rvest_0.3.5 lifecycle_0.2.0 ## [49] statmod_1.4.34 rstatix_0.5.0 MASS_7.3-51.6 zoo_1.8-8 ## [53] hms_0.5.3 parallel_4.0.0 sandwich_2.5-1 yaml_2.2.1 ## [57] curl_4.3 pander_0.6.3 stringi_1.4.6 bayestestR_0.6.0 ## [61] checkmate_2.0.0 boot_1.3-25 zip_2.0.4 lava_1.6.7 ## [65] rlang_0.4.6 pkgconfig_2.0.3 matrixStats_0.56.0 evaluate_0.14 ## [69] purrr_0.3.4 rapportools_1.0 tidyselect_1.1.0 bookdown_0.18 ## [73] R6_2.4.1 magick_2.3 generics_0.0.2 multcomp_1.4-13 ## [77] pillar_1.4.4 haven_2.2.0 foreign_0.8-79 withr_2.2.0 ## [81] survival_3.1-12 abind_1.4-5 tibble_3.0.1 performance_0.4.6 ## [85] modelr_0.1.7 crayon_1.3.4 rmarkdown_2.1 grid_4.0.0 ## [89] readxl_1.3.1 data.table_1.12.8 forcats_0.5.0 digest_0.6.25 ## [93] webshot_0.5.2 xtable_1.8-4 tidyr_1.0.3 munsell_0.5.0 ## [97] viridisLite_0.3.0 tcltk_4.0.0 Acá vemos un listado de información muy completo, desde versión de R, sistema operativo, opciones de idioma local (LOCALE), y muchas librerías. Si optamos por esta versión de la información de la sesión, lo importante es fijarse en (a) version de R, y (b) de las librerías cargadas al principio, que aquí aparecen bajo “other attached packages”.\nLa segunda opción permite obtener información más precisa, con sessioninfo sessioninfo()(la única diferencia con la anterior en el nombre es que info es con minúscula sessioninfo). Con un poco más de especificaciones de sintaxis se pueden obtener directamente los puntos (a) y (b) mencionados anteriormente:\nsession_info(\u0026quot;sessioninfo\u0026quot;)$platform ## setting value ## version R version 4.0.0 (2020-04-24) ## os Ubuntu 16.04.6 LTS ## system x86_64, linux-gnu ## ui X11 ## language en_US ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/Santiago ## date 2020-05-16 package_info(pkgs = (.packages()), dependencies = FALSE) ## package * version date lib source ## car * 3.0-7 2020-03-11 [1] CRAN (R 4.0.0) ## carData * 3.0-3 2019-11-16 [1] CRAN (R 4.0.0) ## corrplot * 0.84 2017-10-16 [1] CRAN (R 4.0.0) ## dplyr * 0.8.5 2020-03-07 [1] CRAN (R 4.0.0) ## ggplot2 * 3.3.0 2020-03-05 [1] CRAN (R 4.0.0) ## ggpubr * 0.3.0 2020-05-04 [1] CRAN (R 4.0.0) ## gridExtra * 2.3 2017-09-09 [1] CRAN (R 4.0.0) ## kableExtra * 1.1.0 2019-03-16 [1] CRAN (R 4.0.0) ## knitr * 1.28 2020-02-06 [1] CRAN (R 4.0.0) ## lattice * 0.20-41 2020-04-02 [1] CRAN (R 4.0.0) ## magrittr * 1.5 2014-11-22 [1] CRAN (R 4.0.0) ## pacman * 0.5.1 2019-03-11 [1] CRAN (R 4.0.0) ## plyr * 1.8.6 2020-03-03 [1] CRAN (R 4.0.0) ## prodlim * 2019.11.13 2019-11-17 [1] CRAN (R 4.0.0) ## psych * 1.9.12.31 2020-01-08 [1] CRAN (R 4.0.0) ## Publish * 2019.12.04 2019-12-04 [1] CRAN (R 4.0.0) ## Rmisc * 1.5 2013-10-22 [1] CRAN (R 4.0.0) ## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.0.0) ## sessioninfo * 1.1.1 2018-11-05 [1] CRAN (R 4.0.0) ## sjmisc * 2.8.4 2020-04-03 [1] CRAN (R 4.0.0) ## sjPlot * 2.8.3 2020-03-09 [1] CRAN (R 4.0.0) ## sjstats * 0.18.0 2020-05-06 [1] CRAN (R 4.0.0) ## stargazer * 5.2.2 2018-05-30 [1] CRAN (R 4.0.0) ## summarytools * 0.9.6 2020-03-02 [1] CRAN (R 4.0.0) ## ## [1] /home/juank/Dropbox/Rlibrary ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library   Resumen Práctica 2: Descripción de variables En esta práctica revisamos los siguientes contenidos:\n tabla descriptiva general de variables tabla de asociación (o contingencia) entre dos variables categóricas tabla y gráfico de asociación entre variables categóricas y contínuas asociaciones entre pares de variables continuas mediante el índice de correlación.   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí\n Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Foro práctica 2  ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"112494b1f3727cfe1df8f164d59d3152","permalink":"/assignment/02-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/02-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.","tags":null,"title":"Práctica 2. Descripción de variables","type":"docs"},{"authors":null,"categories":null,"content":" Presentación El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevante para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades.\n Preparacion de datos con ELSOC 2016 Librerías y configuración library(dplyr) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union rm(list=ls()) # borrar todos los objetos en el enviorment options(scipen=999) #sin notacion cientifica Cargar base de datos  Ejemplo de ruta, debe remplazarla por la de su computador.  setwd(\u0026quot;C:/usuario/usted/multivariada/materiales/01material\u0026quot;)  # buscammos la sub carpeta ... datos/original/ELSOC_W01_v3.10.RData load(\u0026quot;data/original/ELSOC_W01_v3.10.RData\u0026quot;) elsoc \u0026lt;- elsoc_2016; remove(elsoc_2016) # load(\u0026quot;link/ELSOC_W01_v3.10.RData\u0026quot;)  Datos perdidos  En ELSOC todos los valores -888 y -999 corresponden a valores para las categorias “No sabe” y “No responde”, respectivamente. Decidimos dejarlas como valores perdidos (NA)  for (i in 1:ncol(elsoc)) { elsoc[,i][elsoc[,i] == c(-888)] \u0026lt;- NA #Missing elsoc[,i][elsoc[,i] == c(-999)] \u0026lt;- NA #Missing }   Recodificacion Variables percepcion de meritocracia  [c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo) [c18_10]: “Grado de acuerdo: Las personas son recompensada por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)  elsoc$c18_09 \u0026lt;- as.numeric(elsoc$c18_09) elsoc$c18_10 \u0026lt;- as.numeric(elsoc$c18_10) # Variables meritocracia promedio ----------------------------------------- elsoc \u0026lt;- rename(elsoc,meffort=c18_09) # cambio de nombre de la variable c18_09 a uno mas sustantivo elsoc \u0026lt;- rename(elsoc,mtalent=c18_10) # cambio de nombre de la variable c18_10 a uno mas sustantivo # creamos un indice promedio de percepcion de meritocracia usando ambas preguntas elsoc$merit \u0026lt;- (elsoc$meffort+elsoc$mtalent)/2 # re escalamos la variable de 1-5 a una de 0 a 100 (para facilitar interpretacion) elsoc$merit \u0026lt;- (elsoc$merit-min(elsoc$merit,na.rm=T))/(max(elsoc$merit,na.rm=T)-min(elsoc$merit,na.rm=T))*100  Recodificacion variable Estatus subjetivo  [d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)  elsoc$ess \u0026lt;- as.numeric(elsoc$d01_01) # Estatus Social Subjetivo table(elsoc$ess) summary(elsoc$ess) ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 44 84 207 439 677 975 310 116 37 4 22 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0.00 3.00 5.00 4.33 5.00 10.00 12  Recodificacion variables Estatus objetivo Ingresos del hogar summary(elsoc$m29) # ingresos total ; NA == 587 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0 267500 420000 2477852 700000 4000000000 587 summary(elsoc$m30) # ingresos tramos  ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 3.000 6.000 7.415 11.000 20.000 2479 summary(elsoc$nhogar1) # tamannio del hogar ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 3.077 4.000 14.000 elsoc$m29[elsoc$m29==0] \u0026lt;- NA # Remplazar NA por media de categorias Ingreso -------------------------------# elsoc$mean_tramos \u0026lt;- NA # creamos una variable vacia # remplazamos ... elsoc$mean_tramos[elsoc$m30==1] \u0026lt;-110000 elsoc$mean_tramos[elsoc$m30==2] \u0026lt;-250000.5 elsoc$mean_tramos[elsoc$m30==3] \u0026lt;-305000.5 elsoc$mean_tramos[elsoc$m30==4] \u0026lt;-355000.5 elsoc$mean_tramos[elsoc$m30==5] \u0026lt;-400000.5 elsoc$mean_tramos[elsoc$m30==6] \u0026lt;-445000.5 elsoc$mean_tramos[elsoc$m30==7] \u0026lt;-490000.5 elsoc$mean_tramos[elsoc$m30==8] \u0026lt;-535000.5 elsoc$mean_tramos[elsoc$m30==9] \u0026lt;-585000.5 elsoc$mean_tramos[elsoc$m30==10]\u0026lt;-640000.5 elsoc$mean_tramos[elsoc$m30==11]\u0026lt;-700000.5 elsoc$mean_tramos[elsoc$m30==12]\u0026lt;-765000.5 elsoc$mean_tramos[elsoc$m30==13]\u0026lt;-845000.5 elsoc$mean_tramos[elsoc$m30==14]\u0026lt;-935000.5 elsoc$mean_tramos[elsoc$m30==15]\u0026lt;-1040000.5 elsoc$mean_tramos[elsoc$m30==16]\u0026lt;-1180000.5 elsoc$mean_tramos[elsoc$m30==17]\u0026lt;-1375000.5 elsoc$mean_tramos[elsoc$m30==18]\u0026lt;-1670000.5 elsoc$mean_tramos[elsoc$m30==19]\u0026lt;-2275000.5 elsoc$mean_tramos[elsoc$m30==20]\u0026lt;-3726106 table(elsoc$mean_tramos) # chequeamos ## ## 110000 250000.5 305000.5 355000.5 400000.5 445000.5 490000.5 535000.5 ## 49 42 36 35 33 33 38 21 ## 585000.5 640000.5 700000.5 765000.5 845000.5 935000.5 1040000.5 1180000.5 ## 26 16 18 15 11 14 19 13 ## 1375000.5 1670000.5 2275000.5 3726106 ## 4 10 8 7 elsoc$m29 \u0026lt;- ifelse(test = (is.na(elsoc$m29)),#¿es el valor un NA? yes = elsoc$mean_tramos, #Si es verdadero, remplazar por el valor de mean_tramos no = elsoc$m29)# Si es falso, remplazar por el valor del m29 summary(elsoc$m29) # NA = 147 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 20000 280000 445000 2182986 700000 4000000000 147 # cambiamos el nombre de las variables inghogar = m29; nhogar=nhogar1 elsoc \u0026lt;- rename(elsoc, inghogar=m29, nhogar=nhogar1) # ingreso neto = ingreso del hogar / numero de personas en el hogar elsoc$ingneto \u0026lt;- as.numeric(elsoc$inghogar/elsoc$nhogar) # logaritmo natural del ingreso neto (para normalizar la distribucion sesgada del ingreso) elsoc$lningneto \u0026lt;- log(elsoc$ingneto) summary(elsoc$ingneto) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 7500 95000 150000 1028152 267500 2000000000 147 summary(elsoc$lningneto) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 8.923 11.462 11.918 12.006 12.497 21.416 147 #---Deciles (ingreso per capita hogar)------------------------------------------------ elsoc \u0026lt;- elsoc %\u0026gt;% mutate(inc10h = ntile(inghogar, 10)) # Crear Deciles de ingreso elsoc$D10h \u0026lt;- factor(elsoc$inc10h, levels = c(1,2,3,4,5,6,7,8,9,10), labels = c(\u0026quot;D01\u0026quot;,\u0026quot;D02\u0026quot;,\u0026quot;D03\u0026quot;,\u0026quot;D04\u0026quot;,\u0026quot;D05\u0026quot;, \u0026quot;D06\u0026quot;,\u0026quot;D07\u0026quot;,\u0026quot;D08\u0026quot;,\u0026quot;D09\u0026quot;,\u0026quot;D10\u0026quot;));table(elsoc$D10h) ## ## D01 D02 D03 D04 D05 D06 D07 D08 D09 D10 ## 278 278 278 278 278 278 278 278 278 278  Educación table(elsoc$m01) # Educacion en ELSOC ## ## 1 2 3 4 5 6 7 8 9 10 ## 37 322 297 394 857 102 381 186 303 46 Recodificación CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1 2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1 3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2 4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3 5. Educacion Media o Humanidades completa = [CINE 3 ] = 3 6. Tecnico Superior incompleta = [CINE 5 ] = 4 7. Tecnico Superior completa = [CINE 5 ] = 4 8. Universitaria incompleta = [CINE 6 ] = 5 9. Universitaria completa = [CINE 6 ] = 6 10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6 # recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car elsoc$edcine \u0026lt;- car::recode(elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) round(prop.table(table(elsoc$edcine)), 3) ## ## 1 2 3 4 5 ## 0.123 0.102 0.428 0.165 0.183 elsoc$edcine \u0026lt;- factor(elsoc$edcine, levels = c(1,2,3,4,5), labels=c(\u0026quot;Primaria incompleta menos\u0026quot;, \u0026quot;Primaria y secundaria baja\u0026quot;, \u0026quot;Secundaria alta\u0026quot;, \u0026quot;Terciaria ciclo corto\u0026quot;, \u0026quot;Terciaria y Postgrado\u0026quot;)) table(elsoc$edcine) #chequeamos ## ## Primaria incompleta menos Primaria y secundaria baja ## 359 297 ## Secundaria alta Terciaria ciclo corto ## 1251 483 ## Terciaria y Postgrado ## 535   Variables control #---Sexo---- elsoc$sexo \u0026lt;- car::recode(elsoc$m0_sexo, \u0026quot;1=1;2=0\u0026quot;) elsoc$sexo \u0026lt;- factor(elsoc$sexo, levels = c(0,1), labels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;)) # Sexo #Hombre=0 #Mujer=1 #---Edad---- elsoc$edad \u0026lt;- as.numeric(elsoc$m0_edad) #Edad #---Posicion Politica---- # PREGUNTA: \u0026quot;Autoubicacion escala izquierda-derecha\u0026quot; # (0 = izquierda; 10 = Derecha; 11 = Independiente; 12 =Ninguno) elsoc$ppolcat \u0026lt;- car::recode(elsoc$c15, \u0026quot;c(0,1,2,3,4)=1;5=2;c(6,7,8,9,10)=3;11=4;12=5\u0026quot;) elsoc$ppolcat \u0026lt;- factor(elsoc$ppolcat, levels = c(1,2,3,4,5), labels = c(\u0026quot;Izquierda/Centro Izquierda\u0026quot;, \u0026quot;Centro\u0026quot;, \u0026quot;Derecha/Centro Derecha\u0026quot;, \u0026quot;Independiente\u0026quot;, \u0026quot;Ninguno\u0026quot;))   Mantener variables relevantes # selecccionamos las variables relevantes elsoc_16 \u0026lt;- elsoc %\u0026gt;% dplyr::select(merit,ess,edcine,lningneto,D10h, sexo, edad,ppolcat) # dejamos solamente los casos con informacion completa (listwise deletion) elsoc_16 \u0026lt;- na.omit(elsoc_16) names(elsoc_16) # comprobamos los nombres de variables ## [1] \u0026quot;merit\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;lningneto\u0026quot; \u0026quot;D10h\u0026quot; \u0026quot;sexo\u0026quot; ## [7] \u0026quot;edad\u0026quot; \u0026quot;ppolcat\u0026quot; head(elsoc_16) #chequear ## merit ess edcine lningneto D10h sexo edad ppolcat ## 1 75.0 5 Primaria incompleta menos 11.22524 D03 Hombre 64 Independiente ## 2 75.0 5 Secundaria alta 12.42922 D06 Hombre 60 Ninguno ## 3 50.0 3 Secundaria alta 11.31040 D06 Hombre 26 Ninguno ## 4 75.0 6 Terciaria y Postgrado 13.54763 D08 Mujer 51 Ninguno ## 5 62.5 4 Secundaria alta 13.10216 D06 Mujer 69 Ninguno ## 6 75.0 5 Secundaria alta 13.10216 D06 Mujer 62 Independiente # Guardar base de datos procesada --------------------------------------------------------------- save(elsoc_16,file = \u0026quot;data/proc/ELSOC_ess_merit2016.RData\u0026quot;)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585881306,"objectID":"96782a7dad874126bc6358fdb483b41e","permalink":"/assignment/01material/prep-datos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/01material/prep-datos/","section":"assignment","summary":"Presentación El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.","tags":null,"title":"Material 1. Procesamiento de datos en R","type":"assignment"},{"authors":null,"categories":null,"content":"       Contenidos y Presentaciones  Prácticas y evaluaciones  Lecturas y material adicional    ABRIL      3 1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales Práctica 1: Preparación de datos - *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología  MAYO      15 2. Bases/Repaso - Datos y variables - Preparación y descripción - Varianza y covarianza - Correlación (descriptiva) Práctica 2: Descripción de variables - Moore: 1.Comprensión de los datos (1-54)  22 3. Regresión simple I Distribución condicional\nMínimos cuadrados y recta de regresión Práctica 3: Correlación y regresión - Moore: 2. Análisis de relaciones (97-131)   29 4. Regresión simple II Regresión vs correlación Residuos y ajuste general (R2) Presentación pauta de Trabajo del curso Practica 4: Residuos y ajuste - Moore: Residuos (144-154)  JUNIO      5 Semana preparación Informe 1 Informe 1: Regresión simple (individual) 20%, entrega MIERCOLES 10 Ejemplo de informe aquí  12 Semana de receso    19 5. Regresión múltiple 1 - Introducción Práctica 5: Tabla de regresión múltiple - * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)  26 6. Regresión múltiple 2 - Coeficientes de regresión parcial - Correlación parcial y semiparcial  Práctica 6: Parcialización y control estadístico - * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)  JULIO      03 7. Regresión e inferencia - Conceptos y supuestos - Tabla ANOVA - Inferencia sobre coeficientes Práctica 6: Inferencia - Moore 7: Inferencia para medias (482-543)  10 8. Predictores e interpretación - Predictores categóricos - Selección de predictores, setwise \u0026amp; stepwise Práctica 7: Predictores - Wooldridge (2010) Cap 7: Análisis de regresión múltiple con información cualitativa (225-246)  17 Semana preparación informe 2 Informe 2: Regresión múltiple (grupal) 30%, entrega Miércoles 29 - * Wooldridge (2010) Cap 19: Realización de un proyecto empírico (668-694)       24 Semana de Receso    31 9. Regresión logística I - Probabilidades - Odds ratios Práctica 9: Probabilidades y Odds Camarero et al (2017) Regresión logística (1-29)   AGOSTO      07 10. Regresión logística II - Estimación de parámetros - Inferencia - Predicción Práctica 10: Estimación logística - Camarero et al (2017) Regresión logística (30-52)  14 11. Detección y manejo de irregularidades en modelos de regresión - Relaciones no lineales -Transformaciones - Centrado Práctica 11: Chequeos de robustez - Darlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities - Darlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships  21 12. Repaso, pendientes y cierre de los contenidos Preparación Informe 3 Entrega Informe 3: Regresión logística, predictores categóricos y supuestos (grupal) 50%. Wooldridge cap 6 Temas adicionales    Examen final: Semana del 7 de Septiembre\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593180783,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Contenidos y Presentaciones  Prácticas y evaluaciones  Lecturas y material adicional    ABRIL      3 1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales Práctica 1: Preparación de datos - *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología  MAYO      15 2.","tags":null,"title":"Planificación","type":"page"},{"authors":null,"categories":null,"content":"  Propósito general del curso Competencias a las que contribuye el curso Sub-Competencias  Resultados de Aprendizaje Saberes / contenidos UNIDAD 1: Introducción al modelamiento de datos sociales UNIDAD 2: Regresión Lineal Simple y Múltiple UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Metodología (actualizado) Evaluación (actualizado) (detalles en pestaña Trabajos) Requisitos de aprobación Bibliografía Textos principales. MODELOS CIENTÍFICOS (Unidad 1) MODELOS DE REGRESIÓN LINEAL (Unidad 2) MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3) Links \u0026amp; otras recomendaciones  Software Plataformas de comunicación y discusión VARIOS Programación de sesiones   Propósito general del curso Al finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado. Se espera que los estudiantes sean capaces de:\n identificar las principales técnicas de análisis estadístico multivariado utilizadas en la investigación sociológica depurar y preparar datos para la aplicación de distintas técnicas de análisis estadístico multivariado; corroborar las condiciones de aplicación de distintas técnicas de análisis estadístico multivariado utilizar software de análisis estadístico contrastar hipótesis de investigación elaborar reportes de resultados y conclusiones a partir de la aplicación de diferentes técnicas de análisis estadístico multivariado.  Complementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos.\n Competencias a las que contribuye el curso  Diseñar y desarrollar estrategias de investigación social.\n Comunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos.\n  Sub-Competencias  Diseñar y aplicar diversas técnicas de recolección y producción de información empírica, pertinentes al objeto de estudio.\n Interpretar información empírica aplicando diversas técnicas, en función de un plan de análisis.\n Diseñar estrategias para comunicar los saberes disciplinares considerando las características de distintos contextos y audiencias.\n Comunicar en forma oral y escrita los saberes disciplinares considerando distintos contextos y audiencias, haciendo un uso creativo de distintas estrategias.\n    Resultados de Aprendizaje Al finalizar el curso, los estudiantes:\n Serán capaces de explicar los conceptos y fundamentos teóricos y estadísticos de la investigación social basada en modelos predictivos para variables observadas y serán capaces de explicar su utilidad para la sociología. Serán capaces de preparar y depurar bases de datos para su análisis utilizando técnicas multivariadas, evaluando la pertinencia y la presencia de condiciones para la aplicación de modelos predictivos para variables observadas. Serán capaces de manejar software especializado y reportar los resultados de modelos predictivos para variables observadas cuantitativas y no cuantitativas.   Saberes / contenidos UNIDAD 1: Introducción al modelamiento de datos sociales  Tipos de investigación (descriptiva vs relacional y explicativa) y su materialización en el análisis estadístico. La explicación en ciencias sociales: su relación con el concepto de covariación; la explicación como dependencia robusta y como cadena causal y el trabajo con modelos. El trabajo con modelos: tipos de modelos (modelo teórico, modelo normativo, modelo científico, modelo estadístico); la vinculación entre los modelos científicos y los modelos teóricos; los modelos estadísticos como tipo de modelo científico. Ciencia abierta y modelamiento: transparencia, reproducibilidad y replicación.   UNIDAD 2: Regresión Lineal Simple y Múltiple  Bases: varianza, covarianza y correlación. Usos y aplicaciones en ciencias sociales de la regresión lineal. Supuestos y condiciones de aplicación de la regresión lineal. Manejo de casos influyentes Procedimientos de estimación e interpretación de parámetros. Introducción de variables de control estadístico. Criterios de validez, capacidad predictiva y evaluación del ajuste de la regresión lineal. Temas avanzados de regresión lineal: introducción de predictores categóricos, estimación de efectos de interacción y mediación, y uso de herramientas gráficas como apoyo a la interpretación y análisis de datos.   UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Limitaciones de la regresión lineal y potencialidades de la introducción de variables dependientes categóricas. Concepto y sentido de la función logística y funciones afines. Supuestos y condiciones de aplicación de la regresión para variables categóricas. Procedimientos de estimación e interpretación de parámetros de regresión logística. Criterios de validez, capacidad predictiva y evaluación del ajuste de la regresión Logística. Generalización de modelos de regresión logística: modelo de regresión logística multinomial y ordinal. Empleo de otras matrices de correlación (tetracórica, biserial y policórica).    Metodología (actualizado) En las circunstancias excepcionales de este semestre dada la crisis santiaria, se han realizado una serie de ajustes metodológicos. De todas maneras estos se irán actualizando en el transcurso del semestre según varíe la contingencia y también atendiendio a necesidades y sugerencias de l_s participantes.\nTendremos tres espacios principales de aprendizaje:\nSesiones de clases: mientras dure la emergencia se realizaran online mediante la plataforma Zoom para las dos secciones; eventualmente algunas de las clases serán reemplazadas por videos explicativos. Todo el material de presentaciones se encontrará disponible en este sitio.\n Prácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana separados por secciones, para dar mayor oportunidad de participación y resolver las dudas respectivas. Estas prácticas serán supervisadas principalmente por los apoyos docentes.\n Trabajos: se desarrollarán trabajos de investigación durante el semestre (ver sección evaluación abajo) que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados principalmente por ayudantes que se asignarán a cada grupo.\n   Evaluación (actualizado) (detalles en pestaña Trabajos) El curso tendrá tres instancias de evaluación:\n Trabajo 1 (individual): Correlación y regresión simple (20%). Trabajo 2 (grupal): Regresión multiple e inferencia estadística (30%) Trabajo 3 (grupal): Regresión logística, predictores categóricos y supuestos (50%)  La nota ponderada de los trabajos equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\n Requisitos de aprobación Nota mínima de aprobación: 4,0 (en escala de 1 a 7).\nRequisitos de eximición de examen:\ncontar con un promedio ponderado igual o superior a 5.5. no tener nota bajo 4 en ninguno de los trabajos  Requisitos para presentación a examen:\n Podrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5. El examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0.   Bibliografía La bibliografía obligatoria para cada semana se presenta en la planificación del curso, desde donde se puede acceder directamente a los documentos. De todas maneras, abajo algunos textos comentados y referencias para cada unidad.\nTextos principales. Hay cuatro referencias principales recomendadas para este curso:\n Moore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch. No estaba en la bibliografía original, pero se incluye porque explica de manera bastante clara (y en español) una serie de análisis estadístico que sirven de base para este curso.\n Darlington, R. B., \u0026amp; Hayes, A. F. (2017). Regression analysis and linear models: concepts, applications, and implementation. Guilford Press. Este libro me parece un muy buen texto para acompañar un curso de regresión en ciencias sociales, lamentablemente está en inglés y por lo tanto solo es bibliografía sugerida. Los capítulos más relevantes estarán a disposición,\n Wooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning. Libro clásico de regresión para economístas, la ventaja es que está en español, la desventaja (para nosotros) es que en ocasiones utiliza un lenguaje y ejemplos lejanos a la sociología.\n Wickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly. Libro con enfoque en el aprendizaje de R con técnicas que ciertamente van más allá del curso, pero muy util como referencia general. Además, está disponible también en español como “R para ciencia de datos”.\n  Abajo bilbiografía recomendada para cada unidad\n MODELOS CIENTÍFICOS (Unidad 1)  García-Ferrando, M. (1985). Análisis y modelización causal en sociología. Reis, 29(1), 143-164. Goldthorpe, J. H. (2001). Causation, statistics, and sociology. European Sociological Review, 17(1), 1-20. Ramón, L., \u0026amp; Ángeles, M. (2006). Estadística y causalidad en la sociología empírica del XX. Papers: revista de sociología, 80(1), 223-255. Salgado, M. (2009). Construyendo explicaciones: el uso de modelos en sociología. Persona y Sociedad, 30 (3), 29-60.   MODELOS DE REGRESIÓN LINEAL (Unidad 2)  Etxeberria, J. (1999). Regresión múltiple. Madrid: La Muralla. Fox, J. \u0026amp; Weisberg, S. (2011) An R Companion to Applied Regression (149-183). London: Sage. Pértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal múltiple. Cuadernos de atención primaria, 7(3), 173-176. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331162 Pértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal simple. Cuadernos de atención primaria, 7(2), 91-94. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331559 Grolemund, G. \u0026amp; Wickam, H. (2017) R for Data Science. Disponible en: https://r4ds.had.co.nz/   MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)  Silva LC, Barroso J. (2004). Regresión Logística. Cuaderno 27. Madrid: La Muralla. Silva LC. (1995). Excursión a la regresión logística en ciencias de la salud. Madrid: Díaz de Santos; 1995. Jovell, A.J. (1995). Análisis de regresión logística, Cuadernos Metodológicos del CIS. Madrid.   Links \u0026amp; otras recomendaciones  Econometrics with R    Software Usaremos R 4.0 a través de la interfaz de RStudio. También realizaremos ejercicios y prácticas online en RCloud.\n Plataformas de comunicación y discusión  Foros Ucursos En evaluación  Disqus    VARIOS  Las clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Materiales, y están desarrollados con base en Rmarkdown/XaringanRmarkdown/ Xaringan. Estos documentos no son:\n “la clase” autoexplicativos (ni aspiran a serlo) “el ppt” (ni mucho menos “la ppt”)  Políticas de participación y trato: se espera y enfatiza la participación por distintos canales disponibles. También se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo estan siendo, se solicita reportar para solucionar la situación.\n   Programación de sesiones Visitar la página de Planificación.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593784608,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/programa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/programa/","section":"","summary":"Propósito general del curso Competencias a las que contribuye el curso Sub-Competencias  Resultados de Aprendizaje Saberes / contenidos UNIDAD 1: Introducción al modelamiento de datos sociales UNIDAD 2: Regresión Lineal Simple y Múltiple UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Metodología (actualizado) Evaluación (actualizado) (detalles en pestaña Trabajos) Requisitos de aprobación Bibliografía Textos principales. MODELOS CIENTÍFICOS (Unidad 1) MODELOS DE REGRESIÓN LINEAL (Unidad 2) MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3) Links \u0026amp; otras recomendaciones  Software Plataformas de comunicación y discusión VARIOS Programación de sesiones   Propósito general del curso Al finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.","tags":null,"title":"Programa","type":"page"},{"authors":null,"categories":null,"content":" Required  Chapter 1 in Kieran Healy, Data Visualization [@Healy:2019] Chapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585881306,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"/reading/01-reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":" Required  Chapter 1 in Kieran Healy, Data Visualization [@Healy:2019] Chapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)   ","tags":null,"title":"Truth, Beauty, and Data","type":"reading"}]