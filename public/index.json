[{"authors":["JC"],"categories":null,"content":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585582766,"objectID":"9b5dd807a92ef9cf578125f1957a7629","permalink":"/authors/kjhealy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kjhealy/","section":"authors","summary":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.","tags":null,"title":"Juan Castillo","type":"authors"},{"authors":null,"categories":null,"content":"\rÍndice\r\rInstrucciones generales para las prácticas\rReportes de progreso\rNotas sobre trabajo con software R\rTutorial de instalación de R\rTutorial RCloud\r\r\r\rEsta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas\r\rLas prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 9:00 a 10:00); ver detalles en la planificación del curso.\n\rEstas sesiones acompañarán el desarrollo de las guías prácticas disponibles en este sitio.\n\rLos contenidos de las guías refieren a aplicaciones de análisis de datos de lo visto en clases la semana anterior\n\rEn las prácticas vamos a trabajar con el software R, Versión 4.0. Para su instalación consultar el video-tutorial disponible en la página de la práctica 1 (click aquí)\n\rPara poder tener una asesoría y monitoreo más cercano en el desarrollo de las guías, los estudiantes han sido divididos en grupos asignados a un/a ayudante (ver en UCursos)\n\rEl trabajo con estas guías se organiza en los siguientes momentos:\n\rcada estudiante realiza la guía de manera autónoma durante la semana correspondiente, antes de la sesión de práctica\ren caso de dudas, las realizan en los foros disponibles o se contactan directamente con su ayudante\rdurante las sesiones prácticas, cada ayudante se reunirá con su grupo de estudiantes asignado para revisar la guía paso a paso y resolver dudas\rcada semana se completa un reporte de progreso (detalles abajo) que va a ser implementado en la plataforma de UCursos\r\r\r\rReportes de progreso\rEste curso se caracteriza por el desarrollo secuencial y acumulativo de aprendizajes. En otras palabras, va a ser muy difícil poder lograr los objetivos de aprendizaje posteriores sin haber logrado los objetivos de contenidos previos. Y nuevamente en otras palabras: es muy difícil aprender a multiplicar sin saber sumar. Por lo tanto, como equipo a cargo del curso nos interesa poder monitorear permanentemente el cumplimiento de objetivos de aprendizaje semana a semana para así poder prestar asesoría oportuna.\nEl sistema de monitoreo de cumplimiento de objetivos se llevará a cabo mediante reportes de progreso. Un ejemplo de este reporte se ve así:\nLos reportes consisten en completar una encuesta simple y breve, donde se preguntará por el cumplimiento de los objetivos de las prácticas respectivas. La idea es que los puedan completar durante la semana en que se desarrolla la guía, a más tardar los días viernes.\nActualización (22/05)\n1- El primer reporte (Praćtica 1) se generó en la función Test de UCursos, pero lamentablemente la forma en que se entregan los resultados no nos permitió un análisis desagregado por pregunta, que es importante para poder monitorear distintos objetivos. Por eso, desde la práctica 2 hay disponible una encuesta formato web (Forms), a la que se accede directamente la final de la página de cada práctica.\r2- Como incentivo para completar los reportes de progreso, se entregarán dos décimas adicionales a cada evaluación para quienes tengan sus reportes completados.\n\rNotas sobre trabajo con software R\rPara los análisis estadísticos de este curso usamos el programa R, principalmente porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\rtrabajar con la misma y última versión de R, que es la 4.0\n\revitar uso de tilde, ñ, espacios y mayusculas tanto en carpetas y archivos, así como también en los nombres de las variable\n\ral momento de hacer consultas sobre problemas en la ejecución del código, adjuntar archivo con:\nCódigo completo hasta que se produce el problema\rIndicar línea del código donde se produce el problema\rAdjuntar el resultado del output de la información de la sesión (sessionInfo())\r\r\rTutorial de instalación de R\r\rPara quienes no trabajan en R constantemente, abajo un primer tutorial sobre instalación de R y RStudio, necesarios para poder desarrollar esta práctica: Actualizado a versión 4.0 \r\r\r\r\rTutorial RCloud\rRCloud permite trabajar con RStudio en línea, sin necesidad de instalar localmente. Puede ser muy útil para quienes tengan problemas de instalación, así como también para trabajo colaborativo.\n\r\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1590761707,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"Índice\r\rInstrucciones generales para las prácticas\rReportes de progreso\rNotas sobre trabajo con software R\rTutorial de instalación de R\rTutorial RCloud\r\r\r\rEsta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas\r\rLas prácticas se desarrollarán semana a semana en el horario correspondiente a cada sección (Jueves Sección 1, Viernes Sección 2, de 9:00 a 10:00); ver detalles en la planificación del curso.","tags":null,"title":"Material","type":"docs"},{"authors":null,"categories":null,"content":"\rIf I assign readings, you really should read them.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585568956,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"If I assign readings, you really should read them.","tags":null,"title":"Reading","type":"docs"},{"authors":null,"categories":null,"content":"\rAquí se accede a las distintas guías prácticas desde el menú de la izquierda\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1585568305,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"\rAquí se accede a las distintas guías prácticas desde el menú de la izquierda\r\r","tags":null,"title":"Prácticas","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593230635,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"/class/06-class/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rExplorar base de datos\rModelo de regresión simple\rRelacion entre variables\rModelo de regresión multiple\rInterpretación\rIntercepto\rCoeficientes de regresion\r\rComparando el modelo de regresión simple con múltiple\r¿Por qué utilizar R^2 ajustado?\r\rResumen Práctica 5:\rReporte de progreso\rForo práctica 5\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica nos enfocaremos en el concepto de regresión múltiple, a partir de la incorporación de dos o más predictores en el modelo. Para ello utilizaremos el ejemplo 3.1 de Wooldridge (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías\rpacman::p_load(ggpubr, #graficos\rdplyr, #manipulacion de datos\rsjPlot, #tablas\rgridExtra, #unir graficos\rtexreg, #mostrar regresion multiple\rsummarytools, #estadisticos descriptivos\rwooldridge) #paquete con los ejemplos del libro\r\rDatos\rLos datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables\r- [\\(colGPA\\)]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\r- [\\(hsGPA\\)]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\r- [\\(ACT\\)]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\rPrimero, se cargará la base de datos que contiene la librería wooldridge y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos\rgpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables\r\rExplorar base de datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026#39;render\u0026#39;))\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r## Warning in png(png_loc \u0026lt;- tempfile(fileext = \u0026quot;.png\u0026quot;), width = 150 *\r## graph.magnif, : X cannot set locale modifiers\r\rModelo de regresión simple\rSi solo nos centramos en el análisis de regresión simple, intuitivamente partiremos por predecir las calificaciones de la universidad a partir del puntaje obtenido en la prueba de admisión a esta. Formalmente\n\\[\\widehat{colGPA} = b_{0} +b_{1}ACT \\]\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) #Crear regresion simple\rsummary(col_actmodel)\r## ## Call:\r## lm(formula = colGPA ~ ACT, data = gpa1)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.85251 -0.25251 -0.04426 0.26400 0.89336 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.40298 0.26420 9.095 8.8e-16 ***\r## ACT 0.02706 0.01086 2.491 0.0139 * ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.3656 on 139 degrees of freedom\r## Multiple R-squared: 0.04275, Adjusted R-squared: 0.03586 ## F-statistic: 6.207 on 1 and 139 DF, p-value: 0.0139\rEn formato publicable:\nsjPlot::tab_model(col_actmodel, show.ci=FALSE) #Tabla resumen de resultados\r\r\rcol GPA\r\r\r\rPredictors\r\rEstimates\r\rp\r\r\r\r(Intercept)\r\r2.40\r\r\u0026lt;0.001\r\r\r\rACT\r\r0.03\r\r0.014\r\r\r\rObservations\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r\r\rEn consecuencia, nuestro modelo que relaciona el promedio de calificaciones en la universidad solo con el puntaje obtenido en el examen de admisión señala que por cada punto adicional que se obtiene en la prueba de admisión, el promedio de la universidad aumenta en 0.027 (aproximado en la tabla de sjPlot a 0.03) puntos promedio.\n\\[\\widehat{colGPA} = 2.40 +0.0271ACT \\]\nAhora bien, si miramos nuestro \\(R^2\\) notaremos que \\(ACT\\) solo explica en un 4.3% la varianza de \\(colGPA\\). Por ello, incluiremos el promedio de las calificaciones de la enseñanza media (\\(hsGPA\\)) para intentar predecir mejor el promedio general de las calificaciones en la universidad.\n\rRelacion entre variables\rSe grafican las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus respectivas regresiones simples.\n#Grafico x1 = ACT\rgact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3, # Forma y tamaño de puntos\radd = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion\rcor.coef = TRUE)# Agregar coeficiente correlacion\r#Grafico x2 = hsGPA\rghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3,\radd = \u0026quot;reg.line\u0026quot;,\rcor.coef = TRUE)\r\rgrid.arrange(gact, ghsGPA, nrow = 1) # Unir graficos\rCon el gráfico anterior podemos notar que si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\rAhora bien, ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?\n\rModelo de regresión multiple\rPara estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nGrabar / exportar tablas :Exportar tablas \rmodelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n\rcol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1)\rcol_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1)\rcol_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1)\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rPredictores\r\rβ\r\rβ\r\rβ\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\rObservations\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\r\\[\\widehat{colGPA} = 1.29 +0.0094 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n\rInterpretación\r¿Cómo se interpreta esta ecuación general de \\(colGPA\\) con dos predictores?\nIntercepto\r\rEl intercepto 1.20 indica la predicción del promedio general de calificaciones en la universidad (\\(colGPA\\)) si \\(hsGPA\\) y \\(ACT\\) son ambos cero. Este intercepto no tiene mucho significado debido a que eso implica un individuo ficticio que no haya ni asistido a la universidad ni haya asistido a la enseñanza media, por lo cual no es parte de nuestra pregunta por las determinantes del promedio en la universidad.\r\r\rCoeficientes de regresion\r\rFijémonos en los coeficientes de regresión de \\(hsGPA\\). Como era de esperar en función de los gráficos que habíamos presentado, existe una relación positiva entre \\(hsGPA\\) y \\(colGPA\\): con \\(ACT\\) constante, cada punto más en \\(hsGPA\\) se relaciona con un aumento en 0.453 puntos adicionales en \\(colGPA\\), es decir, casi medio punto.\r\rEn otras palabras, si se eligen dos estudiantes, A y B, y estos tienen la misma puntación en el exámen de admisión (\\(ACT\\)), pero el promedio en la enseñanza media de A es mayor al de B (\\(hsGPA\\)), entonces se predice que en la universidad el estudiante A tendrá un promedio general de 0.453 puntos más altos que el estudiante B.\n\rFijémonos ahora en el coeficiente de regresión de \\(ACT\\): si \\(hsGPA\\) permanece constante, un aumento en un punto de \\(ACT\\) solo produce un aumento en 0.0094 puntos en \\(colGPA\\), es decir, un cambio muy pequeño.\r\rDe hecho, un cambio de 10 puntos en el examen de admisión \\(ACT\\) tendrá un efecto sobre \\(colGPA\\) de menos de una décima de punto, es decir, menor al cambio que tiene \\(hsGPA\\). Además, la posibilidad de tener un cambio de 10 puntos en \\(ACT\\) es muy grande pues como mostramos en los estadísticos descriptivos de nuestras variables el promedio de puntaje en \\(colGPA\\) es 24 puntos con una desviación estándar de 2.8, lo que hace poco posible ese cambio en la realidad.\nCon esto podemos decir que el puntaje en el examen de admisión \\(ACT\\) no es un fuerte predictor del promedio de calificaciones en la universidad \\(colGPA\\).\n\r\rComparando el modelo de regresión simple con múltiple\rIniciamos este práctico mostrando un análisis de regresión simple con un predictor para el promedio de calificaciones en la universidad: el promedio en el examen de admisión (\\(ACT\\)).\nObtuvimos que por cada punto de aumento de \\(ACT\\), \\(colGPA\\) aumentaba en 0.0271 puntos sus calificaciones, es decir, casi el triple de lo que fue estimado en el modelo de regresión múltiple (tal como se señala en Modelo 1)\n¿Cuál de los dos modelos es más certero?\nEsto lo podemos definir a partir de la bondad de ajuste de nuestros modelos. Por un lado, el \\(R^2\\) del modelo 1 es de 4.3% mientras que en el modelo 3 el \\(R^2ajustado\\) es de 16%, es decir, las variables que se contienen en el modelo explican más la varianza de nuestra variable dependiente.\n\r¿Por qué utilizar R^2 ajustado?\rHasta ahora habíamos utilizado \\(R^2\\) que nos señalaba qué porcentaje de la variación de la variable dependiente es explicada por la variable independiente.\nAhora bien, es esperable que a medida que añadimos más variables a una regresión, el \\(R^2\\) tiende a aumentar a pesar de que la contribución de cada una de las variables nuevas no tenga relevancia estadística.\nPor ello, el \\(R^2\\) ajustado se utiliza en la regresión múltiple para analizar en conjunto la intensidad que tienen las variables independientes en explicar la variable dependiente. Es decir, el \\(R^2\\) ajustado nos dice qué porcentaje de variación de la variable dependiente es explicado colectivamente por todas las variables independientes.\nEn consecuencia, \\(R^2\\) ajustado nos permite determinar mejor si añadir una nueva variable al modelo permite explicar una mayor parte de la variación de la variable dependientE.\nEn el ejercicio anterior bien podemos hacer este análisis comparando los \\(R^2\\) de nuestros modelos 1 y 2 para luego mirar el resultado de nuestro \\(R^2\\) ajustado en nuestro modelo 3. Como podremos notar el \\(R^2\\) del modelo 2 es de 17%, mientras que el \\(R^2\\) es de 18% y el \\(R^2\\) ajustado de 16%.\nEn palabras más simples, si solo miramos el \\(R^2\\) llegaremos a la conclusión de que aunque por mínimo que sea, nuestro modelo 3 ajusta mejor que el modelo 2 pues la variable \\(ACT\\) permitiría predecir mejor \\(colGPA\\) en conjunto a \\(hsGPA\\). Sin embargo, \\(R^2 ajustado\\) del modelo 3 (16%) es menor que la del modelo 2 (17%) por lo que la incorporación de \\(ACT\\) al modelo múltiple no tiene un aporte significativo.\nDe hecho, un punto no menor es que \\(ACT\\) pierde significancia estadística en el modelo 3, mientras que \\(hsGPA\\) sigue siendo significativa con un 99% confianza (la significancia estadística lo revisaremos más adelante).\n\r\rResumen Práctica 5:\rEn esta práctica revisamos los siguientes contenidos\n\rRepaso de regresión lineal simple\rEstimación de regresión lineal múltiple\rInterpretar regresión lineal múltiple\rComparar regresión múltiple y simple\rDiferencia entre \\(R^2\\) ajustado y \\(R^2\\)\r\r\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí.\n\rForo práctica 5\r\r","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592791125,"objectID":"e933840b45d355c28b7bb0057d254a85","permalink":"/assignment/05-code/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/assignment/05-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 5. Regresión múltiple 1 ","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rExplorar base de datos\rRelacion entre variables\rModelo de regresión multiple\rInterpretación\r¿Porqué se alteran los coeficientes de correlación?\r\rParcialización\rParcializar \\(ACT\\) de \\(hsGPA\\)\r\rControl estadístico\r¿Qué significa mantener todos los demás factores constantes?\r\rResumen Práctica 6:\rReporte de progreso\rArchivo de código\rForo práctica 6\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica nos enfocaremos en el significado de las parcializaciones en la regresión múltiple. Para ello utilizaremos el ejemplo 3.1 de Wooldrige (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías\rpacman::p_load(ggpubr, #graficos\rdplyr, #manipulacion de datos\rsjPlot, #tablas\rgridExtra, #unir graficos\rtexreg, #mostrar regresion multiple\rsummarytools, #estadisticos descriptivos\rwooldrige) #paquete con los ejemplos del libro\rlibrary(wooldridge)\r\rDatos\rLos datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables\r- [\\(colGPA\\)]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\r- [\\(hsGPA\\)]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\r- [\\(ACT\\)]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\nPrimero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos\rgpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables\r\rExplorar base de datos\rA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026#39;render\u0026#39;))\r\rRelacion entre variables\rSe grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n#Grafico x1 = ACT y= colGPA\rgact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3, # Forma y tamaño de puntos\radd = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion\rcor.coef = TRUE)# Agregar coeficiente correlacion\r#Grafico x2 = hsGPA y= colGPA\rghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,\rshape = 21, size = 3, \radd = \u0026quot;reg.line\u0026quot;, \rcor.coef = TRUE)\r\r#Grafico x2 = hsGPA x1 = ACT\rgact_hs \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;ACT\u0026quot;,\rshape = 21, size = 3, \radd = \u0026quot;reg.line\u0026quot;, \rcor.coef = TRUE)\r\rgrid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos\rCon el gráfico anterior podemos notar dos puntos relevantes:\r- Si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\r- Como es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\nEn la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo\n\rModelo de regresión multiple\rPara estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nGrabar / exportar tablas :Exportar tablas \rmodelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n\rcol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1)\rcol_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1)\rcol_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1)\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\r\r\rPredictores\r\rß\r\rß\r\rß\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\rObservations\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\r\\[\\widehat{colGPA} = 1.29 +0.0094 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n\rInterpretación\r¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante\rPor otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n¿Porqué se alteran los coeficientes de correlación?\rComo vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).\n\r\rParcialización\rLa forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en compun \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{2}\\triangle{hsGPA} \\]\nParcializar \\(ACT\\) de \\(hsGPA\\)\r¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado po \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\nPaso 1: Estimar modelo\rmodel_act_hs =lm(ACT ~hsGPA, data = gpa1) #Crear regresion con predictores\rcoef(model_act_hs)\r## (Intercept) hsGPA ## 13.696763 3.074331\rEn consecuencia tenemos que\r\\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\r#### Paso 2: calcular valores predichos y residuos\nSabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos\rres_act_hs=residuals(model_act_hs) #Calcular residuos\rgpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos\rhead(gpa1) #Mostrar los primeros elementos de la base de datos\r## colGPA hsGPA ACT fit_act_hs res_act_hs\r## 1 3.0 3.0 21 22.91975 -1.9197550\r## 2 3.4 3.2 24 23.53462 0.4653787\r## 3 3.0 3.6 26 24.76435 1.2356469\r## 4 3.5 3.5 27 24.45692 2.5430797\r## 5 3.6 3.9 28 25.68665 2.3133472\r## 6 3.0 3.4 25 24.14949 0.8505125\rPodemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n\rPaso 3: Crear regresión con variable parcializada\rAhora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\nact_hs_model \u0026lt;-lm(colGPA ~res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT\rsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)\r\r\rModelo 1\r\rModelo 2\r\rModelo 3\r\rModelo 4\r\r\r\rPredictores\r\rß\r\rß\r\rß\r\rß\r\r\r\r(Intercept)\r\r2.40 ***\r\r1.42 ***\r\r1.29 ***\r\r3.06 ***\r\r\r\rACT\r\r0.03 *\r\r\r0.01 \r\r\r\r\rhsGPA\r\r\r0.48 ***\r\r0.45 ***\r\r\r\r\rres_act_hs\r\r\r\r\r0.01 \r\r\r\rObservations\r\r141\r\r141\r\r141\r\r141\r\r\r\rR2 / R2 adjusted\r\r0.043 / 0.036\r\r0.172 / 0.166\r\r0.176 / 0.164\r\r0.005 / -0.003\r\r\r\r\rp\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001\r\r\r\r\rLo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.\n\r\r\rControl estadístico\r¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\nplot_model(col_model, show.values = TRUE)+theme_sjplot()\rComo podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de a qué variable poner ojo: el centro está en las hipótesis que queremos probar con nuestros modelos.\n\r¿Qué significa mantener todos los demás factores constantes?\rEn la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recoltados de manera constante. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\).\rMás bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.\n\r\rResumen Práctica 6:\rEn esta práctica revisamos los siguientes contenidos\r- Repaso de regresión lineal múltiple\r- Parcialización\r- Control estadístico\n\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica [aquí]\n\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar [aquí]\n\rForo práctica 6\r\r","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592524800,"objectID":"c721292a113c2490ec6624b75af80b46","permalink":"/assignment/06-code/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/assignment/06-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 6. Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592524913,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"/class/05-class/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión múltiple 1","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590861193,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"/class/04-class/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de la clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de la clase\r\r\r\rLecturas\rMoore: Residuos (144-154)\n\r","tags":null,"title":"Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rLibrerías\rDatos\rResiduos\rModelo y cálculo de parámetros\rBondad de Ajuste: Residuos y \\(R^{2}\\)\rSuma de cuadrados y \\(R^{2}\\)\rVisualización\rEl coeficiente de Regresión versus el coeficiente de correlación\rReporte de progreso\rForo\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rBasados en el cálculo de parámetros del modelo de regresión en la práctica anterior (intercepto y coeficiente de regresión o pendiente), en esta práctica nos abocamos a temas de ajuste, residuos y relación entre correlación y regresión. La práctica está basada en el ejemplo de Darlington \u0026amp; Hayes cap. 2 (The simple regression model), que utilizamos en clases.\n\rLibrerías\rpacman::p_load(stargazer, ggplot2, dplyr,webshot)\r\rDatos\rLos datos a utilizar son los mismos que los de la práctica 3, corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego: el número de veces que se ha jugado antes (X) y el número de puntos ganados (Y).\ndatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\rdatos\r## id juegos_x puntos_y\r## 1 1 0 2\r## 2 2 0 3\r## 3 3 1 2\r## 4 4 1 3\r## 5 5 1 4\r## 6 6 2 2\r## 7 7 2 3\r## 8 8 2 4\r## 9 9 2 5\r## 10 10 3 2\r## 11 11 3 3\r## 12 12 3 4\r## 13 13 3 5\r## 14 14 3 6\r## 15 15 4 3\r## 16 16 4 4\r## 17 17 4 5\r## 18 18 4 6\r## 19 19 5 4\r## 20 20 5 5\r## 21 21 5 6\r## 22 22 6 5\r## 23 23 6 6\rTambién desde esta misma dirección web se pueden bajar los datos y llamarlos localmente\nDirectorio de trabajo :Directorio de trabajo \nPara el trabajo de análisis de datos se recomienda establecer claramente el directorio de trabajo, es decir, la carpeta que contiene los archivos de datos, los códigos y los resultados. Esta carpeta es el lugar donde uno se posiciona para hacer los análisis, llamar otros archivos y exportar archivos.\nPara esto, varias opciones:\n\ren RStudio, Session \u0026gt; Set Working Directory \u0026gt; Choose Directory\ro también vía consola con el comando setwd(ruta-hacia-la-carpeta-local)\r\rSi se quiere verificar en qué carpeta se está trabajando, comando getwd()\nCon esto entonces, si los datos están guardados en la misma carpeta, entonces se llaman simplemente datos \u0026lt;- read.csv(\"tacataca.txt\", sep=\"\"). No se requiere dar la ruta completa justamente porque el programa ya sabe dónde uno está posicionado. Asimísmo, al momento de guardar/exportar algún resultado, automáticamente quedará en la carpeta de trabajo.\n\rRecordando la distribución de los datos y la recta de regresión:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point() +\rgeom_smooth(method=lm, se=FALSE)\rg2\rGrabar / exportar gráficos :Exportar gráficos \rSi se quiere grabar un gráfico para luego utilizarlo en algún documento fuera del entorno R, algunas alternativas:\n\rutilizar la función ggsave (para gráficos ggplot)\r\rggsave(\u0026quot;g2.png\u0026quot;, g2)\r\rmás genéricamente, para guardar como imagen cualquier cosa que aparece en el visor de RStudio:\r\rpng(file = \u0026quot;g2.png\u0026quot;) # se abre un archivo vacío\rg2 # se genera el gráfico a guardar en el archivo\rdev.off() # se cierra el archivo\r\rEl gráfico quedará grabado en el directorio de trabajo (ver arriba). Si se desea que se grabe en otra parte, dar la ruta completa hacia la carpeta correspondiente (“C:/[ruta-hacia-carpeta]/g2.png”)\n\r\rResiduos\rEn el gráfico anterior vemos que la línea resume la relación entre X e Y que se denomina recta de regresión, caracterizada por un intercepto y una pendiente.\nClaramente, esta recta es una simplificación que no abarca toda la variabilidad de los datos. Por ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exactamente su puntaje basado en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje.\nLo anterior tiene que ver con el concepto de residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\). Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina suma de residuos al cuadrado o \\(SS_{residual}\\) ya que como hay residuos positivos y negativos unos se cancelan a otros y la suma es 0. De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: residuos cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\rModelo y cálculo de parámetros\rComo vimos la práctica anterior, el modelo de regresión entonces se relaciona con una ecuación de la recta, o recta de regresión, que se puede definir en términos simples de la siguiente manera:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos)\rreg1\r## ## Call:\r## lm(formula = puntos_y ~ juegos_x, data = datos)\r## ## Coefficients:\r## (Intercept) juegos_x ## 2.5 0.5\rPodemos generar una tabla en un formato más publicable:\nstargazer(reg1, type=\u0026quot;text\u0026quot;)\r## ## ===============================================\r## Dependent variable: ## ---------------------------\r## puntos_y ## -----------------------------------------------\r## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## -----------------------------------------------\r## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## ===============================================\r## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01\rTambién es posible generar una tabla más resumida en formato publicable y visible en RStudio:\nsjPlot::tab_model(reg1, show.ci=FALSE)\r\r\rpuntos y\r\r\r\rPredictors\r\rEstimates\r\rp\r\r\r\r(Intercept)\r\r2.50\r\r\u0026lt;0.001\r\r\r\rjuegos_x\r\r0.50\r\r0.001\r\r\r\rObservations\r\r23\r\r\r\rR2 / R2 adjusted\r\r0.405 / 0.376\r\r\r\rGrabar / exportar tablas :Exportar tablas \nMuchas de las tablas producidas con R son en formato html, es decir, archivos para ser publicados en formato web. Por lo tanto, en general las tablas se graban primero como html, y luego se convierten a formato imagen con la librería webshot.\nPara tablas generadas con stargazer\nstargazer(reg1, type=\u0026quot;html\u0026quot;, out = \u0026quot;reg1.html\u0026quot;)\rwebshot(\u0026quot;reg1.html\u0026quot;,\u0026quot;reg1.png\u0026quot;)\rAlternativamente, para tablas de regresión con sjPlot:\nsjPlot::tab_model(reg1, show.ci=FALSE, file = \u0026quot;reg1_tab.html\u0026quot;)\rwebshot(\u0026quot;reg1_tab.html\u0026quot;,\u0026quot;reg1_tab.png\u0026quot;)\r\r\r\rBondad de Ajuste: Residuos y \\(R^{2}\\)\rA partir del método de Mínimos Cuadrados Ordinarios obtenemos una recta que describe un conjunto de datos minimizando las diferencias entre el modelo y la distribución de los datos mismos.\nNo obstante, incluso cuando se ajusta el mejor modelo siempre existirá un grado de imprecisión, representado por las diferencias entre los datos observados y los valores predichos por la recta de regresión.\nLa precisión de nuestro modelo se relaciona con el concepto de Bondad de Ajuste, y se evalúa a partir del estadístico \\(R^2\\).\nEn el siguiente apartado se puede observar la manera de calcular la predicción de Y (puntos_y) en base a X (juegos_x), y almacenarlos en la base de datos, con los respectivos residuos.\n#summary(lm(puntos_y~juegos_x, data=datos))\r#beta=0.5 intercepto=2.5\r\r#Variable de valores predichos\rdatos$estimado\u0026lt;-(2.5 +datos$juegos_x*0.5)\r\r# Alternativa por comando\r#datos$estimado \u0026lt;- predict(reg1)\r\r#Estimamos el residuo\rdatos$residuo \u0026lt;-datos$puntos_y -datos$estimado\r\r# Alternativa por comando\r#datos$residuo \u0026lt;- residuals(reg1)\r\rdatos %\u0026gt;%select(id, estimado, residuo)\r## id estimado residuo\r## 1 1 2.5 -0.5\r## 2 2 2.5 0.5\r## 3 3 3.0 -1.0\r## 4 4 3.0 0.0\r## 5 5 3.0 1.0\r## 6 6 3.5 -1.5\r## 7 7 3.5 -0.5\r## 8 8 3.5 0.5\r## 9 9 3.5 1.5\r## 10 10 4.0 -2.0\r## 11 11 4.0 -1.0\r## 12 12 4.0 0.0\r## 13 13 4.0 1.0\r## 14 14 4.0 2.0\r## 15 15 4.5 -1.5\r## 16 16 4.5 -0.5\r## 17 17 4.5 0.5\r## 18 18 4.5 1.5\r## 19 19 5.0 -1.0\r## 20 20 5.0 0.0\r## 21 21 5.0 1.0\r## 22 22 5.5 -0.5\r## 23 23 5.5 0.5\r\rSuma de cuadrados y \\(R^{2}\\)\rUsando la media como modelo podemos calcular las diferencias entre los valores observados y los valores predichos por la media.\n\rSuma Total de Cuadrados: La suma de las diferencias del promedio de Y al cuadrado (asociado al concepto de varianza de Y)\r\r\\[SS_{tot} = \\sum(y-\\bar{y})^2 \\]\rY calculamos\nss_tot\u0026lt;-sum((datos$puntos_y-mean(datos$puntos_y))^2); ss_tot\r## [1] 42\r\rSuma de cuadrados de la regresión: se refiere a la suma de diferencias (al cuadrado) entre el valor estimado por el modelo de regresión y la media. Expresa cuanto de la varianza de Y alcanzamos a predecir con X\r\r\\[SS_{reg} = \\sum(\\hat{y}-\\bar{y})^2\\]\nss_reg\u0026lt;-sum((datos$estimado-mean(datos$puntos_y))^2) ; ss_reg\r## [1] 17\r\rSuma de residuos al cuadrado: al contrario de el cálculo anterior, los residuos representan la parte de la varianza de Y que no alcanzamos a abarcar con nuestro modelo de regresión. Es decir, reprsentan el error en la predicción (diferencia entre lo estimado por el modelo y el valor observado)\r\r\\[SS_{error} = \\sum(y-\\hat{y})^2\\]\nss_err\u0026lt;-sum((datos$puntos_y -datos$estimado)^2);ss_err\r## [1] 25\rA partir de las sumas de cuadrados anteriores es posible calcular el estadístico \\(R^{2}\\)\n\\[R^2=\\frac{SS_{reg}}{SS_{tot}}= 1- \\frac{SS_{error}}{SS_{tot}}\\]\n#Opción 1\rss_reg/ss_tot\r## [1] 0.4047619\r#Opción 2\r1-ss_err/ss_tot\r## [1] 0.4047619\r#por comando\rsummary(lm(puntos_y~juegos_x, data=datos))$r.squared\r## [1] 0.4047619\r\rVisualización\rEn la siguiente sección se presentan distintas formas de visualizar los residuos a partir del paquete ggplot2.\n#Visualizacion\rlibrary(ggplot2)\r\rggplot(datos, aes(x=juegos_x, y=puntos_y))+\rgeom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion\rgeom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas\rgeom_point() +#Capa 1\rgeom_point(aes(y=estimado), shape =1) +\rtheme_bw()\rEn esta segunda opción, se agrega tamaño y color a los residuos mayores:\nggplot(datos, aes(x=juegos_x, y=puntos_y))+\rgeom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion\rgeom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas\rgeom_point(aes(color = abs(residuo), size = abs(residuo))) +\rscale_color_continuous(low = \u0026quot;black\u0026quot;, high = \u0026quot;red\u0026quot;) +\rguides(color = FALSE, size = FALSE) +\rgeom_point(aes(y=estimado), shape =1) +\rtheme_bw()\r\rEl coeficiente de Regresión versus el coeficiente de correlación\rTanto \\(r_{xy}\\) y \\(\\beta_1\\) son medidas de la relación entre X e Y. Ellas estan relacionadas con la formula de:\n\\[\\beta_1= r_{xy}(S_y/S_x)\\]\nEs decir:\nbeta\u0026lt;-cor(datos$juegos_x,datos$puntos_y)*(sd(datos$puntos_y)/sd(datos$juegos_x));beta\r## [1] 0.5\rreg1$coefficients[2] #llamamos al coeficiente beta (en posición 2) en el objeto reg1\r## juegos_x ## 0.5\rDel mismo modo existe una relación entre \\(r_{xy}\\) y \\(R^2\\)\n#Correlación (Pearson) entre juegos_x y puntos_y (r)\rcor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\r#Correlación entre juegos_x y puntos_y al cuadrado.\r(cor(datos$juegos_x,datos$puntos_y))^2\r## [1] 0.4047619\rLa correlación entre X e Y es la misma que entre Y e X,\ncor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\rcor(datos$puntos_y,datos$juegos_x)\r## [1] 0.636209\r… mientras la regresión entre X e Y no es la misma que entre Y e X\nlm(datos$puntos_y~datos$juegos_x)$coefficients\r## (Intercept) datos$juegos_x ## 2.5 0.5\rlm(datos$juegos_x~datos$puntos_y)$coefficients\r## (Intercept) datos$puntos_y ## -0.2380952 0.8095238\r\rReporte de progreso\rCompletar el reporte de progreso aquí.\n\rForo\r\r","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590853802,"objectID":"0b905da0b361a42246b0f7d03e970a84","permalink":"/assignment/04-code/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/assignment/04-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 4. Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rSobre hoja de código\rLibrerías\rDatos\rVerificación y descriptivos\rExperiencia en juegos y puntuación\rMedias condicionales\rResiduos\rModelo de regresión y cálculo de parámetros\rCálculo de los parámetros del modelo de regresión\r\rEstimación del modelo de regresión simple en R\rReporte de progreso\rArchivo de código\rForo práctica 3\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEn esta práctica se desarrollan ejercicios iniciales de regresión simple, que fueron presentados en la clase respectiva. El ejemplo a utilizar es del libro de Darlington \u0026amp; Hayes cap. 2 (The simple regression model).\n\rSobre hoja de código\rComo vimos en la práctica anterior, al momento de analizar los datos separamos el trabajo en dos hojas de código distintas: preparacion.R (práctica 1) y analisis.R (práctica 2). Recordar nombres de archivos y directorios sin tildes, espacios ni ñEn este caso, los datos son simples y como es un ejemplo no realizaremos código de preparación, solo el correspondiente a análisis. Antes de comenzar, sugerimos crear un archivo de código en R con el nombre analisis: R: File-\u0026gt; New File -\u0026gt; RScript, o simplemente Ctrl + Shift + N.\n\rLibrerías\rpacman::p_load(stargazer, ggplot2, dplyr)\r\rDatos\rLos datos a utilizar corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego (originalmente de mini-golf en el texto de referencia … pero pensemos en un ejemplo más cercano, de taca-taca). Las dos variables de esta base de datos son el número de veces que se ha jugado antes (juegos_x) y el número de goles o puntos ganados (puntos_y). El archivo de datos es tacataca.txt.\nVamos a cargar estos datos en nuestro espacio de trabajo en R dándole el nombre simple de datos Dos opciones de cargar los datos en R:\n\rbajarlos al computador local desde este link y luego llamarlos desde el directorio respectivo donde se guardaron:\r\rdatos \u0026lt;-read.csv(\u0026quot;( ...ruta hacia el archivo ...)\\tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\r\rllamarlos directamente desde su ubicación en la web:\r\rdatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)\rComo es un archivo de texto simple (txt), los cargamos con la función read.csv, para datos guardados en texto simple separados por coma. Como en el caso de nuestros datos la separación es por espacios en lugar de comas, agregamos esta información con la instrucción sep=\"\"\rPara abrirlos datos recordemos que en la lógica de R se debe generar un objeto donde se guardan los datos. Este objeto puede tener cualquier nombre, en este caso lo llamaremos simplemente “datos”.\nRutas: ¿Cómo identifico la ruta hacia mi archivo? Dos maneras:\n\rBotón derecho sobre el archivo -\u0026gt; propiedades, ahí aparece la ruta completa. Copiar y pegar donde corresponde en el archivo de R, no olvidar agregar al final el nombre completo del archivo.\r\rMás fácil: mouse sobre archivo, boton derecho, copiar (o ctrl+c); luego, en el archivo de R, en el lugar que corresponde dar la ruta pegar (o ctrl+v)\r\r\r\rVerificación y descriptivos\rVerificamos si los datos fueron correctamente cargados:\nView(datos)\rTenemos entonces tres columnas:}\n\rid: número único que identifica a cada sujeto\n\rjuegos_x: número de veces que ha jugado previamente\n\rpuntos_y: numero de puntos que obtuvo en el juego actual\n\r\rGeneramos una tabla de descriptivos básicos con lo aprendido en la práctica de descripción de datos:\nY para publicar, usando la librería stargazer\nstargazer(datos, type = \u0026quot;text\u0026quot;)\r## ## ======================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max\r## ------------------------------------------------------\r## id 23 12.000 6.782 1 6.5 17.5 23 ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## ------------------------------------------------------\rEn la tabla vemos los estadísticos básicos de las variables juegos y puntos, y además aparece la variable id, que es el identificador y por lo tanto no tiene sentido que salga en la tabla. Para corregir, seleccionamos las variables de interés de datos con el operador pipa %\u0026gt;% operador pipa %\u0026gt;%. Este operador permite unir distintas funciones en una misma línea de código, y es muy utilizado por librerías de manejo de datos como dplyr. Por ejemplo, ahora la instrucción es “de la base de datos datos” %\u0026gt;% “selecciona solo las columnas juegos y puntos”:\nstargazer(datos %\u0026gt;%select(juegos_x,puntos_y) , type = \u0026quot;text\u0026quot;)\r## ## =====================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max\r## -----------------------------------------------------\r## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## -----------------------------------------------------\r\rExperiencia en juegos y puntuación\rLa pregunta que nos hacemos para este ejercicio de demostración es: ¿tiene relación la experiencia previa (juegos jugados previamente) con el desempeño actual (puntos obtenidos)?\nVeamos un gráfico de nube de puntos / scatter de ambas variables. Para eso, primero cargamos la librería ggplotde R. Recordar que hay que instalarla primero si es que no se ha hecho previamente con install.packages(\"ggplot\")ggplot.\ng=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point()\rg\rPrimero, sobre librerías y visualización: lo que hicimos fue crear un objeto gráfico scatterplot g con la librería ggplot..\nEn términos de correlación se observa una posible asociación positiva, que podemos corroborar con la función cor:\ncor(datos$juegos_x,datos$puntos_y)\r## [1] 0.636209\rTenemos una correlación positiva (dirección de la relación) y de un tamaño de efecto grande (magnitud de la relación), para ciencias sociales. Es decir, existe una asociación positiva entre ambas variables: a medida que aumenta la experiencia en juegos, aumentan también los puntos obtenidos en el partido de taca taca. Ahora bien, ¿cómo se relaciona más específcamente la experiencia en juegos con los puntos obtenidos posteriormente?\n\rMedias condicionales\rAntes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nComo sabemos el promedio de Y (puntos) es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Como lo conocemos, si el sujeto nos dice que ha jugado antes 6 veces, dada la información que conocemos probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) +\rgeom_point() +\rgeom_smooth(method=lm, se=FALSE)\rg2\r\rResiduos\rEn el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n\rPara realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\n\rDe la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\r\r\rModelo de regresión y cálculo de parámetros\rEl nombre regresión hace alusión a investigaciones sobre estaturas de padres e hij_s en el S.XIX. La estatura de hij_s de padres muy altos es en promedio menor, y si sus padres son baj_s, es mayor (en comparación con sus padres). Este fenómeno se conoce como “regresión hacia el promedio” \nEl modelo de regresión se representa con una ecuación de la recta, o recta de regresión. Esta recta representa los valores predichos para Y según los distintos valores de X:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nDonde\n\r\\(\\widehat{Y}\\) es el valor estimado/predicho de \\(Y\\)\r\\(b_{0}\\) es el intercepto de la recta (el valor de Y cuando X es 0)\r\\(b_{1}\\) es el coeficiente de regresión, que nos dice cuánto aumenta Y por cada punto que aumenta X (pendiente)\r\r\rCálculo de los parámetros del modelo de regresión\r\\(b_{1}\\), o comunmente llamado “beta de regresión” se obtiene de la siguiente manera:\n\\[b_{1}=\\frac{Cov(XY)}{VarX}\\]\rEn términos más suntantivos se puede entender como qué parte de la covariación que hay entre X e Y se relaciona con (la varianza de) X. Especificando la fórmula:\n\\[b_{1}=\\frac{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {n-1}}{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} {n-1}}\\]\rY simplificando\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}\\]\nComo sabemos, la base para todos estos cálculos es el valor de cada variable menos su promedio. Vamos a crear un vector en nuestra base de datos difx=\\(x-\\bar{x}\\) y dify=\\(y-\\bar{y}\\)\ndatos$difx=datos$juegos_x-mean(datos$juegos_x)\rdatos$dify=datos$puntos_y-mean(datos$puntos_y)\rY ahora con esto podemos obtener la diferencia de productos cruzados dif_cru=\\((x-\\bar{x})*(y-\\bar{y})\\), así como la diferencia de X de su promedio al cuadrado SSx=\\((x-\\bar{x})^2\\)\ndatos$difcru=datos$difx*datos$dify\rdatos$difx2=datos$difx^2\rdatos\r## id juegos_x puntos_y difx dify difcru difx2\r## 1 1 0 2 -3 -2 6 9\r## 2 2 0 3 -3 -1 3 9\r## 3 3 1 2 -2 -2 4 4\r## 4 4 1 3 -2 -1 2 4\r## 5 5 1 4 -2 0 0 4\r## 6 6 2 2 -1 -2 2 1\r## 7 7 2 3 -1 -1 1 1\r## 8 8 2 4 -1 0 0 1\r## 9 9 2 5 -1 1 -1 1\r## 10 10 3 2 0 -2 0 0\r## 11 11 3 3 0 -1 0 0\r## 12 12 3 4 0 0 0 0\r## 13 13 3 5 0 1 0 0\r## 14 14 3 6 0 2 0 0\r## 15 15 4 3 1 -1 -1 1\r## 16 16 4 4 1 0 0 1\r## 17 17 4 5 1 1 1 1\r## 18 18 4 6 1 2 2 1\r## 19 19 5 4 2 0 0 4\r## 20 20 5 5 2 1 2 4\r## 21 21 5 6 2 2 4 4\r## 22 22 6 5 3 1 3 9\r## 23 23 6 6 3 2 6 9\rY con esto podemos obtener la suma de productos cruzados y la suma de cuadrados de X\nsum(datos$difcru)\r## [1] 34\rsum(datos$difx2)\r## [1] 68\rReemplazando en la fórmula\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}=\\frac{34}{68}=0.5\\]\nY con esto podemos obtener el valor de \\(b_{0}\\)\n\\[b_{0}=\\bar{Y}-b_{1}\\bar{X}\\]\r\\[b_{0}=4-(3 * 0.5)=2.5\\]\nCompletando la ecuación:\n\\[\\bar{Y}=2.5+0.5X\\]\nEsto nos permite estimar el valor de \\(Y\\) (o su media condicional) basado en el puntaje \\(X\\).\rPor ejemplo, cuál es el valor estimado de \\(Y\\) dado \\(X=5\\)?\n\r\rEstimación del modelo de regresión simple en R\rLa función para estimar regresión en R es lm (linear model). Su forma general es:\nobjeto=lm(dependiente ~ independiente, data=datos)\rDonde\n\robjeto: el nombre (cualquiera) que le damos al objeto donde se guardan los resultados de la estimación\rdependiente / independiente: los nombres de las variables en los datos\rdata = el nombre del objeto de nuestros datos en R\r\rEjemplo con los datos de taca taca:\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos)\rCon esta operación ya estimamos nuestra primera regresión simple. Para ver la estimación de los parámetros principales (intercepto y pendiente) simplemente ejecutamos el nombre del objeto:\nreg1\r## ## Call:\r## lm(formula = puntos_y ~ juegos_x, data = datos)\r## ## Coefficients:\r## (Intercept) juegos_x ## 2.5 0.5\rY obtenemos los valores que calculamos previamente.\nPodemos tener un output en un formato más apropiado utilizando la librería stargazer\nstargazer(reg1, type = \u0026quot;text\u0026quot;)\r## ## ===============================================\r## Dependent variable: ## ---------------------------\r## puntos_y ## -----------------------------------------------\r## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## -----------------------------------------------\r## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## ===============================================\r## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01\rVemos que en la tabla aparecen una serie de elementos adicionales, además de \\(b_{1}\\) (juegos) y el intercepto o constante (“Constant”). Esto será tema de la siguiente sesión.\n\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí\n\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo práctica 3\r\r","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"0c86205acf7811fbfe8648206a8418ff","permalink":"/assignment/03-code/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/assignment/03-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 3. Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rEste video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n\r\r\rLecturas\r\rLinares (2018) La explicación en sociología\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586906392,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"/class/01-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rEste video es una edición de la clase efectuada vía Zoom el día viernes 3 de Abril \n\r\r\rLecturas\r\rLinares (2018) La explicación en sociología\r\r\r","tags":null,"title":"Presentación","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rPróximamente aquí \r---\r\r\r\rLecturas\r\rMoore: 1.Comprensión de los datos (1-54)\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589647555,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"/class/02-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\rPróximamente aquí \r---\r\r\r\rLecturas\r\rMoore: 1.Comprensión de los datos (1-54)\r\r\r","tags":null,"title":"Bases","type":"docs"},{"authors":null,"categories":null,"content":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\r\r\r\rLecturas\r\rMoore: 2. Análisis de relaciones (97-131)\r\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590425049,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"/class/03-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":"\rÍndice\r\rDocumento presentación\rVideo de clase\rLecturas\r\r\rDocumento presentación\rPara ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n\r\rVideo de clase\r\r\r\rLecturas\r\rMoore: 2. Análisis de relaciones (97-131)\r\r\r","tags":null,"title":"Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rPresentación\rObjetivo de la práctica\rAntecedentes de los datos a utilizar\rVideo - Tutoriales\r\rPreparación de datos ELSOC 2016\r1. Librerías principales (de R) a utilizar en el análisis\r2. Cargar base de datos\r3. Selección de variables a utilizar\r4. Procesamiento de variables\r4.1 Percepción de meritocracia\r4.3. Estatus subjetivo\r4.4. Sexo\r4.5 Edad\r\r5. Generación de base de datos procesada para el análisis\r\rArchivo de código\rForo\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rPresentación\rObjetivo de la práctica\rEl desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nEn este curso vamos a distinguir dos momentos del trabajo con datos: procesamiento y análisis.\n\rPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos procesados.\n\rAnálisis: se relaciona principalmente con análisis descriptivos asociados a las preguntas de investigación y también modelamiento de datos para contrastar hipótesis de investigación.\n\r\rLos procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema:\rTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados en un documento de código, en este caso de código RArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: menú File \u0026gt; Save, y darle nombre (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\rLibrerías: cargar librerías a utilizar\rDatos: carga de datos\rSelección de variables a utilizar\rProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\rDescriptivo\rRecodificación: (datos perdidos y valores (en caso de ser necesario)\rEtiquetamiento: de variable y valores (en caso de ser necesario)\rOtros ajustes\r\rGeneración de base de datos procesada para el análisis.\r\rAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de meritocracia y estatus (objetivo y subjetivo) utilizando los datos de la encuesta ELSOC .\n\r\rAntecedentes de los datos a utilizar\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar longitudinalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades. Para ello, junto con variables de meritocracia, consideraremos también variables de estatus (educación y estatus subjetivo), y variables de caracterización sociodemográfica (sexo y edad).\n\rVideo - Tutoriales\r\rSi se requiere instalar R, ir al siguiente tutorial en la página de descripción del uso de R en las prácticas haciendo click aquí.\n\rTambién se agrega un segundo tutorial con instrucciones paso a paso para poder comenzar a realizar esta Práctica 1 usando RStudio:\n\r\r\r\r\r\rPreparación de datos ELSOC 2016\r1. Librerías principales (de R) a utilizar en el análisis\rComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\ninstall.packages(\u0026quot;pacman\u0026quot;)\rY en adelante, las librerías se cargan así:\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer)\rPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\rdplyr: ajuste general de datos\rsjmisc: descripción y exploración de base de datos\rcar: principalmente la función recode para recodificar/agrupar valores de variable\rstargazer: para tabla descriptiva\r\r\r2. Cargar base de datos\rAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\nrm(list=ls()) # borrar todos los objetos en el espacio de trabajo\roptions(scipen=999) # valores sin notación científica\rLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: ELSOC_W01_v3.10.RData.\n#cargamos la base de datos desde internet\rload(url(\u0026quot;https://multivariada.netlify.com/assignment/data/original/ELSOC_W01_v3.10.RData\u0026quot;))\rLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 2927 casos y 383 variables).\ndim(elsoc_2016) # dimension de la base\r## [1] 2927 383\rY si se quiere revisar en formato de planilla de datos:\nView(elsoc_2016)\r\r3. Selección de variables a utilizar\rEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto esfuerzo:\r\rfind_var(data = elsoc_2016,\u0026quot;esfuerzo\u0026quot;)\r## col.nr var.name\r## 1 158 c18_09\r## var.label\r## 1 Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\rNos informa que esta variable es la c18_09.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_elsoc, donde “proc” hace referencia a base procesada:\nproc_elsoc \u0026lt;-elsoc_2016 %\u0026gt;%select(c18_09, # percepción meritocracia esfuerzo\rc18_10, # percepción meritocracia talento\rd01_01, # estatus social subjetivo\rm01, # nivel educacional\rm0_sexo,# sexo\rm0_edad)# edad\r\r# Comprobar\rnames(proc_elsoc)\r## [1] \u0026quot;c18_09\u0026quot; \u0026quot;c18_10\u0026quot; \u0026quot;d01_01\u0026quot; \u0026quot;m01\u0026quot; \u0026quot;m0_sexo\u0026quot; \u0026quot;m0_edad\u0026quot;\rMediante el comando get_label obtenemos el atributo label de las variables.\nsjlabelled::get_label(proc_elsoc)\r## c18_09 ## \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; ## c18_10 ## \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; ## d01_01 ## \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; ## m01 ## \u0026quot;Nivel educacional\u0026quot; ## m0_sexo ## \u0026quot;Sexo del entrevistado\u0026quot; ## m0_edad ## \u0026quot;Edad del entrevistado\u0026quot;\rPodemos ver que son muy largas, por lo tanto, es necesario cambiarlas por etiquetas más cortas.\n\r4. Procesamiento de variables\rPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\nDescriptivo general\rRecodificación: de casos perdidos y otros valores (en caso necesario)\rEtiquetado: cambio de nombres de variables y valores (en caso necesario)\rOtros ajustes\r\rY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n4.1 Percepción de meritocracia\rEn ELSOC, las variables que permiten medir la percepción de las personas con respecto al funcionamiento de la meritocracia en Chile son las siguientes:\n\r[c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r[c18_10]: “Grado de acuerdo: Las personas son recompensadas por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r\ra. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\nfrq(proc_elsoc$c18_09)\r## ## Grado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=-3.06 sd=71.66\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 4 0.14 0.14 0.14\r## -888 No Sabe (no leer) 14 0.48 0.48 0.61\r## 1 Totalmente en desacuerdo 357 12.20 12.20 12.81\r## 2 En desacuerdo 1331 45.47 45.47 58.28\r## 3 Ni de acuerdo ni en desacuerdo 497 16.98 16.98 75.26\r## 4 De acuerdo 646 22.07 22.07 97.34\r## 5 Totalmente de acuerdo 78 2.66 2.66 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rfrq(proc_elsoc$c18_10)\r## ## Grado de acuerdo: Las personas son recompensada por su inteligencia (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=-3.42 sd=74.36\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 2 0.07 0.07 0.07\r## -888 No Sabe (no leer) 18 0.61 0.61 0.68\r## 1 Totalmente en desacuerdo 288 9.84 9.84 10.52\r## 2 En desacuerdo 1163 39.73 39.73 50.26\r## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.10 69.35\r## 4 De acuerdo 814 27.81 27.81 97.16\r## 5 Totalmente de acuerdo 83 2.84 2.84 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rEn ambas variables vemos valores asociados a la opción “No responde” (-999) y “No sabe” (-888), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en orden, así que en la recodificiación solo nos haremos cargo de los casos perdidos.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\nproc_elsoc$c18_09 \u0026lt;-recode(proc_elsoc$c18_09, \u0026quot;c(-888,-999)=NA\u0026quot;)\rproc_elsoc$c18_10 \u0026lt;-recode(proc_elsoc$c18_10, \u0026quot;c(-888,-999)=NA\u0026quot;)\rc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\nproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;mesfuerzo\u0026quot;=c18_09, # meritocracia esfuerzo\r\u0026quot;mtalento\u0026quot; =c18_10) # meritocracia talento\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$mesfuerzo)\r## [1] \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot;\rproc_elsoc$mesfuerzo \u0026lt;-set_label(x = proc_elsoc$mesfuerzo,label = \u0026quot;Recompensa: esfuerzo\u0026quot;)\r\rget_label(proc_elsoc$mtalento)\r## [1] \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot;\rproc_elsoc$mtalento \u0026lt;-set_label(x = proc_elsoc$mtalento, label = \u0026quot;Recompensa: talento\u0026quot;)\rd. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los dos items de meritocracia.\nproc_elsoc$pmerit \u0026lt;-(proc_elsoc$mesfuerzo+proc_elsoc$mtalento)/2\rsummary(proc_elsoc$pmerit)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 2.000 2.500 2.654 3.500 5.000 29\rget_label(proc_elsoc$pmerit)\r## [1] \u0026quot;Recompensa: esfuerzo\u0026quot;\rVemos que todavía tiene la etiqueta de la variable “Recompensa: esfuerzo”\nproc_elsoc$pmerit \u0026lt;-set_label(x = proc_elsoc$pmerit, label = \u0026quot;Meritocracia promedio\u0026quot;)\rRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\nfrq(proc_elsoc$mesfuerzo)\r## ## Recompensa: esfuerzo (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2909 mean=2.57 sd=1.05\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1 Totalmente en desacuerdo 357 12.20 12.27 12.27\r## 2 En desacuerdo 1331 45.47 45.75 58.03\r## 3 Ni de acuerdo ni en desacuerdo 497 16.98 17.08 75.11\r## 4 De acuerdo 646 22.07 22.21 97.32\r## 5 Totalmente de acuerdo 78 2.66 2.68 100.00\r## NA \u0026lt;NA\u0026gt; 18 0.61 NA NA\rfrq(proc_elsoc$mtalento)\r## ## Recompensa: talento (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2907 mean=2.74 sd=1.06\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1 Totalmente en desacuerdo 288 9.84 9.91 9.91\r## 2 En desacuerdo 1163 39.73 40.01 49.91\r## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.23 69.14\r## 4 De acuerdo 814 27.81 28.00 97.14\r## 5 Totalmente de acuerdo 83 2.84 2.86 100.00\r## NA \u0026lt;NA\u0026gt; 20 0.68 NA NA\rfrq(proc_elsoc$pmerit)\r## ## Meritocracia promedio (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2898 mean=2.65 sd=0.97\r## ## val label frq raw.prc valid.prc cum.prc\r## -999.0 No Responde (no leer) 0 0.00 0.00 0.00\r## -888.0 No Sabe (no leer) 0 0.00 0.00 0.00\r## 1.0 Totalmente en desacuerdo 243 8.30 8.39 8.39\r## 1.5 1.5 79 2.70 2.73 11.11\r## 2.0 En desacuerdo 1041 35.57 35.92 47.03\r## 2.5 2.5 222 7.58 7.66 54.69\r## 3.0 Ni de acuerdo ni en desacuerdo 536 18.31 18.50 73.19\r## 3.5 3.5 169 5.77 5.83 79.02\r## 4.0 De acuerdo 528 18.04 18.22 97.24\r## 4.5 4.5 38 1.30 1.31 98.55\r## 5.0 Totalmente de acuerdo 42 1.43 1.45 100.00\r## NA \u0026lt;NA\u0026gt; 29 0.99 NA NA\r4.2. Educación\r\r[m01] = ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente).\r\ra. Descriptivo\nfrq(proc_elsoc$m01)\r## ## Nivel educacional (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=4.57 sd=26.34\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 2 0.07 0.07 0.07\r## -888 No Sabe (no leer) 0 0.00 0.00 0.07\r## 1 Sin estudios 37 1.26 1.26 1.33\r## 2 Educacion Basica o Preparatoria incompleta 322 11.00 11.00 12.33\r## 3 Educacion Basica o Preparatoria completa 297 10.15 10.15 22.48\r## 4 Educacion Media o Humanidades incompleta 394 13.46 13.46 35.94\r## 5 Educacion Media o Humanidades completa 857 29.28 29.28 65.22\r## 6 Tecnica Superior incompleta 102 3.48 3.48 68.71\r## 7 Tecnica Superior completa 381 13.02 13.02 81.72\r## 8 Universitaria incompleta 186 6.35 6.35 88.08\r## 9 Universitaria completa 303 10.35 10.35 98.43\r## 10 Estudios de posgrado (magister o doctorado) 46 1.57 1.57 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación\n\rDatos perdidos:\r\rproc_elsoc$m01 \u0026lt;-recode(proc_elsoc$m01, \u0026quot;c(-888,-999)=NA\u0026quot;)\r\rValores\r\rRecodificación de acuerdo a las categorías CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1\r2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1\r3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2\r4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3\r5. Educacion Media o Humanidades completa = [CINE 3 ] = 3\r6. Tecnico Superior incompleta = [CINE 5 ] = 4\r7. Tecnico Superior completa = [CINE 5 ] = 4\r8. Universitaria incompleta = [CINE 6 ] = 5\r9. Universitaria completa = [CINE 6 ] = 6\r10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6\r# recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car\rproc_elsoc$m01 \u0026lt;-car::recode(proc_elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;)\rComprobar con un nuevo descriptivo:\nfrq(proc_elsoc$m01)\r## ## Nivel educacional (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2925 mean=3.18 sd=1.21\r## ## val label frq raw.prc valid.prc\r## -999 No Responde (no leer) 0 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00\r## 1 Sin estudios 359 12.27 12.27\r## 2 Educacion Basica o Preparatoria incompleta 297 10.15 10.15\r## 3 Educacion Basica o Preparatoria completa 1251 42.74 42.77\r## 4 Educacion Media o Humanidades incompleta 483 16.50 16.51\r## 5 Educacion Media o Humanidades completa 535 18.28 18.29\r## 6 Tecnica Superior incompleta 0 0.00 0.00\r## 7 Tecnica Superior completa 0 0.00 0.00\r## 8 Universitaria incompleta 0 0.00 0.00\r## 9 Universitaria completa 0 0.00 0.00\r## 10 Estudios de posgrado (magister o doctorado) 0 0.00 0.00\r## NA \u0026lt;NA\u0026gt; 2 0.07 NA\r## cum.prc\r## 0.00\r## 0.00\r## 12.27\r## 22.43\r## 65.20\r## 81.71\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## 100.00\r## NA\rSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 5), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\nproc_elsoc$m01 \u0026lt;-set_labels(proc_elsoc$m01,\rlabels=c( \u0026quot;Primaria incompleta menos\u0026quot;=1,\r\u0026quot;Primaria y secundaria baja\u0026quot;=2,\r\u0026quot;Secundaria alta\u0026quot;=3,\r\u0026quot;Terciaria ciclo corto\u0026quot;=4,\r\u0026quot;Terciaria y Postgrado\u0026quot;=5))\rLuego renombramos la variable con un nombre más sustantivo\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edcine\u0026quot;=m01)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edcine)\r## [1] \u0026quot;Nivel educacional\u0026quot;\rproc_elsoc$edcine \u0026lt;-set_label(x = proc_elsoc$edcine,label = \u0026quot;Educación\u0026quot;)\r\r\r4.3. Estatus subjetivo\ra. Descriptivo\n\r[d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\r\rfrq(proc_elsoc$d01_01)\rsummary(proc_elsoc$d01_01)\r## ## Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=0.63 sd=57.67\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 1 0.03 0.03 0.03\r## -888 No Sabe (no leer) 11 0.38 0.38 0.41\r## 0 0 El nivel mas bajo 44 1.50 1.50 1.91\r## 1 1 84 2.87 2.87 4.78\r## 2 2 207 7.07 7.07 11.86\r## 3 3 439 15.00 15.00 26.85\r## 4 4 677 23.13 23.13 49.98\r## 5 5 975 33.31 33.31 83.29\r## 6 6 310 10.59 10.59 93.88\r## 7 7 116 3.96 3.96 97.85\r## 8 8 37 1.26 1.26 99.11\r## 9 9 4 0.14 0.14 99.25\r## 10 10 El nivel mas alto 22 0.75 0.75 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\r## ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -999.0000 3.0000 5.0000 0.6338 5.0000 10.0000\rb. Recodificación\nproc_elsoc$d01_01 \u0026lt;-recode(proc_elsoc$d01_01, \u0026quot;c(-888,-999)=NA\u0026quot;)\rc. Etiquetado\n\rCambio de nombre de variable a etiqueta más sustantiva ess (estatus social subjetivo)\r\rproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;ess\u0026quot;=d01_01) # estatus social subjetivo\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$ess)\r## [1] \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot;\rproc_elsoc$ess \u0026lt;-set_label(x = proc_elsoc$ess,label = \u0026quot;Estatus Social Subjetivo\u0026quot;)\r\r4.4. Sexo\r\r[m0_sexo] = Indicar el sexo del entrevistado.\r\ra. Descriptivo\nfrq(proc_elsoc$m0_sexo)\r## ## Sexo del entrevistado (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=1.60 sd=0.49\r## ## val label frq raw.prc valid.prc cum.prc\r## 1 Hombre 1163 39.73 39.73 39.73\r## 2 Mujer 1764 60.27 60.27 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\nproc_elsoc$m0_sexo \u0026lt;-car::recode(proc_elsoc$m0_sexo, \u0026quot;1=0;2=1\u0026quot;)\rc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\nproc_elsoc$m0_sexo \u0026lt;-set_labels(proc_elsoc$m0_sexo,\rlabels=c( \u0026quot;Hombre\u0026quot;=0,\r\u0026quot;Mujer\u0026quot;=1))\rTambién el nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;sexo\u0026quot;=m0_sexo)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$sexo)\r## [1] \u0026quot;Sexo del entrevistado\u0026quot;\rproc_elsoc$sexo \u0026lt;-set_label(x = proc_elsoc$sexo,label = \u0026quot;Sexo\u0026quot;)\rRevisar con un nuevo descriptivo:\nfrq(proc_elsoc$sexo)\r## ## Sexo (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=0.60 sd=0.49\r## ## val label frq raw.prc valid.prc cum.prc\r## 0 Hombre 1163 39.73 39.73 39.73\r## 1 Mujer 1764 60.27 60.27 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\r\r4.5 Edad\r\r[m0_edad] = ¿Cuáles su edad? (años cumplidos).\r\ra. Descriptivo\nfrq(proc_elsoc$m0_edad)\r## ## Edad del entrevistado (x) \u0026lt;numeric\u0026gt;\r## # total N=2927 valid N=2927 mean=46.09 sd=15.29\r## ## val label frq raw.prc valid.prc cum.prc\r## -999 No Responde (no leer) 0 0.00 0.00 0.00\r## -888 No Sabe (no leer) 0 0.00 0.00 0.00\r## 18 18 19 0.65 0.65 0.65\r## 19 19 32 1.09 1.09 1.74\r## 20 20 26 0.89 0.89 2.63\r## 21 21 39 1.33 1.33 3.96\r## 22 22 49 1.67 1.67 5.64\r## 23 23 44 1.50 1.50 7.14\r## 24 24 51 1.74 1.74 8.88\r## 25 25 46 1.57 1.57 10.45\r## 26 26 44 1.50 1.50 11.96\r## 27 27 51 1.74 1.74 13.70\r## 28 28 58 1.98 1.98 15.68\r## 29 29 47 1.61 1.61 17.29\r## 30 30 66 2.25 2.25 19.54\r## 31 31 48 1.64 1.64 21.18\r## 32 32 64 2.19 2.19 23.37\r## 33 33 55 1.88 1.88 25.25\r## 34 34 55 1.88 1.88 27.13\r## 35 35 67 2.29 2.29 29.42\r## 36 36 70 2.39 2.39 31.81\r## 37 37 46 1.57 1.57 33.38\r## 38 38 57 1.95 1.95 35.33\r## 39 39 37 1.26 1.26 36.59\r## 40 40 57 1.95 1.95 38.54\r## 41 41 58 1.98 1.98 40.52\r## 42 42 67 2.29 2.29 42.81\r## 43 43 54 1.84 1.84 44.65\r## 44 44 45 1.54 1.54 46.19\r## 45 45 53 1.81 1.81 48.00\r## 46 46 77 2.63 2.63 50.63\r## 47 47 56 1.91 1.91 52.55\r## 48 48 72 2.46 2.46 55.01\r## 49 49 53 1.81 1.81 56.82\r## 50 50 69 2.36 2.36 59.17\r## 51 51 55 1.88 1.88 61.05\r## 52 52 69 2.36 2.36 63.41\r## 53 53 57 1.95 1.95 65.36\r## 54 54 76 2.60 2.60 67.95\r## 55 55 72 2.46 2.46 70.41\r## 56 56 76 2.60 2.60 73.01\r## 57 57 53 1.81 1.81 74.82\r## 58 58 57 1.95 1.95 76.77\r## 59 59 44 1.50 1.50 78.27\r## 60 60 57 1.95 1.95 80.22\r## 61 61 33 1.13 1.13 81.35\r## 62 62 33 1.13 1.13 82.47\r## 63 63 49 1.67 1.67 84.15\r## 64 64 39 1.33 1.33 85.48\r## 65 65 60 2.05 2.05 87.53\r## 66 66 39 1.33 1.33 88.86\r## 67 67 39 1.33 1.33 90.19\r## 68 68 35 1.20 1.20 91.39\r## 69 69 32 1.09 1.09 92.48\r## 70 70 37 1.26 1.26 93.75\r## 71 71 29 0.99 0.99 94.74\r## 72 72 28 0.96 0.96 95.70\r## 73 73 42 1.43 1.43 97.13\r## 74 74 39 1.33 1.33 98.46\r## 75 75 37 1.26 1.26 99.73\r## 77 77 1 0.03 0.03 99.76\r## 78 78 3 0.10 0.10 99.86\r## 80 80 1 0.03 0.03 99.90\r## 81 81 1 0.03 0.03 99.93\r## 88 88 2 0.07 0.07 100.00\r## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA\rb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio del nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edad\u0026quot;=m0_edad)\rAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edad)\r## [1] \u0026quot;Edad del entrevistado\u0026quot;\rproc_elsoc$edad \u0026lt;-set_label(x = proc_elsoc$edad,label = \u0026quot;Edad\u0026quot;)\r\r\r5. Generación de base de datos procesada para el análisis\rAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nstargazer(proc_elsoc, type=\u0026quot;text\u0026quot;)\r## ## ==============================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## --------------------------------------------------------------\r## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000\r## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------\r\rGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como \"C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\r\rsave(proc_elsoc,file = \u0026quot;[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\u0026quot;)\rEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\nsave(proc_elsoc,file = \u0026quot;content/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)\r\r\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"9f719bf107561ff88768da3264c94b73","permalink":"/assignment/01-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/01-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 1. Preparación de datos en R","type":"docs"},{"authors":null,"categories":null,"content":"\r\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rÍndice\r\rObjetivo de la práctica\rCódigo de análisis\r1. Librerías\r2. Cargar base de datos\r3. Descripción de variables\r3.1 Tabla descriptiva de variables para sección metodológica\r3.2 Exploración de asociación entre variables\r\rNota final: Información de la sesión de R\r\rResumen Práctica 2: Descripción de variables\rReporte de progreso\rArchivo de código\rForo práctica 2\r\r\r\raddClassKlippyTo(\"pre.r, pre.markdown\");\raddKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');\r\rObjetivo de la práctica\rEsta segunda práctica tiene por objetivo repasar algunos conceptos básicos de los cursos anteriores de Estadística Descriptiva y Estadística Correlacional. Asume como base el desarrollo de la Práctica 1, a la cual se hará referencia permanente.\nEn la Práctica 1 se desarrolló un código de preparación de datos que generó una base de datos procesada para el análisis. En esta Práctica 2 comenzamos con el segundo momento de procesamiento de datos, que es el análisis propiamente tal. El análisis se divide en descripción de variables y contraste de hipótesis. En esta práctica nos enfocaremos en la primera fase, que llega hasta el punto 3 del código de análisis:\nAl igual que el Código de Preparación, el Código de Análisis posee una estructura definida. En este caso son 4 partes, donde las primeras son similares al código de preparación:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\rLibrerías principales (de R) a utilizar en el análisis\rDatos (que provienen de los preparados en la fase anterior)\rDescripción de variables\r\rTabla general de variables para la sección metodológica del reporte\rExploración descriptiva de relaciones entre variables\r\rContraste de hipótesis / inferencia estadística según la técnica que corresponda\r\rAl final de esta práctica la idea es que cada un_ pueda avanzar hasta el punto 3 del Código de Análisis. El punto 4 (contraste de hipótesis) se desarrollará más adelante en este curso con énfasis en la técnica de regresión.\n\rCódigo de análisis\r1. Librerías\rLa explicación de esta parte del código se encuentra en la sección correspondiente de la práctica 1.pacman::p_load\npacman::p_load(dplyr, #Manipulacion de datos\rstargazer, #Tablas\rsjmisc, # Tablas\rsummarytools, # Tablas\rkableExtra, #Tablas\rsjPlot, #Tablas y gráficos\rcorrplot, # Correlaciones\rsessioninfo) # Información de la sesión de trabajo\r\r2. Cargar base de datos\rVamos a cargar la base de datos ELSOC_ess_merit2016.Rproc_elsoc, que generamos durante la práctica 1. Se puede llamar desde el directorio en que la guardaron dando la ruta completa, o también para esta práctica la podemos llamar directamente desde nuestro sitio web:\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)) #Cargar base de datos\r\rExploración inicial general de la base de datos\r\rnames(proc_elsoc) # Muestra los nombres de las variables de la base de datos\r## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot;\rdim(proc_elsoc) # Dimensiones\r## [1] 2927 7\rEn el caso de esta base, 2927 casos y 7 variables\nRecordando el contenido de cada variable preparada en la práctica 1:\n\r[merit] = Indice promedio de percepción de meritocracia.\n\r[ess] = Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\" (0 = el nivel mas bajo; 10 = el nivel mas alto)\n\r[edcine] = Nivel educacional(1 = Primaria incompleta menos, 2 = Primaria y secundaria baja, 3 = Secundaria alta, 4 = Terciaria ciclo corto, 5 = Terciaria y Postgrado)\n\r[sexo] = Sexo (O = Hombre; 1 = Mujer)\n\r[edad] = ¿Cuáles su edad? (años cumplidos)\n\r\r\r3. Descripción de variables\rLos resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n\ren la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\n\ren la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n\r\r3.1 Tabla descriptiva de variables para sección metodológica\rA continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\nstargazer(proc_elsoc,type = \u0026quot;text\u0026quot;)\r## ## ==============================================================\r## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## --------------------------------------------------------------\r## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000\r## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------\rAlgunas observaciones sobre esta tabla:\n\rLa opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\n\rUna distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.60) es la proporción de mujeres vs hombres. En otras palabras, hay un 60% de mujeres y 40% de hombres en la muestra.\n\r\rb. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\nsjmisc::descr(proc_elsoc)\r## ## ## Basic descriptive statistics\r## ## var type label n NA.prc mean sd se md\r## mesfuerzo numeric Recompensa: esfuerzo 2909 0.61 2.57 1.05 0.02 2.0\r## mtalento numeric Recompensa: talento 2907 0.68 2.74 1.06 0.02 3.0\r## ess numeric Estatus Social Subjetivo 2915 0.41 4.33 1.57 0.03 5.0\r## edcine numeric Educación 2925 0.07 3.18 1.21 0.02 3.0\r## sexo numeric Sexo 2927 0.00 0.60 0.49 0.01 1.0\r## edad numeric Edad 2927 0.00 46.09 15.29 0.28 46.0\r## pmerit numeric Meritocracia promedio 2898 0.99 2.65 0.97 0.02 2.5\r## trimmed range skew\r## 2.56 4 (1-5) 0.42\r## 2.76 4 (1-5) 0.18\r## 4.36 10 (0-10) -0.01\r## 3.23 4 (1-5) -0.15\r## 0.63 1 (0-1) -0.42\r## 45.90 70 (18-88) 0.07\r## 2.66 4 (1-5) 0.26\rEn este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en una práctica posterior):\nsjmisc::descr(proc_elsoc,\rshow = c(\u0026quot;label\u0026quot;,\u0026quot;range\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;n\u0026quot;))%\u0026gt;%\rkable(.,\u0026quot;markdown\u0026quot;)\r\r\r\rvar\rlabel\rn\rNA.prc\rmean\rsd\rrange\r\r\r\r4\rmesfuerzo\rRecompensa: esfuerzo\r2909\r0.6149641\r2.5727054\r1.0466874\r4 (1-5)\r\r5\rmtalento\rRecompensa: talento\r2907\r0.6832935\r2.7389061\r1.0596182\r4 (1-5)\r\r3\ress\rEstatus Social Subjetivo\r2915\r0.4099761\r4.3300172\r1.5666965\r10 (0-10)\r\r2\redcine\rEducación\r2925\r0.0683293\r3.1839316\r1.2066058\r4 (1-5)\r\r7\rsexo\rSexo\r2927\r0.0000000\r0.6026648\r0.4894300\r1 (0-1)\r\r1\redad\rEdad\r2927\r0.0000000\r46.0908780\r15.2867983\r70 (18-88)\r\r6\rpmerit\rMeritocracia promedio\r2898\r0.9907755\r2.6538992\r0.9694792\r4 (1-5)\r\r\r\rc. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\ndfSummary(proc_elsoc, plain.ascii = FALSE)\r## ### Data Frame Summary ## #### proc_elsoc ## **Dimensions:** 2927 x 7 ## **Duplicates:** 396 ## ## ----------------------------------------------------------------------------------------------------------------------------------------\r## No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing ## ---- ------------ -------------------------- -------------------------- ---------------------- -------------------- ---------- ---------\r## 1 mesfuerzo\\ Recompensa: esfuerzo Mean (sd) : 2.6 (1)\\ 1 : 357 (12.3%)\\ II \\ 2909\\ 18\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1331 (45.8%)\\ IIIIIIIII \\ (99.39%) (0.61%) ## 1 \u0026lt; 2 \u0026lt; 5\\ 3 : 497 (17.1%)\\ III \\ ## IQR (CV) : 1 (0.4) 4 : 646 (22.2%)\\ IIII \\ ## 5 : 78 ( 2.7%) ## ## 2 mtalento\\ Recompensa: talento Mean (sd) : 2.7 (1.1)\\ 1 : 288 ( 9.9%)\\ I \\ 2907\\ 20\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1163 (40.0%)\\ IIIIIIII \\ (99.32%) (0.68%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 559 (19.2%)\\ III \\ ## IQR (CV) : 2 (0.4) 4 : 814 (28.0%)\\ IIIII \\ ## 5 : 83 ( 2.9%) ## ## 3 ess\\ Estatus Social Subjetivo Mean (sd) : 4.3 (1.6)\\ 11 distinct values \\ 2915\\ 12\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ \\ \\ \\ \\ \\ \\ :\\ (99.59%) (0.41%) ## 0 \u0026lt; 5 \u0026lt; 10\\ \\ \\ \\ \\ \\ \\ . :\\ ## IQR (CV) : 2 (0.4) \\ \\ \\ \\ . : :\\ ## \\ \\ \\ \\ : : : .\\ ## . : : : : : . ## ## 4 edcine\\ Educación Mean (sd) : 3.2 (1.2)\\ 1 : 359 (12.3%)\\ II \\ 2925\\ 2\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 297 (10.2%)\\ II \\ (99.93%) (0.07%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 1251 (42.8%)\\ IIIIIIII \\ ## IQR (CV) : 1 (0.4) 4 : 483 (16.5%)\\ III \\ ## 5 : 535 (18.3%) III ## ## 5 sexo\\ Sexo Min : 0\\ 0 : 1163 (39.7%)\\ IIIIIII \\ 2927\\ 0\\ ## [numeric] Mean : 0.6\\ 1 : 1764 (60.3%) IIIIIIIIIIII (100%) (0%) ## Max : 1 ## ## 6 edad\\ Edad Mean (sd) : 46.1 (15.3)\\ 63 distinct values \\ 2927\\ 0\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ . . . : :\\ (100%) (0%) ## 18 \u0026lt; 46 \u0026lt; 88\\ . : : : : : .\\ ## IQR (CV) : 25 (0.3) : : : : : : : :\\ ## : : : : : : : :\\ ## : : : : : : : : . ## ## 7 pmerit\\ Meritocracia promedio Mean (sd) : 2.7 (1)\\ 1.00 : 243 ( 8.4%)\\ I \\ 2898\\ 29\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 1.50 : 79 ( 2.7%)\\ \\ (99.01%) (0.99%) ## 1 \u0026lt; 2.5 \u0026lt; 5\\ 2.00 : 1041 (35.9%)\\ IIIIIII \\ ## IQR (CV) : 1.5 (0.4) 2.50 : 222 ( 7.7%)\\ I \\ ## 3.00 : 536 (18.5%)\\ III \\ ## 3.50 : 169 ( 5.8%)\\ I \\ ## 4.00 : 528 (18.2%)\\ III \\ ## 4.50 : 38 ( 1.3%)\\ \\ ## 5.00 : 42 ( 1.5%) ## ----------------------------------------------------------------------------------------------------------------------------------------\rEs muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\nview(dfSummary(proc_elsoc, headings=FALSE))\r\r\rNo\rVariable\rLabel\rStats / Values\rFreqs (% of Valid)\rGraph\rValid\rMissing\r\r\r\r\r1\rmesfuerzo\r[numeric]\rRecompensa: esfuerzo\rMean (sd) : 2.6 (1)\rmin 1:357(12.3%)2:1331(45.8%)3:497(17.1%)4:646(22.2%)5:78(2.7%)\r\r2909\r(99.39%)\r18\r(0.61%)\r\r\r2\rmtalento\r[numeric]\rRecompensa: talento\rMean (sd) : 2.7 (1.1)\rmin 1:288(9.9%)2:1163(40.0%)3:559(19.2%)4:814(28.0%)5:83(2.9%)\r\r2907\r(99.32%)\r20\r(0.68%)\r\r\r3\ress\r[numeric]\rEstatus Social Subjetivo\rMean (sd) : 4.3 (1.6)\rmin 11 distinct values\r\r2915\r(99.59%)\r12\r(0.41%)\r\r\r4\redcine\r[numeric]\rEducaci\u0026#0243;n\rMean (sd) : 3.2 (1.2)\rmin 1:359(12.3%)2:297(10.2%)3:1251(42.8%)4:483(16.5%)5:535(18.3%)\r\r2925\r(99.93%)\r2\r(0.07%)\r\r\r5\rsexo\r[numeric]\rSexo\rMin : 0\rMean : 0.6\rMax : 1\r0:1163(39.7%)1:1764(60.3%)\r\r2927\r(100%)\r0\r(0%)\r\r\r6\redad\r[numeric]\rEdad\rMean (sd) : 46.1 (15.3)\rmin 63 distinct values\r\r2927\r(100%)\r0\r(0%)\r\r\r7\rpmerit\r[numeric]\rMeritocracia promedio\rMean (sd) : 2.7 (1)\rmin 1.00:243(8.4%)1.50:79(2.7%)2.00:1041(35.9%)2.50:222(7.7%)3.00:536(18.5%)3.50:169(5.8%)4.00:528(18.2%)4.50:38(1.3%)5.00:42(1.5%)\r\r2898\r(99.01%)\r29\r(0.99%)\r\r\r\rGenerated by summarytools 0.9.6 (R version 3.6.0)2020-04-23\n\rNota sobre casos perdidos (NAs)na.omit(data)\nHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n\rrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_elsoc_original.\rcontamos el número de casos con el comando dim\rcontamos el número de casos perdidos con sum(is.na(proc_elsoc))\rborramos los casos perdidos con proc_elsoc \u0026lt;-na.omit(proc_elsoc)\rcontamos nuevamente con dim para asegurarnos que se borraron\ry por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.\r\rproc_elsoc_original \u0026lt;-proc_elsoc\rdim(proc_elsoc)\r## [1] 2927 7\rsum(is.na(proc_elsoc))\r## [1] 81\rproc_elsoc \u0026lt;-na.omit(proc_elsoc)\rdim(proc_elsoc)\r## [1] 2887 7\rproc_elsoc \u0026lt;-sjlabelled::copy_labels(proc_elsoc,proc_elsoc_original)\r\r3.2 Exploración de asociación entre variables\rDado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivio que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n\rVariables categóricas: tabla de contingencia\rVariable categórica y continua: tabla de promedios por cada categoría\rVariables continuas: correlaciones.\r\rEn esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\nTablas de contingencia para variables categóricas\rPara tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo)\r\rEducación\r\rSexo\r\rTotal\r\r\r\rHombre\r\rMujer\r\r\r\rPrimaria incompleta\nmenos\r\r102\r\r247\r\r349\r\r\r\rPrimaria y\nsecundaria baja\r\r105\r\r186\r\r291\r\r\r\rSecundaria alta\r\r511\r\r727\r\r1238\r\r\r\rTerciaria ciclo\ncorto\r\r186\r\r292\r\r478\r\r\r\rTerciaria y\nPostgrado\r\r245\r\r286\r\r531\r\r\r\rTotal\r\r1149\r\r1738\r\r2887\r\r\rχ2=28.154 · df=4 · Cramer’s V=0.099 · p=0.000\r\r\r\rAl ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo,\rshow.col.prc=TRUE,\rshow.summary=FALSE\r)\r\rEducación\r\rSexo\r\rTotal\r\r\r\rHombre\r\rMujer\r\r\r\rPrimaria incompleta\nmenos\r\r102\n8.9 %\r\r247\n14.2 %\r\r349\n12.1 %\r\r\r\rPrimaria y\nsecundaria baja\r\r105\n9.1 %\r\r186\n10.7 %\r\r291\n10.1 %\r\r\r\rSecundaria alta\r\r511\n44.5 %\r\r727\n41.8 %\r\r1238\n42.9 %\r\r\r\rTerciaria ciclo\ncorto\r\r186\n16.2 %\r\r292\n16.8 %\r\r478\n16.6 %\r\r\r\rTerciaria y\nPostgrado\r\r245\n21.3 %\r\r286\n16.5 %\r\r531\n18.4 %\r\r\r\rTotal\r\r1149\n100 %\r\r1738\n100 %\r\r2887\n100 %\r\r\r\r\rTablas de promedio de variable continua por una categóricas\rEn ejemplo vamos a explorar datos de nuestra variable de percepción de meritocracia pmerit por los niveles educacionales edcine.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\ntapply(proc_elsoc$pmerit, proc_elsoc$edcine, mean)\r## 1 2 3 4 5 ## 2.968481 2.697595 2.662763 2.479079 2.559322\rAquí vemos en promedio de pmerit para cada uno de los 5 niveles de la variable educación edcine. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %\u0026gt;%. El sentido de cada función aparece comentado abajo:\nproc_elsoc %\u0026gt;%# se especifica la base de datos\rselect(pmerit,edcine) %\u0026gt;%# se seleccionan las variables\rdplyr::group_by(Educación=sjlabelled::as_label(edcine)) %\u0026gt;%# se agrupan por la variable categórica y se usan sus etiquetas con as_label\rdplyr::summarise(Obs.=n(),Promedio=mean(pmerit),SD=sd(pmerit)) %\u0026gt;%# se agregan las operaciones a presentar en la tabla\rkable(, format = \u0026quot;markdown\u0026quot;) # se genera la tabla\r\r\rEducación\rObs.\rPromedio\rSD\r\r\r\rPrimaria incompleta menos\r349\r2.968481\r0.9828315\r\rPrimaria y secundaria baja\r291\r2.697595\r1.0041093\r\rSecundaria alta\r1238\r2.662762\r0.9685655\r\rTerciaria ciclo corto\r478\r2.479080\r0.9431323\r\rTerciaria y Postgrado\r531\r2.559322\r0.9223446\r\r\r\rEsta asocación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función plot_grpfrq de sjPlot:sjPlot::plot_grpfrq\nplot_grpfrq(proc_elsoc$pmerit,proc_elsoc$edcine,\rtype = \u0026quot;box\u0026quot;)\r\rCorrelaciones (variables continuas)\rAlgunas notas sobre correlación:\n\rEl coeficiente de correlación mide la fuerza de la relación lineal entre dos variable continuas. Esta puede ser:\n\rpositiva: a medida que aumenta una, aumenta la otra (ej: estatura y edad)\rnegativa: a medida que una aumenta, disminuye la otra (ej: tiempo dedicado al estudio y probabilidad de reprobar)\rneutra: no hay asociación entre variables.\r\rEl rango de variación del coeficiente de correlación va desde -1 (correlación negativa perfecta) y 1 (correlación positiva perfecta).\n\rExisten diferentes formas de cálculo del coeficiente de correlación (Spearman, Kendall, Pearson).\n\rEn el coeficiente de correlación se analiza tanto su tamaño como su significación estadística.\n\r\rEn lo que sigue nos concentraremos en el coeficiente de correlación más utilizado que es el de Pearson, que se aplica cuando las variables son de naturaleza continua.\nTablas/matrices de correlación\nLas correlaciones entre variables se presentan en general en modo de matrices, es decir, las variables se presentan en las filas y las columnas y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a lacor base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\nM \u0026lt;-cor(proc_elsoc)\rM\r## mesfuerzo mtalento ess edcine sexo\r## mesfuerzo 1.000000000 0.69768811 -0.004312135 -0.12167659 -0.04480502\r## mtalento 0.697688106 1.00000000 0.018447696 -0.10582754 -0.03759340\r## ess -0.004312135 0.01844770 1.000000000 0.28959248 -0.03745546\r## edcine -0.121676591 -0.10582754 0.289592479 1.00000000 -0.08682644\r## sexo -0.044805024 -0.03759340 -0.037455462 -0.08682644 1.00000000\r## edad 0.096495547 0.07383771 -0.066031873 -0.37660283 0.06121699\r## pmerit 0.920404032 0.92224547 0.007740598 -0.12341680 -0.04469515\r## edad pmerit\r## mesfuerzo 0.09649555 0.920404032\r## mtalento 0.07383771 0.922245465\r## ess -0.06603187 0.007740598\r## edcine -0.37660283 -0.123416804\r## sexo 0.06121699 -0.044695146\r## edad 1.00000000 0.092369792\r## pmerit 0.09236979 1.000000000\rEste es el reporte simple, pero no muy amigable a la vista. Para una versión más amable utilizamos la función sjt.corrsjPlot::sjt.corr:NOTA: sjPlot actualizó su librería a fines de Mayo (versión 2.8.4); para quienes hayan actualizado a esta versión, la función para tabla de correlaciones ahora es tab_corr\nsjt.corr(proc_elsoc)\r\r\rRecompensa: esfuerzo\r\rRecompensa: talento\r\rEstatus Social Subjetivo\r\rEducación\r\rSexo\r\rEdad\r\rMeritocracia promedio\r\r\r\rRecompensa: esfuerzo\r\r\r0.698***\r\r-0.004\r\r-0.122***\r\r-0.045*\r\r0.096***\r\r0.920***\r\r\r\rRecompensa: talento\r\r0.698***\r\r\r0.018\r\r-0.106***\r\r-0.038*\r\r0.074***\r\r0.922***\r\r\r\rEstatus Social Subjetivo\r\r-0.004\r\r0.018\r\r\r0.290***\r\r-0.037*\r\r-0.066***\r\r0.008\r\r\r\rEducación\r\r-0.122***\r\r-0.106***\r\r0.290***\r\r\r-0.087***\r\r-0.377***\r\r-0.123***\r\r\r\rSexo\r\r-0.045*\r\r-0.038*\r\r-0.037*\r\r-0.087***\r\r\r0.061**\r\r-0.045*\r\r\r\rEdad\r\r0.096***\r\r0.074***\r\r-0.066***\r\r-0.377***\r\r0.061**\r\r\r0.092***\r\r\r\rMeritocracia promedio\r\r0.920***\r\r0.922***\r\r0.008\r\r-0.123***\r\r-0.045*\r\r0.092***\r\r\r\r\rComputed correlation used pearson-method with listwise-deletion.\r\r\r\rCon esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n\rEn esta matriz las variables están representadas en las filas y en las columnas.\rCada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de recompensa por esfuerzo y recompensa por inteligencia es 0.698.\rLa información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno.\rEn la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva. En esta tabla se omiten y aparece la diagonal vacía, ya que es información redundante. Por lo mismo, también se recomienda eliminar el triangulo superior de la tabla (redundante) de la siguiente manera:\r\rsjt.corr(proc_elsoc,\rtriangle = \u0026quot;lower\u0026quot;)\r\r\rRecompensa: esfuerzo\r\rRecompensa: talento\r\rEstatus Social Subjetivo\r\rEducación\r\rSexo\r\rEdad\r\rMeritocracia promedio\r\r\r\rRecompensa: esfuerzo\r\r\r\r\r\r\r\r\r\r\rRecompensa: talento\r\r0.698***\r\r\r\r\r\r\r\r\r\rEstatus Social Subjetivo\r\r-0.004\r\r0.018\r\r\r\r\r\r\r\r\rEducación\r\r-0.122***\r\r-0.106***\r\r0.290***\r\r\r\r\r\r\r\rSexo\r\r-0.045*\r\r-0.038*\r\r-0.037*\r\r-0.087***\r\r\r\r\r\r\rEdad\r\r0.096***\r\r0.074***\r\r-0.066***\r\r-0.377***\r\r0.061**\r\r\r\r\r\rMeritocracia promedio\r\r0.920***\r\r0.922***\r\r0.008\r\r-0.123***\r\r-0.045*\r\r0.092***\r\r\r\r\rComputed correlation used pearson-method with listwise-deletion.\r\r\r\rUna segunda forma de presentar matrices de correlaciones es de manera gráfica con la librería corrplot, cuya función corrplot.mixed corrplot::corrplot.mixedse aplica al objeto que generamos con la función cor (M):\ncorrplot.mixed(M)\rEste gráfico/matriz representa el grado de asociación entre variables mediante el tamaño de los círculos e intensidad de colores, y el signo de la asociación se representa con una gradiente de colores que va del azul (positivo) al rojo (negativo). Bajo la diagonal aparecen los indices de correlación entre pares de variables.\nFinalmente, también se puede representar la correlación entre dos variables en un gráfico de nube de puntos o scatterplot:sjPlot::plot_scatter\nnames(proc_elsoc)\r## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot;\rplot_scatter(proc_elsoc, edad, ess)\rDonde:\n\rcada punto representa un caso\rla forma de la nube indica si la asociación es positiva, negativa o neutra:\r\rEn el caso de nuestra nube de puntos entre edad y estatus social subjetivo, observamos que no hay asociación (lo que ya era indicado por su correlación de -0.07 observada en la matriz de correlaciones).\n\r\r\rNota final: Información de la sesión de R\rR y sus librerías tienen distintas versiones. Esto puede representar algunos problemas de compatibilidad entre usuarios, por ejemplo, dos personas que trabajan en el mismo proyecto pero con distintas versiones (librerías y/o de R), pueden tener ocasionalmente complicaciones. Por eso, una buena práctica es registrar al final del código la información de la sesión. Y como siempre en R, varias maneras de hacer esto. Vamos con la más genérica que es muy simple: sessionInfo() sessionInfo()\nsessionInfo()\r## R version 4.0.0 (2020-04-24)\r## Platform: x86_64-pc-linux-gnu (64-bit)\r## Running under: Ubuntu 16.04.6 LTS\r## ## Matrix products: default\r## BLAS: /usr/lib/libblas/libblas.so.3.6.0\r## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0\r## ## locale:\r## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=es_CL.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=es_CL.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=es_CL.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=es_CL.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages:\r## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages:\r## [1] sessioninfo_1.1.1 corrplot_0.84 sjmisc_2.8.4 summarytools_0.9.6\r## [5] sjstats_0.18.0 psych_1.9.12.31 Publish_2019.12.04 prodlim_2019.11.13\r## [9] ggpubr_0.3.0 magrittr_1.5 car_3.0-7 carData_3.0-3 ## [13] scales_1.1.1 gridExtra_2.3 ggplot2_3.3.0 stargazer_5.2.2 ## [17] sjPlot_2.8.3 kableExtra_1.1.0 Rmisc_1.5 plyr_1.8.6 ## [21] lattice_0.20-41 dplyr_0.8.5 knitr_1.28 pacman_0.5.1 ## ## loaded via a namespace (and not attached):\r## [1] TH.data_1.0-10 minqa_1.2.4 colorspace_1.4-1 pryr_0.1.4 ## [5] ggsignif_0.6.0 ellipsis_0.3.0 rio_0.5.16 sjlabelled_1.1.4 ## [9] estimability_1.3 parameters_0.6.1 base64enc_0.1-3 rstudioapi_0.11 ## [13] fansi_0.4.1 mvtnorm_1.1-0 lubridate_1.7.8 xml2_1.3.2 ## [17] codetools_0.2-16 splines_4.0.0 mnormt_1.5-7 nloptr_1.2.2.1 ## [21] ggeffects_0.14.3 broom_0.5.6 effectsize_0.3.0 readr_1.3.1 ## [25] compiler_4.0.0 httr_1.4.1 emmeans_1.4.6 backports_1.1.7 ## [29] assertthat_0.2.1 Matrix_1.2-18 cli_2.0.2 htmltools_0.4.0 ## [33] tools_4.0.0 coda_0.19-3 gtable_0.3.0 glue_1.4.1 ## [37] Rcpp_1.0.4.6 cellranger_1.1.0 vctrs_0.3.0 nlme_3.1-147 ## [41] blogdown_0.18 insight_0.8.4 xfun_0.13 stringr_1.4.0 ## [45] openxlsx_4.1.5 lme4_1.1-23 rvest_0.3.5 lifecycle_0.2.0 ## [49] statmod_1.4.34 rstatix_0.5.0 MASS_7.3-51.6 zoo_1.8-8 ## [53] hms_0.5.3 parallel_4.0.0 sandwich_2.5-1 yaml_2.2.1 ## [57] curl_4.3 pander_0.6.3 stringi_1.4.6 bayestestR_0.6.0 ## [61] checkmate_2.0.0 boot_1.3-25 zip_2.0.4 lava_1.6.7 ## [65] rlang_0.4.6 pkgconfig_2.0.3 matrixStats_0.56.0 evaluate_0.14 ## [69] purrr_0.3.4 rapportools_1.0 tidyselect_1.1.0 bookdown_0.18 ## [73] R6_2.4.1 magick_2.3 generics_0.0.2 multcomp_1.4-13 ## [77] pillar_1.4.4 haven_2.2.0 foreign_0.8-79 withr_2.2.0 ## [81] survival_3.1-12 abind_1.4-5 tibble_3.0.1 performance_0.4.6 ## [85] modelr_0.1.7 crayon_1.3.4 rmarkdown_2.1 grid_4.0.0 ## [89] readxl_1.3.1 data.table_1.12.8 forcats_0.5.0 digest_0.6.25 ## [93] webshot_0.5.2 xtable_1.8-4 tidyr_1.0.3 munsell_0.5.0 ## [97] viridisLite_0.3.0 tcltk_4.0.0\rAcá vemos un listado de información muy completo, desde versión de R, sistema operativo, opciones de idioma local (LOCALE), y muchas librerías. Si optamos por esta versión de la información de la sesión, lo importante es fijarse en (a) version de R, y (b) de las librerías cargadas al principio, que aquí aparecen bajo “other attached packages”.\nLa segunda opción permite obtener información más precisa, con sessioninfo sessioninfo()(la única diferencia con la anterior en el nombre es que info es con minúscula sessioninfo). Con un poco más de especificaciones de sintaxis se pueden obtener directamente los puntos (a) y (b) mencionados anteriormente:\nsession_info(\u0026quot;sessioninfo\u0026quot;)$platform\r## setting value ## version R version 4.0.0 (2020-04-24)\r## os Ubuntu 16.04.6 LTS ## system x86_64, linux-gnu ## ui X11 ## language en_US ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/Santiago ## date 2020-05-16\rpackage_info(pkgs = (.packages()), dependencies = FALSE)\r## package * version date lib source ## car * 3.0-7 2020-03-11 [1] CRAN (R 4.0.0)\r## carData * 3.0-3 2019-11-16 [1] CRAN (R 4.0.0)\r## corrplot * 0.84 2017-10-16 [1] CRAN (R 4.0.0)\r## dplyr * 0.8.5 2020-03-07 [1] CRAN (R 4.0.0)\r## ggplot2 * 3.3.0 2020-03-05 [1] CRAN (R 4.0.0)\r## ggpubr * 0.3.0 2020-05-04 [1] CRAN (R 4.0.0)\r## gridExtra * 2.3 2017-09-09 [1] CRAN (R 4.0.0)\r## kableExtra * 1.1.0 2019-03-16 [1] CRAN (R 4.0.0)\r## knitr * 1.28 2020-02-06 [1] CRAN (R 4.0.0)\r## lattice * 0.20-41 2020-04-02 [1] CRAN (R 4.0.0)\r## magrittr * 1.5 2014-11-22 [1] CRAN (R 4.0.0)\r## pacman * 0.5.1 2019-03-11 [1] CRAN (R 4.0.0)\r## plyr * 1.8.6 2020-03-03 [1] CRAN (R 4.0.0)\r## prodlim * 2019.11.13 2019-11-17 [1] CRAN (R 4.0.0)\r## psych * 1.9.12.31 2020-01-08 [1] CRAN (R 4.0.0)\r## Publish * 2019.12.04 2019-12-04 [1] CRAN (R 4.0.0)\r## Rmisc * 1.5 2013-10-22 [1] CRAN (R 4.0.0)\r## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.0.0)\r## sessioninfo * 1.1.1 2018-11-05 [1] CRAN (R 4.0.0)\r## sjmisc * 2.8.4 2020-04-03 [1] CRAN (R 4.0.0)\r## sjPlot * 2.8.3 2020-03-09 [1] CRAN (R 4.0.0)\r## sjstats * 0.18.0 2020-05-06 [1] CRAN (R 4.0.0)\r## stargazer * 5.2.2 2018-05-30 [1] CRAN (R 4.0.0)\r## summarytools * 0.9.6 2020-03-02 [1] CRAN (R 4.0.0)\r## ## [1] /home/juank/Dropbox/Rlibrary\r## [2] /usr/local/lib/R/site-library\r## [3] /usr/lib/R/site-library\r## [4] /usr/lib/R/library\r\r\rResumen Práctica 2: Descripción de variables\rEn esta práctica revisamos los siguientes contenidos:\n\rtabla descriptiva general de variables\rtabla de asociación (o contingencia) entre dos variables categóricas\rtabla y gráfico de asociación entre variables categóricas y contínuas\rasociaciones entre pares de variables continuas mediante el índice de correlación.\r\r\rReporte de progreso\rCompletar el reporte de progreso correspondiente a esta práctica aquí\n\rArchivo de código\rEl archivo de código R de esta práctica se puede descargar aquí\n\rForo práctica 2\r\r","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591276264,"objectID":"112494b1f3727cfe1df8f164d59d3152","permalink":"/assignment/02-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/02-code/","section":"assignment","summary":"a.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.","tags":null,"title":"Práctica 2. Descripción de variables","type":"docs"},{"authors":null,"categories":null,"content":"\rPresentación\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevante para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades.\n\rPreparacion de datos con ELSOC 2016\rLibrerías y configuración\rlibrary(dplyr)\r## ## Attaching package: \u0026#39;dplyr\u0026#39;\r## The following objects are masked from \u0026#39;package:stats\u0026#39;:\r## ## filter, lag\r## The following objects are masked from \u0026#39;package:base\u0026#39;:\r## ## intersect, setdiff, setequal, union\rrm(list=ls()) # borrar todos los objetos en el enviorment\roptions(scipen=999) #sin notacion cientifica\rCargar base de datos\r\rEjemplo de ruta, debe remplazarla por la de su computador.\r\rsetwd(\u0026quot;C:/usuario/usted/multivariada/materiales/01material\u0026quot;) \r# buscammos la sub carpeta ... datos/original/ELSOC_W01_v3.10.RData\rload(\u0026quot;data/original/ELSOC_W01_v3.10.RData\u0026quot;)\relsoc \u0026lt;- elsoc_2016; remove(elsoc_2016)\r# load(\u0026quot;link/ELSOC_W01_v3.10.RData\u0026quot;)\r\rDatos perdidos\r\rEn ELSOC todos los valores -888 y -999 corresponden a valores para las categorias “No sabe” y “No responde”, respectivamente.\rDecidimos dejarlas como valores perdidos (NA)\r\rfor (i in 1:ncol(elsoc)) {\relsoc[,i][elsoc[,i] == c(-888)] \u0026lt;- NA #Missing elsoc[,i][elsoc[,i] == c(-999)] \u0026lt;- NA #Missing }\r\r\rRecodificacion Variables percepcion de meritocracia\r\r[c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r[c18_10]: “Grado de acuerdo: Las personas son recompensada por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)\r\relsoc$c18_09 \u0026lt;- as.numeric(elsoc$c18_09) elsoc$c18_10 \u0026lt;- as.numeric(elsoc$c18_10) # Variables meritocracia promedio -----------------------------------------\relsoc \u0026lt;- rename(elsoc,meffort=c18_09) # cambio de nombre de la variable c18_09 a uno mas sustantivo elsoc \u0026lt;- rename(elsoc,mtalent=c18_10) # cambio de nombre de la variable c18_10 a uno mas sustantivo # creamos un indice promedio de percepcion de meritocracia usando ambas preguntas\relsoc$merit \u0026lt;- (elsoc$meffort+elsoc$mtalent)/2 # re escalamos la variable de 1-5 a una de 0 a 100 (para facilitar interpretacion) elsoc$merit \u0026lt;- (elsoc$merit-min(elsoc$merit,na.rm=T))/(max(elsoc$merit,na.rm=T)-min(elsoc$merit,na.rm=T))*100\r\rRecodificacion variable Estatus subjetivo\r\r[d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\r\relsoc$ess \u0026lt;- as.numeric(elsoc$d01_01) # Estatus Social Subjetivo\rtable(elsoc$ess)\rsummary(elsoc$ess)\r## ## 0 1 2 3 4 5 6 7 8 9 10 ## 44 84 207 439 677 975 310 116 37 4 22 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0.00 3.00 5.00 4.33 5.00 10.00 12\r\rRecodificacion variables Estatus objetivo\rIngresos del hogar\rsummary(elsoc$m29) # ingresos total ; NA == 587\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0 267500 420000 2477852 700000 4000000000 587\rsummary(elsoc$m30) # ingresos tramos \r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 3.000 6.000 7.415 11.000 20.000 2479\rsummary(elsoc$nhogar1) # tamannio del hogar\r## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 3.077 4.000 14.000\relsoc$m29[elsoc$m29==0] \u0026lt;- NA\r# Remplazar NA por media de categorias Ingreso -------------------------------#\relsoc$mean_tramos \u0026lt;- NA # creamos una variable vacia\r# remplazamos ...\relsoc$mean_tramos[elsoc$m30==1] \u0026lt;-110000\relsoc$mean_tramos[elsoc$m30==2] \u0026lt;-250000.5\relsoc$mean_tramos[elsoc$m30==3] \u0026lt;-305000.5\relsoc$mean_tramos[elsoc$m30==4] \u0026lt;-355000.5\relsoc$mean_tramos[elsoc$m30==5] \u0026lt;-400000.5\relsoc$mean_tramos[elsoc$m30==6] \u0026lt;-445000.5\relsoc$mean_tramos[elsoc$m30==7] \u0026lt;-490000.5\relsoc$mean_tramos[elsoc$m30==8] \u0026lt;-535000.5\relsoc$mean_tramos[elsoc$m30==9] \u0026lt;-585000.5\relsoc$mean_tramos[elsoc$m30==10]\u0026lt;-640000.5\relsoc$mean_tramos[elsoc$m30==11]\u0026lt;-700000.5\relsoc$mean_tramos[elsoc$m30==12]\u0026lt;-765000.5\relsoc$mean_tramos[elsoc$m30==13]\u0026lt;-845000.5\relsoc$mean_tramos[elsoc$m30==14]\u0026lt;-935000.5\relsoc$mean_tramos[elsoc$m30==15]\u0026lt;-1040000.5\relsoc$mean_tramos[elsoc$m30==16]\u0026lt;-1180000.5\relsoc$mean_tramos[elsoc$m30==17]\u0026lt;-1375000.5\relsoc$mean_tramos[elsoc$m30==18]\u0026lt;-1670000.5\relsoc$mean_tramos[elsoc$m30==19]\u0026lt;-2275000.5\relsoc$mean_tramos[elsoc$m30==20]\u0026lt;-3726106\rtable(elsoc$mean_tramos) # chequeamos\r## ## 110000 250000.5 305000.5 355000.5 400000.5 445000.5 490000.5 535000.5 ## 49 42 36 35 33 33 38 21 ## 585000.5 640000.5 700000.5 765000.5 845000.5 935000.5 1040000.5 1180000.5 ## 26 16 18 15 11 14 19 13 ## 1375000.5 1670000.5 2275000.5 3726106 ## 4 10 8 7\relsoc$m29 \u0026lt;- ifelse(test = (is.na(elsoc$m29)),#¿es el valor un NA? yes = elsoc$mean_tramos, #Si es verdadero, remplazar por el valor de mean_tramos\rno = elsoc$m29)# Si es falso, remplazar por el valor del m29\rsummary(elsoc$m29) # NA = 147\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 20000 280000 445000 2182986 700000 4000000000 147\r# cambiamos el nombre de las variables inghogar = m29; nhogar=nhogar1\relsoc \u0026lt;- rename(elsoc, inghogar=m29, nhogar=nhogar1) # ingreso neto = ingreso del hogar / numero de personas en el hogar\relsoc$ingneto \u0026lt;- as.numeric(elsoc$inghogar/elsoc$nhogar) # logaritmo natural del ingreso neto (para normalizar la distribucion sesgada del ingreso)\relsoc$lningneto \u0026lt;- log(elsoc$ingneto) summary(elsoc$ingneto)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 7500 95000 150000 1028152 267500 2000000000 147\rsummary(elsoc$lningneto)\r## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 8.923 11.462 11.918 12.006 12.497 21.416 147\r#---Deciles (ingreso per capita hogar)------------------------------------------------\relsoc \u0026lt;- elsoc %\u0026gt;% mutate(inc10h = ntile(inghogar, 10)) # Crear Deciles de ingreso\relsoc$D10h \u0026lt;- factor(elsoc$inc10h, levels = c(1,2,3,4,5,6,7,8,9,10), labels = c(\u0026quot;D01\u0026quot;,\u0026quot;D02\u0026quot;,\u0026quot;D03\u0026quot;,\u0026quot;D04\u0026quot;,\u0026quot;D05\u0026quot;,\r\u0026quot;D06\u0026quot;,\u0026quot;D07\u0026quot;,\u0026quot;D08\u0026quot;,\u0026quot;D09\u0026quot;,\u0026quot;D10\u0026quot;));table(elsoc$D10h)\r## ## D01 D02 D03 D04 D05 D06 D07 D08 D09 D10 ## 278 278 278 278 278 278 278 278 278 278\r\rEducación\rtable(elsoc$m01) # Educacion en ELSOC\r## ## 1 2 3 4 5 6 7 8 9 10 ## 37 322 297 394 857 102 381 186 303 46\rRecodificación CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1\r2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1\r3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2\r4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3\r5. Educacion Media o Humanidades completa = [CINE 3 ] = 3\r6. Tecnico Superior incompleta = [CINE 5 ] = 4\r7. Tecnico Superior completa = [CINE 5 ] = 4\r8. Universitaria incompleta = [CINE 6 ] = 5\r9. Universitaria completa = [CINE 6 ] = 6\r10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6\r# recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car elsoc$edcine \u0026lt;- car::recode(elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) round(prop.table(table(elsoc$edcine)), 3)\r## ## 1 2 3 4 5 ## 0.123 0.102 0.428 0.165 0.183\relsoc$edcine \u0026lt;- factor(elsoc$edcine,\rlevels = c(1,2,3,4,5),\rlabels=c(\u0026quot;Primaria incompleta menos\u0026quot;,\r\u0026quot;Primaria y secundaria baja\u0026quot;,\r\u0026quot;Secundaria alta\u0026quot;,\r\u0026quot;Terciaria ciclo corto\u0026quot;,\r\u0026quot;Terciaria y Postgrado\u0026quot;))\rtable(elsoc$edcine) #chequeamos\r## ## Primaria incompleta menos Primaria y secundaria baja ## 359 297 ## Secundaria alta Terciaria ciclo corto ## 1251 483 ## Terciaria y Postgrado ## 535\r\r\rVariables control\r#---Sexo----\relsoc$sexo \u0026lt;- car::recode(elsoc$m0_sexo, \u0026quot;1=1;2=0\u0026quot;)\relsoc$sexo \u0026lt;- factor(elsoc$sexo, levels = c(0,1), labels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;)) # Sexo\r#Hombre=0\r#Mujer=1\r#---Edad----\relsoc$edad \u0026lt;- as.numeric(elsoc$m0_edad) #Edad\r#---Posicion Politica----\r# PREGUNTA: \u0026quot;Autoubicacion escala izquierda-derecha\u0026quot; # (0 = izquierda; 10 = Derecha; 11 = Independiente; 12 =Ninguno)\relsoc$ppolcat \u0026lt;- car::recode(elsoc$c15, \u0026quot;c(0,1,2,3,4)=1;5=2;c(6,7,8,9,10)=3;11=4;12=5\u0026quot;) elsoc$ppolcat \u0026lt;- factor(elsoc$ppolcat, levels = c(1,2,3,4,5), labels = c(\u0026quot;Izquierda/Centro Izquierda\u0026quot;,\r\u0026quot;Centro\u0026quot;,\r\u0026quot;Derecha/Centro Derecha\u0026quot;,\r\u0026quot;Independiente\u0026quot;,\r\u0026quot;Ninguno\u0026quot;))\r\r\rMantener variables relevantes\r# selecccionamos las variables relevantes\relsoc_16 \u0026lt;- elsoc %\u0026gt;% dplyr::select(merit,ess,edcine,lningneto,D10h, sexo, edad,ppolcat) # dejamos solamente los casos con informacion completa (listwise deletion)\relsoc_16 \u0026lt;- na.omit(elsoc_16)\rnames(elsoc_16) # comprobamos los nombres de variables\r## [1] \u0026quot;merit\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;lningneto\u0026quot; \u0026quot;D10h\u0026quot; \u0026quot;sexo\u0026quot; ## [7] \u0026quot;edad\u0026quot; \u0026quot;ppolcat\u0026quot;\rhead(elsoc_16) #chequear\r## merit ess edcine lningneto D10h sexo edad ppolcat\r## 1 75.0 5 Primaria incompleta menos 11.22524 D03 Hombre 64 Independiente\r## 2 75.0 5 Secundaria alta 12.42922 D06 Hombre 60 Ninguno\r## 3 50.0 3 Secundaria alta 11.31040 D06 Hombre 26 Ninguno\r## 4 75.0 6 Terciaria y Postgrado 13.54763 D08 Mujer 51 Ninguno\r## 5 62.5 4 Secundaria alta 13.10216 D06 Mujer 69 Ninguno\r## 6 75.0 5 Secundaria alta 13.10216 D06 Mujer 62 Independiente\r# Guardar base de datos procesada ---------------------------------------------------------------\rsave(elsoc_16,file = \u0026quot;data/proc/ELSOC_ess_merit2016.RData\u0026quot;)\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585881306,"objectID":"96782a7dad874126bc6358fdb483b41e","permalink":"/assignment/01material/prep-datos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/01material/prep-datos/","section":"assignment","summary":"Presentación\rEl Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.","tags":null,"title":"Material 1. Procesamiento de datos en R","type":"assignment"},{"authors":null,"categories":null,"content":"\r\r\r\r\r\r Contenidos y Presentaciones\r Prácticas y evaluaciones\r Lecturas y material adicional\r\r\r\rABRIL \r\r\r\r\r3\r1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales\rPráctica 1: Preparación de datos\r- *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología\r\rMAYO \r\r\r\r\r15\r2. Bases/Repaso - Datos y variables - Preparación y descripción - Varianza y covarianza - Correlación (descriptiva)\rPráctica 2: Descripción de variables\r- Moore: 1.Comprensión de los datos (1-54)\r\r22\r3. Regresión simple I Distribución condicional\nMínimos cuadrados y recta de regresión\rPráctica 3: Correlación y regresión\r- Moore: 2. Análisis de relaciones (97-131) \r\r29\r4. Regresión simple II Regresión vs correlación Residuos y ajuste general (R2) Presentación pauta de Trabajo del curso\rPractica 4: Residuos y ajuste\r- Moore: Residuos (144-154)\r\rJUNIO \r\r\r\r\r5\rSemana preparación Informe 1\rInforme 1: Regresión simple (individual) 20%, entrega MIERCOLES 10\rEjemplo de informe aquí\r\r12\rSemana de receso\r\r\r\r19\r5. Regresión múltiple 1 - Introducción\rPráctica 5: Tabla de regresión múltiple\r- * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)\r\r26\r6. Regresión múltiple 2 - Coeficientes de regresión parcial - Correlación parcial y semiparcial \rPráctica 6: Parcialización y control estadístico\r- * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)\r\rJULIO \r\r\r\r\r03\r7. Regresión e inferencia - Conceptos y supuestos - Tabla ANOVA - Inferencia sobre coeficientes\rPráctica 6: Inferencia\r- Moore 7: Inferencia para medias (482-543)\r\r10\r8. Predictores e interpretación - Predictores categóricos - Selección de predictores, setwise \u0026amp; stepwise\rPráctica 7: Predictores\r- Wooldridge (2010) Cap 7: Análisis de regresión múltiple con información cualitativa (225-246)\r\r17\rSemana preparación informe 2\rInforme 2: Regresión múltiple (grupal) 30%, entrega Miércoles 29\r- * Wooldridge (2010) Cap 19: Realización de un proyecto empírico (668-694)\r\r\r\r\r\r\r24\rSemana de Receso\r\r\r\r31\r9. Regresión logística I - Probabilidades - Odds ratios\rPráctica 9: Probabilidades y Odds\rCamarero et al (2017) Regresión logística (1-29) \r\rAGOSTO \r\r\r\r\r07\r10. Regresión logística II - Estimación de parámetros - Inferencia - Predicción\rPráctica 10: Estimación logística\r- Camarero et al (2017) Regresión logística (30-52)\r\r14\r11. Detección y manejo de irregularidades en modelos de regresión - Relaciones no lineales -Transformaciones - Centrado\rPráctica 11: Chequeos de robustez\r- Darlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities - Darlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships\r\r21\r12. Repaso, pendientes y cierre de los contenidos Preparación Informe 3\rEntrega Informe 3: Regresión logística, predictores categóricos y supuestos (grupal) 50%.\rWooldridge cap 6 Temas adicionales\r\r\r\rExamen final: Semana del 7 de Septiembre\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593180783,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Contenidos y Presentaciones\r Prácticas y evaluaciones\r Lecturas y material adicional\r\r\r\rABRIL \r\r\r\r\r3\r1. Presentación - Programa y forma de trabajo  - Modelos y explicación en ciencias sociales\rPráctica 1: Preparación de datos\r- *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Salgado (2009) Construyendo explicaciones en sociología\r\rMAYO \r\r\r\r\r15\r2.","tags":null,"title":"Planificación","type":"page"},{"authors":null,"categories":null,"content":"\r\rPropósito general del curso\rCompetencias a las que contribuye el curso\rSub-Competencias\r\rResultados de Aprendizaje\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\rUNIDAD 2: Regresión Lineal Simple y Múltiple\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rMetodología (actualizado)\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rRequisitos de aprobación\rBibliografía\rTextos principales.\rMODELOS CIENTÍFICOS (Unidad 1)\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\r\rSoftware\rPlataformas de comunicación y discusión\rVARIOS\rProgramación de sesiones\r\r\rPropósito general del curso\rAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.\rSe espera que los estudiantes sean capaces de:\n\ridentificar las principales técnicas de análisis estadístico multivariado utilizadas en la investigación sociológica\rdepurar y preparar datos para la aplicación de distintas técnicas de análisis estadístico multivariado; corroborar las condiciones de aplicación de distintas técnicas de análisis estadístico multivariado\rutilizar software de análisis estadístico\rcontrastar hipótesis de investigación\relaborar reportes de resultados y conclusiones a partir de la aplicación de diferentes técnicas de análisis estadístico multivariado.\r\rComplementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos.\n\rCompetencias a las que contribuye el curso\r\rDiseñar y desarrollar estrategias de investigación social.\n\rComunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos.\n\r\rSub-Competencias\r\rDiseñar y aplicar diversas técnicas de recolección y producción de información empírica, pertinentes al objeto de estudio.\n\rInterpretar información empírica aplicando diversas técnicas, en función de un plan de análisis.\n\rDiseñar estrategias para comunicar los saberes disciplinares considerando las características de distintos contextos y audiencias.\n\rComunicar en forma oral y escrita los saberes disciplinares considerando distintos contextos y audiencias, haciendo un uso creativo de distintas estrategias.\n\r\r\r\rResultados de Aprendizaje\rAl finalizar el curso, los estudiantes:\n\rSerán capaces de explicar los conceptos y fundamentos teóricos y estadísticos de la investigación social basada en modelos predictivos para variables observadas y serán capaces de explicar su utilidad para la sociología.\rSerán capaces de preparar y depurar bases de datos para su análisis utilizando técnicas multivariadas, evaluando la pertinencia y la presencia de condiciones para la aplicación de modelos predictivos para variables observadas.\rSerán capaces de manejar software especializado y reportar los resultados de modelos predictivos para variables observadas cuantitativas y no cuantitativas.\r\r\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\r\rTipos de investigación (descriptiva vs relacional y explicativa) y su materialización en el análisis estadístico.\rLa explicación en ciencias sociales: su relación con el concepto de covariación; la explicación como dependencia robusta y como cadena causal y el trabajo con modelos.\rEl trabajo con modelos: tipos de modelos (modelo teórico, modelo normativo, modelo científico, modelo estadístico); la vinculación entre los modelos científicos y los modelos teóricos; los modelos estadísticos como tipo de modelo científico.\rCiencia abierta y modelamiento: transparencia, reproducibilidad y replicación.\r\r\rUNIDAD 2: Regresión Lineal Simple y Múltiple\r\rBases: varianza, covarianza y correlación.\rUsos y aplicaciones en ciencias sociales de la regresión lineal.\rSupuestos y condiciones de aplicación de la regresión lineal.\rManejo de casos influyentes\rProcedimientos de estimación e interpretación de parámetros.\rIntroducción de variables de control estadístico.\rCriterios de validez, capacidad predictiva y evaluación del ajuste de la regresión lineal.\rTemas avanzados de regresión lineal: introducción de predictores categóricos, estimación de efectos de interacción y mediación, y uso de herramientas gráficas como apoyo a la interpretación y análisis de datos.\r\r\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rLimitaciones de la regresión lineal y potencialidades de la introducción de variables dependientes categóricas.\rConcepto y sentido de la función logística y funciones afines.\rSupuestos y condiciones de aplicación de la regresión para variables categóricas.\rProcedimientos de estimación e interpretación de parámetros de regresión logística.\rCriterios de validez, capacidad predictiva y evaluación del ajuste de la regresión Logística.\rGeneralización de modelos de regresión logística: modelo de regresión logística multinomial y ordinal.\rEmpleo de otras matrices de correlación (tetracórica, biserial y policórica).\r\r\r\rMetodología (actualizado)\rEn las circunstancias excepcionales de este semestre dada la crisis santiaria, se han realizado una serie de ajustes metodológicos. De todas maneras estos se irán actualizando en el transcurso del semestre según varíe la contingencia y también atendiendio a necesidades y sugerencias de l_s participantes.\nTendremos tres espacios principales de aprendizaje:\nSesiones de clases: mientras dure la emergencia se realizaran online mediante la plataforma Zoom para las dos secciones; eventualmente algunas de las clases serán reemplazadas por videos explicativos. Todo el material de presentaciones se encontrará disponible en este sitio.\n\rPrácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana separados por secciones, para dar mayor oportunidad de participación y resolver las dudas respectivas. Estas prácticas serán supervisadas principalmente por los apoyos docentes.\n\rTrabajos: se desarrollarán trabajos de investigación durante el semestre (ver sección evaluación abajo) que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados principalmente por ayudantes que se asignarán a cada grupo.\n\r\r\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rEl curso tendrá tres instancias de evaluación:\n\rTrabajo 1 (individual): Correlación y regresión simple (20%).\rTrabajo 2 (grupal): Regresión multiple e inferencia estadística (30%)\rTrabajo 3 (grupal): Regresión logística, predictores categóricos y supuestos (50%)\r\rLa nota ponderada de los trabajos equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\n\rRequisitos de aprobación\rNota mínima de aprobación: 4,0 (en escala de 1 a 7).\nRequisitos de eximición de examen:\ncontar con un promedio ponderado igual o superior a 5.5.\rno tener nota bajo 4 en ninguno de los trabajos\r\rRequisitos para presentación a examen:\n\rPodrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\rEl examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0.\r\r\rBibliografía\rLa bibliografía obligatoria para cada semana se presenta en la planificación del curso, desde donde se puede acceder directamente a los documentos. De todas maneras, abajo algunos textos comentados y referencias para cada unidad.\nTextos principales.\rHay cuatro referencias principales recomendadas para este curso:\n\rMoore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch. No estaba en la bibliografía original, pero se incluye porque explica de manera bastante clara (y en español) una serie de análisis estadístico que sirven de base para este curso.\n\rDarlington, R. B., \u0026amp; Hayes, A. F. (2017). Regression analysis and linear models: concepts, applications, and implementation. Guilford Press. Este libro me parece un muy buen texto para acompañar un curso de regresión en ciencias sociales, lamentablemente está en inglés y por lo tanto solo es bibliografía sugerida. Los capítulos más relevantes estarán a disposición,\n\rWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning. Libro clásico de regresión para economístas, la ventaja es que está en español, la desventaja (para nosotros) es que en ocasiones utiliza un lenguaje y ejemplos lejanos a la sociología.\n\rWickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly. Libro con enfoque en el aprendizaje de R con técnicas que ciertamente van más allá del curso, pero muy util como referencia general. Además, está disponible también en español como “R para ciencia de datos”.\n\r\rAbajo bilbiografía recomendada para cada unidad\n\rMODELOS CIENTÍFICOS (Unidad 1)\r\rGarcía-Ferrando, M. (1985). Análisis y modelización causal en sociología. Reis, 29(1), 143-164.\rGoldthorpe, J. H. (2001). Causation, statistics, and sociology. European Sociological Review, 17(1), 1-20.\rRamón, L., \u0026amp; Ángeles, M. (2006). Estadística y causalidad en la sociología empírica del XX. Papers: revista de sociología, 80(1), 223-255.\rSalgado, M. (2009). Construyendo explicaciones: el uso de modelos en sociología. Persona y Sociedad, 30 (3), 29-60.\r\r\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\r\rEtxeberria, J. (1999). Regresión múltiple. Madrid: La Muralla.\rFox, J. \u0026amp; Weisberg, S. (2011) An R Companion to Applied Regression (149-183). London: Sage.\rPértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal múltiple. Cuadernos de atención primaria, 7(3), 173-176. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331162\rPértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal simple. Cuadernos de atención primaria, 7(2), 91-94. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331559\rGrolemund, G. \u0026amp; Wickam, H. (2017) R for Data Science. Disponible en: https://r4ds.had.co.nz/\r\r\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\r\rSilva LC, Barroso J. (2004). Regresión Logística. Cuaderno 27. Madrid: La Muralla.\rSilva LC. (1995). Excursión a la regresión logística en ciencias de la salud. Madrid: Díaz de Santos; 1995.\rJovell, A.J. (1995). Análisis de regresión logística, Cuadernos Metodológicos del CIS. Madrid.\r\r\r\rSoftware\rUsaremos R 4.0 a través de la interfaz de RStudio. También realizaremos ejercicios y prácticas online en RCloud.\n\rPlataformas de comunicación y discusión\r\rForos Ucursos\rEn evaluación\r\rDisqus\r\r\r\rVARIOS\r\rLas clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Materiales, y están desarrollados con base en Rmarkdown/XaringanRmarkdown/ Xaringan. Estos documentos no son:\n\r“la clase”\rautoexplicativos (ni aspiran a serlo)\r“el ppt” (ni mucho menos “la ppt”)\r\rPolíticas de participación y trato: se espera y enfatiza la participación por distintos canales disponibles. También se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo estan siendo, se solicita reportar para solucionar la situación.\n\r\r\rProgramación de sesiones\rVisitar la página de Planificación.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590119858,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/programa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/programa/","section":"","summary":"Propósito general del curso\rCompetencias a las que contribuye el curso\rSub-Competencias\r\rResultados de Aprendizaje\rSaberes / contenidos\rUNIDAD 1: Introducción al modelamiento de datos sociales\rUNIDAD 2: Regresión Lineal Simple y Múltiple\rUNIDAD 3: Regresión múltiple para variables dependientes categóricas\r\rMetodología (actualizado)\rEvaluación (actualizado) (detalles en pestaña Trabajos)\rRequisitos de aprobación\rBibliografía\rTextos principales.\rMODELOS CIENTÍFICOS (Unidad 1)\rMODELOS DE REGRESIÓN LINEAL (Unidad 2)\rMODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)\r\rSoftware\rPlataformas de comunicación y discusión\rVARIOS\rProgramación de sesiones\r\r\rPropósito general del curso\rAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.","tags":null,"title":"Programa","type":"page"},{"authors":null,"categories":null,"content":"\rRequired\r\rChapter 1 in Kieran Healy, Data Visualization [@Healy:2019]\rChapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)\r\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585881306,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"/reading/01-reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":"\rRequired\r\rChapter 1 in Kieran Healy, Data Visualization [@Healy:2019]\rChapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)\r\r\r","tags":null,"title":"Truth, Beauty, and Data","type":"reading"}]