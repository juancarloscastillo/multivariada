[{"authors":["juancastillo"],"categories":null,"content":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1615479945,"objectID":"5c580fbb5017138cb2136789294442fd","permalink":"/authors/juancastillo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/juancastillo/","section":"authors","summary":"Juan C. Castillo es profesor del Departamento de Sociología, Universidad de Chile.","tags":null,"title":"Juan Castillo","type":"authors"},{"authors":null,"categories":null,"content":"  Índice  Instrucciones generales para las prácticas Reportes de progreso Trabajo con software R  Instalación de R \u0026amp; RStudio Sobre el trabajo en hojas de código en RStudio Tutorial RCloud    Esta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas  Las instancia práctica consiste en el desarrollo de una guía práctica cada semana donde se aplican y profundizan los contenidos de las clases. La organización de estas prácticas se puede revisar en la planificación del curso.\n El trabajo con estas guías se organiza en los siguientes momentos:\n cada estudiante realiza la guía de manera autónoma durante la semana en caso de dudas que surjan durante la semana se recomienda preguntar en el foro de U-Cursos o preferentemente en el foro de Disqus al final de la página de cada práctica. en la sesión del día jueves se revisará la guía, se resolverán dudas y se entregaran complementos en caso de ser necesario. las sesiones de los jueves se realizarán en grupos pequeños guiados por ayudantes. Estos grupos serán inicialmente asignados al azar y luego corresponderan a los grupos conformados para realizar el trabajo final del curso. cada semana se completa un reporte de progreso (detalles abajo)  En las prácticas vamos a trabajar con el software R, Versión 4.0. Para su instalación consultar el video-tutorial disponible en la página de la práctica 1 (click aquí)\n   Reportes de progreso Este curso se caracteriza por el desarrollo secuencial y acumulativo de aprendizajes. En otras palabras, va a ser muy difícil poder lograr los objetivos de aprendizaje posteriores sin haber logrado los objetivos de contenidos previos. En otras palabras: es muy difícil aprender a multiplicar sin saber sumar. Por lo tanto, como equipo a cargo del curso nos interesa poder monitorear permanentemente el cumplimiento de objetivos de aprendizaje semana a semana para así poder prestar asesoría oportuna.\nEl sistema de monitoreo permanente de cumplimiento de objetivos se llevará a cabo mediante reportes de progreso. Un ejemplo de este reporte se ve así:\nLos reportes consisten en completar una encuesta simple y breve, donde se preguntará por el cumplimiento de los objetivos de las prácticas respectivas. El link para completar el reporte se encuentra al final de cada práctica. Se deben completar durante la semana en que se desarrolla la guía, a más tardar los días viernes (ya que ese día se publican las guías prácticas correspondientes a la semana siguiente).\nComo incentivo para completar los reportes de progreso, se entregarán dos décimas adicionales a la evaluación a quienes tengan sus reportes de progreso completados entre instancias de evaluación (por ejemplo, en el caso de la evaluación 2 se deben tener todos los reportes de progreso completados entre la evaluación 1 y 2).\n Trabajo con software R Para los análisis estadísticos de este curso usamos el programa R, principalmente porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n trabajar con la misma y última versión de R, que es la 4.0\n evitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variable\n al momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\nCódigo completo hasta que se produce el problema Indicar línea del código donde se produce el problema Adjuntar el resultado del output de la información de la sesión (sessionInfo())   Instalación de R \u0026amp; RStudio Para esta versión del curso vamos a trabajar con el programa R Version 4.0 (se sugiere la última versión de Febrero 2021, 4.0.4) y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://rstudio.com/products/rstudio/ y bajar/instalar RStudio desktop, Open Source License (libre).\n Sobre el trabajo en hojas de código en RStudio  El trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File \u0026gt; New File \u0026gt; R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\n Los contenidos de las hojas de código son básicamente 2:\n comandos o funciones: se escriben en la hoja, y para ejecutarlos posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola. texto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #  Para grabar nuestra hoja de código y así respaldar nuestros análisis, File \u0026gt; Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R\n   Tutorial RCloud RCloud permite trabajar con RStudio en línea, sin necesidad de instalar localmente. Puede ser muy útil para quienes tengan problemas de instalación, así como también para trabajo colaborativo. Tenemos a disposición una página tutorial de cómo usar RCloud.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1616091116,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"Índice  Instrucciones generales para las prácticas Reportes de progreso Trabajo con software R  Instalación de R \u0026amp; RStudio Sobre el trabajo en hojas de código en RStudio Tutorial RCloud    Esta página contiene los materiales de los contenidos de cada sesión (documento de presentación, lecturas, links), y también las guías prácticas.\nTodo el material es accesible desde el menú de la izquierda \u0026lt;–\nInstrucciones generales para las prácticas  Las instancia práctica consiste en el desarrollo de una guía práctica cada semana donde se aplican y profundizan los contenidos de las clases.","tags":null,"title":"Contenidos","type":"docs"},{"authors":null,"categories":null,"content":"  If I assign readings, you really should read them.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1615479945,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"If I assign readings, you really should read them.","tags":null,"title":"Reading","type":"docs"},{"authors":null,"categories":null,"content":"  Aquí se accede a las distintas guías prácticas desde el menú de la izquierda  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1615479945,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"  Aquí se accede a las distintas guías prácticas desde el menú de la izquierda  ","tags":null,"title":"Prácticas","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de clase Lecturas   Documento presentación   Video de clase Próximamente aquí  ---    Lecturas  Moore: 1.Comprensión de los datos (1-54)   ","date":1616716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616763664,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"/class/02-class/","publishdate":"2021-03-26T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":"  Índice  Documento presentación Video de clase Lecturas   Documento presentación   Video de clase Próximamente aquí  ---    Lecturas  Moore: 1.Comprensión de los datos (1-54)   ","tags":null,"title":"Bases","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Código de análisis  1. Librerías 2. Cargar base de datos 3. Descripción de variables  3.1 Tabla descriptiva de variables para sección metodológica 3.2 Exploración de asociación entre variables  Nota final: Información de la sesión de R  Resumen Práctica 2: Descripción de variables Reporte de progreso Archivo de código Foro práctica 2    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Esta segunda práctica tiene por objetivo repasar algunos conceptos básicos de los cursos anteriores de Estadística Descriptiva y Estadística Correlacional. Asume como base el desarrollo de la Práctica 1, a la cual se hará referencia permanente.\nEn la Práctica 1 se desarrolló un código de preparación de datos que generó una base de datos procesada para el análisis. En esta Práctica 2 comenzamos con el segundo momento de procesamiento de datos, que es el análisis propiamente tal. El análisis se divide en descripción de variables y contraste de hipótesis. En esta práctica nos enfocaremos en la primera fase, que llega hasta el punto 3 del código de análisis:\nAl igual que el Código de Preparación, el Código de Análisis posee una estructura definida. En este caso son 4 partes, donde las primeras son similares al código de preparación:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento Librerías principales (de R) a utilizar en el análisis Datos (que provienen de los preparados en la fase anterior) Descripción de variables  Tabla general de variables para la sección metodológica del reporte Exploración descriptiva de relaciones entre variables  Contraste de hipótesis / inferencia estadística según la técnica que corresponda  Al final de esta práctica la idea es que cada un_ pueda avanzar hasta el punto 3 del Código de Análisis. El punto 4 (contraste de hipótesis) se desarrollará más adelante en este curso con énfasis en la técnica de regresión.\n Código de análisis 1. Librerías La explicación de esta parte del código se encuentra en la sección correspondiente de la práctica 1.pacman::p_load\npacman::p_load(dplyr, #Manipulacion de datos  stargazer, #Tablas  sjmisc, # Tablas  summarytools, # Tablas  kableExtra, #Tablas  sjPlot, #Tablas y gráficos  corrplot, # Correlaciones  sessioninfo) # Información de la sesión de trabajo  2. Cargar base de datos Vamos a cargar la base de datos ELSOC_ess_merit2016.Rproc_elsoc, que generamos durante la práctica 1. Se puede llamar desde el directorio en que se guardó anteriormente dando la ruta completa:\nload(\u0026quot;ruta-hacia-carpeta-local/ELSOC_ess_merit2016.RData\u0026quot;) #Cargar base de datos O también para esta práctica la podemos llamar directamente desde nuestro sitio web:\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)) #Cargar base de datos  Exploración inicial general de la base de datos  names(proc_elsoc) # Muestra los nombres de las variables de la base de datos ## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot; dim(proc_elsoc) # Dimensiones ## [1] 2927 7 En el caso de esta base, 2927 casos y 7 variables\nRecordando el contenido de cada variable preparada en la práctica 1:\n [merit] = Indice promedio de percepción de meritocracia.\n [ess] = Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\" (0 = el nivel mas bajo; 10 = el nivel mas alto)\n [edcine] = Nivel educacional(1 = Primaria incompleta menos, 2 = Primaria y secundaria baja, 3 = Secundaria alta, 4 = Terciaria ciclo corto, 5 = Terciaria y Postgrado)\n [sexo] = Sexo (O = Hombre; 1 = Mujer)\n [edad] = ¿Cuáles su edad? (años cumplidos)\n   3. Descripción de variables Los resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n en la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\n en la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n  3.1 Tabla descriptiva de variables para sección metodológica A continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\nstargazer(proc_elsoc,type = \u0026quot;text\u0026quot;) ## ## ============================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## -------------------------------------------------------------- ## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000 ## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## -------------------------------------------------------------- Algunas observaciones sobre esta tabla:\n La opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\n Una distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.60) es la proporción de mujeres vs hombres. En otras palabras, hay un 60% de mujeres y 40% de hombres en la muestra.\n  b. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\nsjmisc::descr(proc_elsoc) ## ## ## Basic descriptive statistics ## ## var type label n NA.prc mean sd se md ## mesfuerzo numeric Recompensa: esfuerzo 2909 0.61 2.57 1.05 0.02 2.0 ## mtalento numeric Recompensa: talento 2907 0.68 2.74 1.06 0.02 3.0 ## ess numeric Estatus Social Subjetivo 2915 0.41 4.33 1.57 0.03 5.0 ## edcine numeric Educación 2925 0.07 3.18 1.21 0.02 3.0 ## sexo numeric Sexo 2927 0.00 0.60 0.49 0.01 1.0 ## edad numeric Edad 2927 0.00 46.09 15.29 0.28 46.0 ## pmerit numeric Meritocracia promedio 2898 0.99 2.65 0.97 0.02 2.5 ## trimmed range skew ## 2.56 4 (1-5) 0.42 ## 2.76 4 (1-5) 0.18 ## 4.36 10 (0-10) -0.01 ## 3.23 4 (1-5) -0.15 ## 0.63 1 (0-1) -0.42 ## 45.90 70 (18-88) 0.07 ## 2.66 4 (1-5) 0.26 En este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en una práctica posterior):\nsjmisc::descr(proc_elsoc,  show = c(\u0026quot;label\u0026quot;,\u0026quot;range\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;n\u0026quot;))%\u0026gt;% kable(.,\u0026quot;markdown\u0026quot;)    var label n NA.prc mean sd range    4 mesfuerzo Recompensa: esfuerzo 2909 0.6149641 2.5727054 1.0466874 4 (1-5)  5 mtalento Recompensa: talento 2907 0.6832935 2.7389061 1.0596182 4 (1-5)  3 ess Estatus Social Subjetivo 2915 0.4099761 4.3300172 1.5666965 10 (0-10)  2 edcine Educación 2925 0.0683293 3.1839316 1.2066058 4 (1-5)  7 sexo Sexo 2927 0.0000000 0.6026648 0.4894300 1 (0-1)  1 edad Edad 2927 0.0000000 46.0908780 15.2867983 70 (18-88)  6 pmerit Meritocracia promedio 2898 0.9907755 2.6538992 0.9694792 4 (1-5)    c. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\ndfSummary(proc_elsoc, plain.ascii = FALSE) ## ### Data Frame Summary ## #### proc_elsoc ## **Dimensions:** 2927 x 7 ## **Duplicates:** 396 ## ## ---------------------------------------------------------------------------------------------------------------------------------------- ## No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing ## ---- ------------ -------------------------- -------------------------- ---------------------- -------------------- ---------- --------- ## 1 mesfuerzo\\ Recompensa: esfuerzo Mean (sd) : 2.6 (1)\\ 1 : 357 (12.3%)\\ II \\ 2909\\ 18\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1331 (45.8%)\\ IIIIIIIII \\ (99.39%) (0.61%) ## 1 \u0026lt; 2 \u0026lt; 5\\ 3 : 497 (17.1%)\\ III \\ ## IQR (CV) : 1 (0.4) 4 : 646 (22.2%)\\ IIII \\ ## 5 : 78 ( 2.7%) ## ## 2 mtalento\\ Recompensa: talento Mean (sd) : 2.7 (1.1)\\ 1 : 288 ( 9.9%)\\ I \\ 2907\\ 20\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 1163 (40.0%)\\ IIIIIIII \\ (99.32%) (0.68%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 559 (19.2%)\\ III \\ ## IQR (CV) : 2 (0.4) 4 : 814 (28.0%)\\ IIIII \\ ## 5 : 83 ( 2.9%) ## ## 3 ess\\ Estatus Social Subjetivo Mean (sd) : 4.3 (1.6)\\ 11 distinct values \\ 2915\\ 12\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ \\ \\ \\ \\ \\ \\ :\\ (99.59%) (0.41%) ## 0 \u0026lt; 5 \u0026lt; 10\\ \\ \\ \\ \\ \\ \\ . :\\ ## IQR (CV) : 2 (0.4) \\ \\ \\ \\ . : :\\ ## \\ \\ \\ \\ : : : .\\ ## . : : : : : . ## ## 4 edcine\\ Educación Mean (sd) : 3.2 (1.2)\\ 1 : 359 (12.3%)\\ II \\ 2925\\ 2\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 2 : 297 (10.2%)\\ II \\ (99.93%) (0.07%) ## 1 \u0026lt; 3 \u0026lt; 5\\ 3 : 1251 (42.8%)\\ IIIIIIII \\ ## IQR (CV) : 1 (0.4) 4 : 483 (16.5%)\\ III \\ ## 5 : 535 (18.3%) III ## ## 5 sexo\\ Sexo Min : 0\\ 0 : 1163 (39.7%)\\ IIIIIII \\ 2927\\ 0\\ ## [numeric] Mean : 0.6\\ 1 : 1764 (60.3%) IIIIIIIIIIII (100%) (0%) ## Max : 1 ## ## 6 edad\\ Edad Mean (sd) : 46.1 (15.3)\\ 63 distinct values \\ 2927\\ 0\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ \\ \\ . . . : :\\ (100%) (0%) ## 18 \u0026lt; 46 \u0026lt; 88\\ . : : : : : .\\ ## IQR (CV) : 25 (0.3) : : : : : : : :\\ ## : : : : : : : :\\ ## : : : : : : : : . ## ## 7 pmerit\\ Meritocracia promedio Mean (sd) : 2.7 (1)\\ 1.00 : 243 ( 8.4%)\\ I \\ 2898\\ 29\\ ## [numeric] min \u0026lt; med \u0026lt; max:\\ 1.50 : 79 ( 2.7%)\\ \\ (99.01%) (0.99%) ## 1 \u0026lt; 2.5 \u0026lt; 5\\ 2.00 : 1041 (35.9%)\\ IIIIIII \\ ## IQR (CV) : 1.5 (0.4) 2.50 : 222 ( 7.7%)\\ I \\ ## 3.00 : 536 (18.5%)\\ III \\ ## 3.50 : 169 ( 5.8%)\\ I \\ ## 4.00 : 528 (18.2%)\\ III \\ ## 4.50 : 38 ( 1.3%)\\ \\ ## 5.00 : 42 ( 1.5%) ## ---------------------------------------------------------------------------------------------------------------------------------------- Es muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\nview(dfSummary(proc_elsoc, headings=FALSE))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 mesfuerzo [numeric] Recompensa: esfuerzo Mean (sd) : 2.6 (1) min 1:357(12.3%)2:1331(45.8%)3:497(17.1%)4:646(22.2%)5:78(2.7%)  2909 (99.39%) 18 (0.61%)   2 mtalento [numeric] Recompensa: talento Mean (sd) : 2.7 (1.1) min 1:288(9.9%)2:1163(40.0%)3:559(19.2%)4:814(28.0%)5:83(2.9%)  2907 (99.32%) 20 (0.68%)   3 ess [numeric] Estatus Social Subjetivo Mean (sd) : 4.3 (1.6) min 11 distinct values  2915 (99.59%) 12 (0.41%)   4 edcine [numeric] Educaci\u0026#0243;n Mean (sd) : 3.2 (1.2) min 1:359(12.3%)2:297(10.2%)3:1251(42.8%)4:483(16.5%)5:535(18.3%)  2925 (99.93%) 2 (0.07%)   5 sexo [numeric] Sexo Min : 0 Mean : 0.6 Max : 1 0:1163(39.7%)1:1764(60.3%)  2927 (100%) 0 (0%)   6 edad [numeric] Edad Mean (sd) : 46.1 (15.3) min 63 distinct values  2927 (100%) 0 (0%)   7 pmerit [numeric] Meritocracia promedio Mean (sd) : 2.7 (1) min 1.00:243(8.4%)1.50:79(2.7%)2.00:1041(35.9%)2.50:222(7.7%)3.00:536(18.5%)3.50:169(5.8%)4.00:528(18.2%)4.50:38(1.3%)5.00:42(1.5%)  2898 (99.01%) 29 (0.99%)    Generated by summarytools 0.9.6 (R version 3.6.0)2020-04-23\n Nota sobre casos perdidos (NAs) na.omit(data) Hasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n respaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_elsoc_original. contamos el número de casos con el comando dim contamos el número de casos perdidos con sum(is.na(proc_elsoc)) borramos los casos perdidos con proc_elsoc \u0026lt;-na.omit(proc_elsoc) contamos nuevamente con dim para asegurarnos que se borraron y por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.  proc_elsoc_original \u0026lt;-proc_elsoc dim(proc_elsoc) ## [1] 2927 7 sum(is.na(proc_elsoc)) ## [1] 81 proc_elsoc \u0026lt;-na.omit(proc_elsoc) dim(proc_elsoc) ## [1] 2887 7 proc_elsoc \u0026lt;-sjlabelled::copy_labels(proc_elsoc,proc_elsoc_original)   3.2 Exploración de asociación entre variables Dado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivio que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n Variables categóricas: tabla de contingencia Variable categórica y continua: tabla de promedios por cada categoría Variables continuas: correlaciones.  En esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\nTablas de contingencia para variables categóricas Para tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo)  Educación  Sexo  Total    Hombre  Mujer    Primaria incompleta\nmenos  102  247  349    Primaria y\nsecundaria baja  105  186  291    Secundaria alta  511  727  1238    Terciaria ciclo\ncorto  186  292  478    Terciaria y\nPostgrado  245  286  531    Total  1149  1738  2887   χ2=28.154 · df=4 · Cramer’s V=0.099 · p=0.000    Al ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\nsjt.xtab(proc_elsoc$edcine, proc_elsoc$sexo,  show.col.prc=TRUE,  show.summary=FALSE )  Educación  Sexo  Total    Hombre  Mujer    Primaria incompleta\nmenos  102\n8.9 %  247\n14.2 %  349\n12.1 %    Primaria y\nsecundaria baja  105\n9.1 %  186\n10.7 %  291\n10.1 %    Secundaria alta  511\n44.5 %  727\n41.8 %  1238\n42.9 %    Terciaria ciclo\ncorto  186\n16.2 %  292\n16.8 %  478\n16.6 %    Terciaria y\nPostgrado  245\n21.3 %  286\n16.5 %  531\n18.4 %    Total  1149\n100 %  1738\n100 %  2887\n100 %     Tablas de promedio de variable continua por una categóricas En ejemplo vamos a explorar datos de nuestra variable de percepción de meritocracia pmerit por los niveles educacionales edcine.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\ntapply(proc_elsoc$pmerit, proc_elsoc$edcine, mean) ## 1 2 3 4 5 ## 2.968481 2.697595 2.662763 2.479079 2.559322 Aquí vemos en promedio de pmerit para cada uno de los 5 niveles de la variable educación edcine. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %\u0026gt;%. El sentido de cada función aparece comentado abajo:\nproc_elsoc %\u0026gt;%# se especifica la base de datos select(pmerit,edcine) %\u0026gt;%# se seleccionan las variables dplyr::group_by(Educación=sjlabelled::as_label(edcine)) %\u0026gt;%# se agrupan por la variable categórica y se usan sus etiquetas con as_label dplyr::summarise(Obs.=n(),Promedio=mean(pmerit),SD=sd(pmerit)) %\u0026gt;%# se agregan las operaciones a presentar en la tabla kable(, format = \u0026quot;markdown\u0026quot;) # se genera la tabla   Educación Obs. Promedio SD    Primaria incompleta menos 349 2.968481 0.9828315  Primaria y secundaria baja 291 2.697595 1.0041093  Secundaria alta 1238 2.662762 0.9685655  Terciaria ciclo corto 478 2.479080 0.9431323  Terciaria y Postgrado 531 2.559322 0.9223446    Esta asocación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función plot_grpfrq de sjPlot:sjPlot::plot_grpfrq\nplot_grpfrq(proc_elsoc$pmerit,proc_elsoc$edcine,  type = \u0026quot;box\u0026quot;)  Correlaciones (variables continuas) Algunas notas sobre correlación:\n El coeficiente de correlación mide la fuerza de la relación lineal entre dos variable continuas. Esta puede ser:\n positiva: a medida que aumenta una, aumenta la otra (ej: estatura y edad) negativa: a medida que una aumenta, disminuye la otra (ej: tiempo dedicado al estudio y probabilidad de reprobar) neutra: no hay asociación entre variables.  El rango de variación del coeficiente de correlación va desde -1 (correlación negativa perfecta) y 1 (correlación positiva perfecta).\n Existen diferentes formas de cálculo del coeficiente de correlación (Spearman, Kendall, Pearson).\n En el coeficiente de correlación se analiza tanto su tamaño como su significación estadística.\n  En lo que sigue nos concentraremos en el coeficiente de correlación más utilizado que es el de Pearson, que se aplica cuando las variables son de naturaleza continua.\nTablas/matrices de correlación\nLas correlaciones entre variables se presentan en general en modo de matrices, es decir, las variables se presentan en las filas y las columnas y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a lacor base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\nM \u0026lt;-cor(proc_elsoc) M ## mesfuerzo mtalento ess edcine sexo ## mesfuerzo 1.000000000 0.69768811 -0.004312135 -0.12167659 -0.04480502 ## mtalento 0.697688106 1.00000000 0.018447696 -0.10582754 -0.03759340 ## ess -0.004312135 0.01844770 1.000000000 0.28959248 -0.03745546 ## edcine -0.121676591 -0.10582754 0.289592479 1.00000000 -0.08682644 ## sexo -0.044805024 -0.03759340 -0.037455462 -0.08682644 1.00000000 ## edad 0.096495547 0.07383771 -0.066031873 -0.37660283 0.06121699 ## pmerit 0.920404032 0.92224547 0.007740598 -0.12341680 -0.04469515 ## edad pmerit ## mesfuerzo 0.09649555 0.920404032 ## mtalento 0.07383771 0.922245465 ## ess -0.06603187 0.007740598 ## edcine -0.37660283 -0.123416804 ## sexo 0.06121699 -0.044695146 ## edad 1.00000000 0.092369792 ## pmerit 0.09236979 1.000000000 Este es el reporte simple, pero no muy amigable a la vista. Para una versión más amable utilizamos la función sjt.corrsjPlot::sjt.corr:NOTA: sjPlot actualizó su librería a fines de Mayo (versión 2.8.4); para quienes hayan actualizado a esta versión, la función para tabla de correlaciones ahora es tab_corr\nsjt.corr(proc_elsoc)   Recompensa: esfuerzo  Recompensa: talento  Estatus Social Subjetivo  Educación  Sexo  Edad  Meritocracia promedio    Recompensa: esfuerzo   0.698***  -0.004  -0.122***  -0.045*  0.096***  0.920***    Recompensa: talento  0.698***   0.018  -0.106***  -0.038*  0.074***  0.922***    Estatus Social Subjetivo  -0.004  0.018   0.290***  -0.037*  -0.066***  0.008    Educación  -0.122***  -0.106***  0.290***   -0.087***  -0.377***  -0.123***    Sexo  -0.045*  -0.038*  -0.037*  -0.087***   0.061**  -0.045*    Edad  0.096***  0.074***  -0.066***  -0.377***  0.061**   0.092***    Meritocracia promedio  0.920***  0.922***  0.008  -0.123***  -0.045*  0.092***     Computed correlation used pearson-method with listwise-deletion.    Con esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n En esta matriz las variables están representadas en las filas y en las columnas. Cada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de recompensa por esfuerzo y recompensa por inteligencia es 0.698. La información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno. En la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva. En esta tabla se omiten y aparece la diagonal vacía, ya que es información redundante. Por lo mismo, también se recomienda eliminar el triangulo superior de la tabla (redundante) de la siguiente manera:  sjt.corr(proc_elsoc,  triangle = \u0026quot;lower\u0026quot;)   Recompensa: esfuerzo  Recompensa: talento  Estatus Social Subjetivo  Educación  Sexo  Edad  Meritocracia promedio    Recompensa: esfuerzo           Recompensa: talento  0.698***          Estatus Social Subjetivo  -0.004  0.018         Educación  -0.122***  -0.106***  0.290***        Sexo  -0.045*  -0.038*  -0.037*  -0.087***       Edad  0.096***  0.074***  -0.066***  -0.377***  0.061**      Meritocracia promedio  0.920***  0.922***  0.008  -0.123***  -0.045*  0.092***     Computed correlation used pearson-method with listwise-deletion.    Una segunda forma de presentar matrices de correlaciones es de manera gráfica con la librería corrplot, cuya función corrplot.mixed corrplot::corrplot.mixedse aplica al objeto que generamos con la función cor (M):\ncorrplot.mixed(M) Este gráfico/matriz representa el grado de asociación entre variables mediante el tamaño de los círculos e intensidad de colores, y el signo de la asociación se representa con una gradiente de colores que va del azul (positivo) al rojo (negativo). Bajo la diagonal aparecen los indices de correlación entre pares de variables.\nFinalmente, también se puede representar la correlación entre dos variables en un gráfico de nube de puntos o scatterplot:sjPlot::plot_scatter\nnames(proc_elsoc) ## [1] \u0026quot;mesfuerzo\u0026quot; \u0026quot;mtalento\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;sexo\u0026quot; \u0026quot;edad\u0026quot; ## [7] \u0026quot;pmerit\u0026quot; plot_scatter(proc_elsoc, edad, ess) Donde:\n cada punto representa un caso la forma de la nube indica si la asociación es positiva, negativa o neutra:  En el caso de nuestra nube de puntos entre edad y estatus social subjetivo, observamos que no hay asociación (lo que ya era indicado por su correlación de -0.07 observada en la matriz de correlaciones).\n   Nota final: Información de la sesión de R R y sus librerías tienen distintas versiones. Esto puede representar algunos problemas de compatibilidad entre usuarios, por ejemplo, dos personas que trabajan en el mismo proyecto pero con distintas versiones (librerías y/o de R), pueden tener ocasionalmente complicaciones. Por eso, una buena práctica es registrar al final del código la información de la sesión. Y como siempre en R, varias maneras de hacer esto. Vamos con la más genérica que es muy simple: sessionInfo() sessionInfo()\nsessionInfo() ## R version 4.0.0 (2020-04-24) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 16.04.6 LTS ## ## Matrix products: default ## BLAS: /usr/lib/libblas/libblas.so.3.6.0 ## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=es_CL.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=es_CL.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=es_CL.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=es_CL.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] sessioninfo_1.1.1 corrplot_0.84 sjmisc_2.8.4 summarytools_0.9.6 ## [5] sjstats_0.18.0 psych_1.9.12.31 Publish_2019.12.04 prodlim_2019.11.13 ## [9] ggpubr_0.3.0 magrittr_1.5 car_3.0-7 carData_3.0-3 ## [13] scales_1.1.1 gridExtra_2.3 ggplot2_3.3.0 stargazer_5.2.2 ## [17] sjPlot_2.8.3 kableExtra_1.1.0 Rmisc_1.5 plyr_1.8.6 ## [21] lattice_0.20-41 dplyr_0.8.5 knitr_1.28 pacman_0.5.1 ## ## loaded via a namespace (and not attached): ## [1] TH.data_1.0-10 minqa_1.2.4 colorspace_1.4-1 pryr_0.1.4 ## [5] ggsignif_0.6.0 ellipsis_0.3.0 rio_0.5.16 sjlabelled_1.1.4 ## [9] estimability_1.3 parameters_0.6.1 base64enc_0.1-3 rstudioapi_0.11 ## [13] fansi_0.4.1 mvtnorm_1.1-0 lubridate_1.7.8 xml2_1.3.2 ## [17] codetools_0.2-16 splines_4.0.0 mnormt_1.5-7 nloptr_1.2.2.1 ## [21] ggeffects_0.14.3 broom_0.5.6 effectsize_0.3.0 readr_1.3.1 ## [25] compiler_4.0.0 httr_1.4.1 emmeans_1.4.6 backports_1.1.7 ## [29] assertthat_0.2.1 Matrix_1.2-18 cli_2.0.2 htmltools_0.4.0 ## [33] tools_4.0.0 coda_0.19-3 gtable_0.3.0 glue_1.4.1 ## [37] Rcpp_1.0.4.6 cellranger_1.1.0 vctrs_0.3.0 nlme_3.1-147 ## [41] blogdown_0.18 insight_0.8.4 xfun_0.13 stringr_1.4.0 ## [45] openxlsx_4.1.5 lme4_1.1-23 rvest_0.3.5 lifecycle_0.2.0 ## [49] statmod_1.4.34 rstatix_0.5.0 MASS_7.3-51.6 zoo_1.8-8 ## [53] hms_0.5.3 parallel_4.0.0 sandwich_2.5-1 yaml_2.2.1 ## [57] curl_4.3 pander_0.6.3 stringi_1.4.6 bayestestR_0.6.0 ## [61] checkmate_2.0.0 boot_1.3-25 zip_2.0.4 lava_1.6.7 ## [65] rlang_0.4.6 pkgconfig_2.0.3 matrixStats_0.56.0 evaluate_0.14 ## [69] purrr_0.3.4 rapportools_1.0 tidyselect_1.1.0 bookdown_0.18 ## [73] R6_2.4.1 magick_2.3 generics_0.0.2 multcomp_1.4-13 ## [77] pillar_1.4.4 haven_2.2.0 foreign_0.8-79 withr_2.2.0 ## [81] survival_3.1-12 abind_1.4-5 tibble_3.0.1 performance_0.4.6 ## [85] modelr_0.1.7 crayon_1.3.4 rmarkdown_2.1 grid_4.0.0 ## [89] readxl_1.3.1 data.table_1.12.8 forcats_0.5.0 digest_0.6.25 ## [93] webshot_0.5.2 xtable_1.8-4 tidyr_1.0.3 munsell_0.5.0 ## [97] viridisLite_0.3.0 tcltk_4.0.0 Acá vemos un listado de información muy completo, desde versión de R, sistema operativo, opciones de idioma local (LOCALE), y muchas librerías. Si optamos por esta versión de la información de la sesión, lo importante es fijarse en (a) version de R, y (b) de las librerías cargadas al principio, que aquí aparecen bajo “other attached packages”.\nLa segunda opción permite obtener información más precisa, con sessioninfo sessioninfo()(la única diferencia con la anterior en el nombre es que info es con minúscula sessioninfo). Con un poco más de especificaciones de sintaxis se pueden obtener directamente los puntos (a) y (b) mencionados anteriormente:\nsession_info(\u0026quot;sessioninfo\u0026quot;)$platform ## setting value ## version R version 4.0.0 (2020-04-24) ## os Ubuntu 16.04.6 LTS ## system x86_64, linux-gnu ## ui X11 ## language en_US ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/Santiago ## date 2020-05-16 package_info(pkgs = (.packages()), dependencies = FALSE) ## package * version date lib source ## car * 3.0-7 2020-03-11 [1] CRAN (R 4.0.0) ## carData * 3.0-3 2019-11-16 [1] CRAN (R 4.0.0) ## corrplot * 0.84 2017-10-16 [1] CRAN (R 4.0.0) ## dplyr * 0.8.5 2020-03-07 [1] CRAN (R 4.0.0) ## ggplot2 * 3.3.0 2020-03-05 [1] CRAN (R 4.0.0) ## ggpubr * 0.3.0 2020-05-04 [1] CRAN (R 4.0.0) ## gridExtra * 2.3 2017-09-09 [1] CRAN (R 4.0.0) ## kableExtra * 1.1.0 2019-03-16 [1] CRAN (R 4.0.0) ## knitr * 1.28 2020-02-06 [1] CRAN (R 4.0.0) ## lattice * 0.20-41 2020-04-02 [1] CRAN (R 4.0.0) ## magrittr * 1.5 2014-11-22 [1] CRAN (R 4.0.0) ## pacman * 0.5.1 2019-03-11 [1] CRAN (R 4.0.0) ## plyr * 1.8.6 2020-03-03 [1] CRAN (R 4.0.0) ## prodlim * 2019.11.13 2019-11-17 [1] CRAN (R 4.0.0) ## psych * 1.9.12.31 2020-01-08 [1] CRAN (R 4.0.0) ## Publish * 2019.12.04 2019-12-04 [1] CRAN (R 4.0.0) ## Rmisc * 1.5 2013-10-22 [1] CRAN (R 4.0.0) ## scales * 1.1.1 2020-05-11 [1] CRAN (R 4.0.0) ## sessioninfo * 1.1.1 2018-11-05 [1] CRAN (R 4.0.0) ## sjmisc * 2.8.4 2020-04-03 [1] CRAN (R 4.0.0) ## sjPlot * 2.8.3 2020-03-09 [1] CRAN (R 4.0.0) ## sjstats * 0.18.0 2020-05-06 [1] CRAN (R 4.0.0) ## stargazer * 5.2.2 2018-05-30 [1] CRAN (R 4.0.0) ## summarytools * 0.9.6 2020-03-02 [1] CRAN (R 4.0.0) ## ## [1] /home/juank/Dropbox/Rlibrary ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library   Resumen Práctica 2: Descripción de variables En esta práctica revisamos los siguientes contenidos:\n tabla descriptiva general de variables tabla de asociación (o contingencia) entre dos variables categóricas tabla y gráfico de asociación entre variables categóricas y contínuas asociaciones entre pares de variables continuas mediante el índice de correlación.   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí\n Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Foro práctica 2  ","date":1616716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616763664,"objectID":"112494b1f3727cfe1df8f164d59d3152","permalink":"/assignment/02-code/","publishdate":"2021-03-26T00:00:00Z","relpermalink":"/assignment/02-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"Práctica 2. Descripción de variables","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo Librerías Datos  Explorar datos  Medición y transformación de variables  Creación de índice Recuperar casos perdidos Ingresos como variable categórica  A tibble: 6 x 2 Estimación  Diágnosticos  Casos influyentes Linealidad   Test homogeneidad de varianza Multicolinealidad  Referencias  Reporte de progreso Foro práctica 11    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo La siguiente práctica tiene el objetivo de introducir a los estudiantes en los supuestos y robustez del modelo de regresión. Por esta razón, volveremos a algunos de los contenidos previos relacionados con la estimación, análisis de residuos y ajuste. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\n Librerías pacman::p_load(dplyr, summarytools, sjPlot,texreg, corrplot,ggplot2,ggfortify,sandwich,lmtest,sjlabelled)  Datos El Estudio Longitudinal Social del Chile (ENACOES 2014), único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad con un alcance nacional, donde se obtuvo una muestra final de 3748 casos en el año 2018.\nload(\u0026quot;content/assignment/data/elsoc18p11.RData\u0026quot;) #Cargamos la base de datos desde internet load(url(\u0026quot;https://multivariada.netlify.com/assignment/data/elsoc18p11.RData\u0026quot;)) Explorar datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\nview(dfSummary(elsoc, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 sexo [numeric] Sexo entrevistado Min : 0 Mean : 0.6 Max : 1 0:1446(38.6%)1:2302(61.4%)  3748 (100%) 0 (0%)   2 edad [numeric] Edad entrevistado Mean (sd) : 47.1 (15.5) min 70 distinct values  3748 (100%) 0 (0%)   3 educ [factor] Nivel educacional 1. 1 2. 2 3. 3 4. 4 5. 5 450(12.0%)370(9.9%)1600(42.8%)598(16.0%)725(19.4%)  3743 (99.87%) 5 (0.13%)   4 pospol [factor] Autoubicacion escala izquierda-derecha 1. 1 2. 2 3. 3 4. 4 807(22.0%)952(26.0%)734(20.0%)1171(32.0%)  3664 (97.76%) 84 (2.24%)   5 part01 [numeric] Frecuencia: Firma carta o peticion apoyando causa Mean (sd) : 1.5 (0.9) min 1:2717(72.6%)2:476(12.7%)3:411(11.0%)4:117(3.1%)5:21(0.6%)  3742 (99.84%) 6 (0.16%)   6 part02 [numeric] Frecuencia: Asiste a marcha o manifestacion pacifica Mean (sd) : 1.2 (0.6) min 1:3289(87.8%)2:195(5.2%)3:191(5.1%)4:51(1.4%)5:19(0.5%)  3745 (99.92%) 3 (0.08%)   7 part03 [numeric] Frecuencia: Participa en huelga Mean (sd) : 1.2 (0.5) min 1:3407(91.0%)2:152(4.1%)3:146(3.9%)4:29(0.8%)5:11(0.3%)  3745 (99.92%) 3 (0.08%)   8 part04 [numeric] Frecuencia: Usa redes sociales para opinar en temas publicos Mean (sd) : 1.6 (1.1) min 1:2598(69.4%)2:310(8.3%)3:514(13.7%)4:223(6.0%)5:98(2.6%)  3743 (99.87%) 5 (0.13%)   9 inghogar [numeric] Ingreso total del hogar Mean (sd) : 678842.5 (781003.9) min 227 distinct values  3080 (82.18%) 668 (17.82%)   10 inghogar_t [numeric] Ingreso total del hogar (en tramos) Mean (sd) : 7 (5.4) min 20 distinct values  477 (12.73%) 3271 (87.27%)   11 tamhogar [numeric] Habitantes del hogar Mean (sd) : 3.2 (1.6) min 13 distinct values  3741 (99.81%) 7 (0.19%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n view_df(elsoc,max.len = 50)  Data frame: elsoc   ID  Name  Label  Values  Value Labels    1  sexo  Sexo entrevistado  0\n1  Hombre\nMujer    2  edad  Edad entrevistado  range: 18-90    3  educ  Nivel educacional  1\n2\n3\n4\n5  Primaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado    4  pospol  Autoubicacion escala izquierda-derecha  1\n2\n3\n4  Derecha\nCentro\nIzquierda\nIndep./Ninguno    5  part01  Frecuencia: Firma carta o peticion apoyando causa  1\n2\n3\n4\n5  Nunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente    6  part02  Frecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica  1\n2\n3\n4\n5  Nunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente    7  part03  Frecuencia: Participa en huelga  1\n2\n3\n4\n5  Nunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente    8  part04  Frecuencia: Usa redes sociales para opinar en\ntemas publicos  1\n2\n3\n4\n5  Nunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente    9  inghogar  Ingreso total del hogar  range: 30000-17000000    10  inghogar_t  Ingreso total del hogar (en tramos)  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20  Menos de $220.000 mensuales liquidos\nDe $220.001 a $280.000 mensuales liquidos\nDe $280.001 a $330.000 mensuales liquidos\nDe $330.001 a $380.000 mensuales liquidos\nDe $380.001 a $420.000 mensuales liquidos\nDe $420.001 a $470.000 mensuales liquidos\nDe $470.001 a $510.000 mensuales liquidos\nDe $510.001 a $560.000 mensuales liquidos\nDe $560.001 a $610.000 mensuales liquidos\nDe $610.001 a $670.000 mensuales liquidos\nDe $670.001 a $730.000 mensuales liquidos\nDe $730.001 a $800.000 mensuales liquidos\nDe $800.001 a $890.000 mensuales liquidos\nDe $890.001 a $980.000 mensuales liquidos\nDe $980.001 a $1.100.000 mensuales liquidos\nDe $1.100.001 a $1.260.000 mensuales liquidos\nDe $1.260.001 a $1.490.000 mensuales liquidos\nDe $1.490.001 a $1.850.000 mensuales liquidos\nDe $1.850.001 a $2.700.000 mensuales liquidos\nMas de $2.700.000 a mensuales liquidos    11  tamhogar  Habitantes del hogar  range: 1-14      Medición y transformación de variables Creación de índice En ELSOC existen cuatro preguntas referentes a la participación política o ciudadana, donde se le pregunta a las personas por la frecuencia en que han participado de determinados eventos vinculados a su rol como ciudadanos. Para esto, se emplearon escalas likert de 5 categorías para medir dicha participación.\nplot_stackfrq(elsoc[,c(\u0026quot;part01\u0026quot;,\u0026quot;part02\u0026quot;,\u0026quot;part03\u0026quot;,\u0026quot;part04\u0026quot;)]) +theme(legend.position=\u0026quot;bottom\u0026quot;) En la figura anterior, podemos ver que existe un alto porcentaje de personas que declaran no haber participado nunca en alguna de estas expresiones de la participación ciudadana. En este sentido, para la creación de un índice o medida agrupada, nos interesa saber si existe algún grado de relación entre nuestros indicadores. Para esto, lo que tradicionalmente se realiza es realizar un análisis de correlación entre los indicadores.\ncorrplot.mixed(cor(select(elsoc,part01,part02,part03,part04),  use = \u0026quot;complete.obs\u0026quot;)) La matriz de correlación nos indica que existen correlaciones moderadas entre los indicadores, donde 0.25 es la más baja y 0.44 la más alta. Es muy importante realizar este paso, debido a que si nuestros indicadores no correlacionan en absoluto, es posible que estemos frente a un atributo distinto. Por lo tanto, sería poco adecuado realizar la construcción de un índice que busque representar un fenómeno o constructo “común” a través de indicadores que no poseen ningún grado de correlación. En nuestro caso, hemos decidido elaborar un índice sumatorio a través de la suma de las respuestas de cada individuo. Para ello emplearemos las funciones mutate (para crear una nueva variable) y rowSums() (para sumar los indicadores) de la librería dplyr.\nelsoc \u0026lt;-elsoc %\u0026gt;%mutate(partpol=rowSums(select(., part01,part02,part03,part04))) descr(elsoc$partpol,style = \u0026quot;rmarkdown\u0026quot;,stats = \u0026quot;common\u0026quot;, transpose = T,headings = F)    Mean Std.Dev Min Median Max N.Valid Pct.Valid    partpol 5.47 2.30 4.00 4.00 20.00 3740.00 99.79    plot_frq(data = elsoc$partpol,type = \u0026quot;hist\u0026quot;,show.mean = T) Vemos que el índice sumatorio posee valores que van desde 4 hasta 20, con una media de 5,47 y una mediana de 4. Además, vemos algo que ya se había identificado en el gráfico descriptivo de cada indicador por separado, el hecho que existe una proporción importante de personas que respondieron “nunca” en los cuatro indicadores, los cuales son representados por una alta frecuencia de 4 en el histograma. Con esto hemos creado nuestro índice sumatorio de Participación Política.\n Recuperar casos perdidos Es común que en las encuestas sociales cierta variables posean una alta proporción de datos perdidos. Un ejemplo común es en el reporte de los ingresos de los hogares o individuos. Esto generalmente puede generarse por características de la persona (p.ej. desempleado, estudiante) o por deseabilidad social (personas de altos ingresos desisten de reportar). En el caso de ELSOC, existen dos estrategias para solicitar que las personas reporten sus ingresos. La primera consiste en preguntar directamente por el monto en pesos chilenos de los ingresos totales del hogar. Alternativamente, si la persona no reporta los ingresos, se le presenta la posibilidad de ubicar los ingresos del hogar en tramos (Por ejemplo “De $560.001 a $610.000 mensuales liquidos”). De esta manera, si existen datos perdidos en la primera, se emplea la segunda pregunta para tener un nivel aproximado del ingreso del hogar.\ndescr(elsoc$inghogar,style = \u0026quot;rmarkdown\u0026quot;,stats = \u0026quot;common\u0026quot;, transpose = T,headings = F)    Mean Std.Dev Min Median Max N.Valid Pct.Valid    inghogar 678842.52 781003.92 30000.00 5e+05 1.7e+07 3080.00 82.18    sjmisc::frq(elsoc$inghogar_t,  out = \u0026quot;txt\u0026quot;,  show.na = T) %\u0026gt;%knitr::kable()      val label frq raw.prc valid.prc cum.prc    1 Menos de $220.000 mensuales liquidos 62 1.65 13.00 13.00  2 De $220.001 a $280.000 mensuales liquidos 46 1.23 9.64 22.64  3 De $280.001 a $330.000 mensuales liquidos 57 1.52 11.95 34.59  4 De $330.001 a $380.000 mensuales liquidos 40 1.07 8.39 42.98  5 De $380.001 a $420.000 mensuales liquidos 38 1.01 7.97 50.94  6 De $420.001 a $470.000 mensuales liquidos 37 0.99 7.76 58.70  7 De $470.001 a $510.000 mensuales liquidos 27 0.72 5.66 64.36  8 De $510.001 a $560.000 mensuales liquidos 15 0.40 3.14 67.51  9 De $560.001 a $610.000 mensuales liquidos 24 0.64 5.03 72.54  10 De $610.001 a $670.000 mensuales liquidos 12 0.32 2.52 75.05  11 De $670.001 a $730.000 mensuales liquidos 15 0.40 3.14 78.20  12 De $730.001 a $800.000 mensuales liquidos 16 0.43 3.35 81.55  13 De $800.001 a $890.000 mensuales liquidos 8 0.21 1.68 83.23  14 De $890.001 a $980.000 mensuales liquidos 14 0.37 2.94 86.16  15 De $980.001 a $1.100.000 mensuales liquidos 14 0.37 2.94 89.10  16 De $1.100.001 a $1.260.000 mensuales liquidos 10 0.27 2.10 91.19  17 De $1.260.001 a $1.490.000 mensuales liquidos 7 0.19 1.47 92.66  18 De $1.490.001 a $1.850.000 mensuales liquidos 11 0.29 2.31 94.97  19 De $1.850.001 a $2.700.000 mensuales liquidos 14 0.37 2.94 97.90  20 Mas de $2.700.000 a mensuales liquidos 10 0.27 2.10 100.00    3271 87.27          Si observamos la tabla de descriptivos para la variable ingreso del hogar (inghogar), tenemos un porcentaje 17,82% de datos perdidos. Por esta razón, emplearemos los datos disponibles en inghogar_t para recuperar información en los ingresos del hogar.\nLa estrategia posee los siguientes pasos:\nCalcular la media del tramo reportado. En el caso de que la persona no haya reportado el monto de los ingresos del hogar, remplazamos este valor perdido por el valor de la media del tramo, en el caso de estar disponible. Comparamos la variable original con la nueva variable que posee información recuperada.  Paso 1: Calcular la media por cada tramo\nelsoc$inghogar_t[elsoc$inghogar_t==1] \u0026lt;-( 220000 ) # [1] \u0026quot;Menos de $220.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==2] \u0026lt;-(220001 +280000 )/2 # [2] \u0026quot;De $220.001 a $280.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==3] \u0026lt;-(280001 +330000 )/2 # [3] \u0026quot;De $280.001 a $330.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==4] \u0026lt;-(330001 +380000 )/2 # [4] \u0026quot;De $330.001 a $380.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==5] \u0026lt;-(380001 +420000 )/2 # [5] \u0026quot;De $380.001 a $420.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==6] \u0026lt;-(420001 +470000 )/2 # [6] \u0026quot;De $420.001 a $470.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==7] \u0026lt;-(470001 +510000 )/2 # [7] \u0026quot;De $470.001 a $510.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==8] \u0026lt;-(510001 +560000 )/2 # [8] \u0026quot;De $510.001 a $560.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==9] \u0026lt;-(560001 +610000 )/2 # [9] \u0026quot;De $560.001 a $610.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==10]\u0026lt;-(610001 +670000 )/2 # [10] \u0026quot;De $610.001 a $670.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==11]\u0026lt;-(670001 +730000 )/2 # [11] \u0026quot;De $670.001 a $730.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==12]\u0026lt;-(730001 +800000 )/2 # [12] \u0026quot;De $730.001 a $800.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==13]\u0026lt;-(800001 +890000 )/2 # [13] \u0026quot;De $800.001 a $890.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==14]\u0026lt;-(890001 +980000 )/2 # [14] \u0026quot;De $890.001 a $980.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==15]\u0026lt;-(980001 +1100000)/2 # [15] \u0026quot;De $980.001 a $1.100.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==16]\u0026lt;-(1100001+1260000)/2 # [16] \u0026quot;De $1.100.001 a $1.260.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==17]\u0026lt;-(1260001+1490000)/2 # [17] \u0026quot;De $1.260.001 a $1.490.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==18]\u0026lt;-(1490001+1850000)/2 # [18] \u0026quot;De $1.490.001 a $1.850.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==19]\u0026lt;-(1850001+2700000)/2 # [19] \u0026quot;De $1.850.001 a $2.700.000 mensuales liquidos\u0026quot; elsoc$inghogar_t[elsoc$inghogar_t==20]\u0026lt;-(2700000) # [20] \u0026quot;Mas de $2.700.000 a mensuales liquidos\u0026quot; Paso 2: En el caso de no tener información, remplazar por la media del tramo\nelsoc$inghogar_i \u0026lt;-ifelse(test = (is.na(elsoc$inghogar)), #¿existen NA en ingresos?  yes = elsoc$inghogar_t, #VERDADERO, remplazar con la media del tramo  no = elsoc$inghogar) #FALSE, mantener la variable original.  elsoc$inghogar_i \u0026lt;-set_label(elsoc$inghogar_i,\u0026quot;Ingreso total del hogar (imputada)\u0026quot;) Paso 3: Comparamos la variable original con la nueva\nsjmisc::descr(elsoc[,c(\u0026quot;inghogar\u0026quot;,\u0026quot;inghogar_i\u0026quot;)],  show =c(\u0026quot;label\u0026quot;, \u0026quot;n\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;md\u0026quot;,\u0026quot;sd\u0026quot;)) %\u0026gt;%knitr::kable(digits = 2)   var label n NA.prc mean sd md    inghogar Ingreso total del hogar 3080 17.82 678842.5 781003.9 500000  inghogar_i Ingreso total del hogar (imputada) 3557 5.10 668539.5 752608.2 480000    Vemos que pasamos de tener 17,82% de datos perdidos a un 5,1%, es decir recuperamos un 12,72% de los casos que antes tenían datos perdidos en la variable ingreso. Con estos datos podemos calcular el ingreso per capita del hogar, empleando la variable habitantes del hogar (tamhogar).\nelsoc$ing_pcap \u0026lt;-elsoc$inghogar_i/elsoc$tamhogar elsoc$ing_pcap \u0026lt;-set_label(elsoc$ing_pcap,\u0026quot;Ingreso per cápita del hogar\u0026quot;) sjmisc::descr(elsoc[,c(\u0026quot;inghogar\u0026quot;,\u0026quot;inghogar_i\u0026quot;,\u0026quot;tamhogar\u0026quot;,\u0026quot;ing_pcap\u0026quot;)],  show =c(\u0026quot;label\u0026quot;, \u0026quot;n\u0026quot;, \u0026quot;NA.prc\u0026quot;, \u0026quot;mean\u0026quot;, \u0026quot;md\u0026quot;,\u0026quot;sd\u0026quot;)) %\u0026gt;%knitr::kable(digits = 2)    var label n NA.prc mean sd md    2 inghogar Ingreso total del hogar 3080 17.82 678842.52 781003.92 500000.0  3 inghogar_i Ingreso total del hogar (imputada) 3557 5.10 668539.54 752608.16 480000.0  4 tamhogar Habitantes del hogar 3741 0.19 3.16 1.57 3.0  1 ing_pcap Ingreso per cápita del hogar 3552 5.23 263057.71 350338.36 166666.7    Vemos que la variable tamhogar posee un 0,19% de datos perdidos, por lo cual, al calcular el ingreso per cápita, vemos que el porcentaje de casos sin información en la nueva variable aumenta levemente a un 5,23%.\n Ingresos como variable categórica Teniendo el ingreso per cápita del hogar, podemos calcular categorías de ingresos tales como los quintiles (o deciles). Por lo tanto, podemos clasificar a los individuos según sus ingresos en una variable categórica.\nEl procedimiento es el siguiente:\nelsoc$quintile\u0026lt;-dplyr::ntile(x = elsoc$ing_pcap,  n = 5) # n de categorias, para quintiles usamos 5 elsoc$quintile \u0026lt;-factor(elsoc$quintile,c(1,2,3,4,5), c(\u0026quot;Quintil 1\u0026quot;,\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;)) elsoc %\u0026gt;% group_by(quintile) %\u0026gt;% summarise(n=n(),  Media=mean(ing_pcap,na.rm = T),  Mediana=median(ing_pcap,na.rm = T)) %\u0026gt;% knitr::kable()   quintile n Media Mediana    Quintil 1 711 62859.09 66666.67  Quintil 2 711 112218.97 111250.12  Quintil 3 710 167748.23 166666.67  Quintil 4 710 262710.27 250000.50  Quintil 5 710 710246.41 500000.00   196      En la tabla podemos observar que la variable quintile posee 5 grupos de tamaño equivalente. Además, agregamos la media y la mediana de los ingresos para cada categoría para ilustrar que podemos tratar esta variable como categórica y ordinal.\nExiste una última estrategia que podemos utilizar para recuperar ese 5,23% (n=196) de casos perdidos. Para esto, generamos una categoría adicional para los datos perdidos, es decir, recodificamos los NA para que se incluyan como una nueva categoría.\nEl procedimiento es el siguiente:\nelsoc$quintilemiss \u0026lt;-factor(elsoc$quintile,ordered = T) elsoc$quintilemiss \u0026lt;-ifelse(is.na(elsoc$quintilemiss),yes = 6,no = elsoc$quintilemiss) elsoc$quintilemiss \u0026lt;-factor(elsoc$quintilemiss ,levels = c(1,2,3,4,5,6),labels = c(\u0026quot;Quintil 1\u0026quot;,\u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Missing\u0026quot;)) elsoc %\u0026gt;%group_by(quintilemiss) %\u0026gt;%summarise(n=n())   A tibble: 6 x 2 quintilemiss n   1 Quintil 1 711 2 Quintil 2 711 3 Quintil 3 710 4 Quintil 4 710 5 Quintil 5 710 6 Missing 196\nTeniendo una nueva categoría de ingresos, podemos recuperar estos casos para los posteriores análisis. A continuación, se llevaran a cabo una serie de análisis que nos permitirán comprar los resultados según distintas especificaciones y empleando distintas maneras de operacionalizar la variable ingresos.\n Estimación fit01\u0026lt;-lm(partpol~sexo+edad+ing_pcap+pospol,data=elsoc) fit02\u0026lt;-lm(partpol~sexo+edad+quintile+pospol,data=elsoc) fit03\u0026lt;-lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc) labs01 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\u0026quot;Ingreso per/cap\u0026quot;,\u0026quot;Centro (ref. derecha)\u0026quot;,\u0026quot;Izquierda\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;,  \u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,  \u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;) htmlreg(list(fit01,fit02,fit03),doctype = FALSE,  custom.model.names = c(\u0026quot;Modelo 1\u0026quot;,\u0026quot;Modelo 2\u0026quot;,\u0026quot;Modelo 3\u0026quot;),  custom.coef.names = labs01) Statistical models     Modelo 1  Modelo 2  Modelo 3    Intercepto  8.27***  7.94***  7.97***     (0.14)  (0.16)  (0.16)    Sexo (mujer=1)  0.05  0.13  0.12     (0.07)  (0.08)  (0.07)    Edad  -0.04***  -0.04***  -0.04***     (0.00)  (0.00)  (0.00)    Ingreso per/cap  0.00***       (0.00)      Centro (ref. derecha)  -1.02***  -1.04***  -1.04***     (0.10)  (0.10)  (0.10)    Izquierda  -1.10***  -1.12***  -1.13***     (0.11)  (0.11)  (0.11)    Idep./Ninguno  -1.59***  -1.58***  -1.60***     (0.10)  (0.10)  (0.10)    Quintil 2   0.22  0.21      (0.11)  (0.11)    Quintil 3   0.51***  0.51***      (0.11)  (0.11)    Quintil 4   0.51***  0.50***      (0.11)  (0.11)    Quintil 5   0.89***  0.88***      (0.12)  (0.12)    Quintil perdido    0.59***       (0.18)    R2  0.17  0.17  0.17    Adj. R2  0.16  0.17  0.17    Num. obs.  3475  3475  3656    RMSE  2.10  2.09  2.10    p \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05    Diágnosticos Casos influyentes Para determinar si un outlier es un caso influyente, es decir que su presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión, calculamos la Distancia de Cook..\nPosteriormente, se establece un punto de corte de \\(4/(n-k-1)\\):\nn\u0026lt;-nobs(fit03) #n de observaciones k\u0026lt;-length(coef(fit03)) # n de parametros dcook\u0026lt;-4/(n-k-1) #punt de corte Si lo graficamos se ve de la siguiente manera:\nfinal \u0026lt;-broom::augment_columns(fit03,data = elsoc) final$id \u0026lt;-as.numeric(row.names(final)) # identify obs with Cook\u0026#39;s D above cutoff ggplot(final, aes(id, .cooksd))+ geom_bar(stat=\u0026quot;identity\u0026quot;, position=\u0026quot;identity\u0026quot;)+ xlab(\u0026quot;Obs. Number\u0026quot;)+ylab(\u0026quot;Cook\u0026#39;s distance\u0026quot;)+ geom_hline(yintercept=dcook)+ geom_text(aes(label=ifelse((.cooksd\u0026gt;dcook),id,\u0026quot;\u0026quot;)), vjust=-0.2, hjust=0.5) Identificamos los casos influyentes y filtramos la base de datos:\nident\u0026lt;-final %\u0026gt;%filter(.cooksd\u0026gt;dcook) elsoc02 \u0026lt;-final %\u0026gt;%filter(!(id %in%ident$id)) Estimación sin casos influyentes:\nfit04\u0026lt;-lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc02) labs02 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,  \u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,  \u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;)  htmlreg(list(fit03,fit04),  doctype = FALSE,  custom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),  custom.coef.names = labs02) Statistical models     Modelo 3  Modelo 4    Intercepto  7.97***  7.05***     (0.16)  (0.11)    Sexo (mujer=1)  0.12  0.07     (0.07)  (0.05)    Edad  -0.04***  -0.03***     (0.00)  (0.00)    Quintil 2  0.21  0.11     (0.11)  (0.08)    Quintil 3  0.51***  0.34***     (0.11)  (0.08)    Quintil 4  0.50***  0.32***     (0.11)  (0.08)    Quintil 5  0.88***  0.57***     (0.12)  (0.08)    Quintil perdido  0.59***  0.31*     (0.18)  (0.13)    Izquierda (ref. derecha)  -1.04***  -0.65***     (0.10)  (0.07)    Centro  -1.13***  -0.71***     (0.11)  (0.08)    Idep./Ninguno  -1.60***  -1.14***     (0.10)  (0.07)    R2  0.17  0.18    Adj. R2  0.17  0.18    Num. obs.  3656  3460    RMSE  2.10  1.48    p \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05    En términos generales, el sentido y significación estadística de los coeficientes del Modelo 4 se mantiene respecto al Modelo 3. Adicionalmente, si observamos que el modelo sin casos influyentes presenta una mejora en ajuste. Por lo tanto, los análisis posteriores se realizaran en base a este modelo.\n Linealidad Para analizar la linealidad respecto de un modelo de regresión, debemos analizar la distribución de los residuos con respecto a la recta de regresión.\n Los residuos deben ser independientes de los valores predichos (fitted values). Cualquier correlación entre residuo y valores predichos violarían este supuesto. La presencia de un patrón no lineal, es señal de que el modelo está especificado incorrectamente.  ggplot(fit04, aes(.fitted, .resid)) + geom_point() + geom_hline(yintercept = 0) + geom_smooth(se = TRUE)  Figure 1: Relación entre residuos y valores predichos  El gráfico nos indica que existe un patrón en la distribución de los residuos. Para intentar mejorar la estimación podemos realizar una transformación de variables. A continuación presentaremos un ejemplo para la Edad y para los Ingresos.\n Polinomio: \\(\\text{Edad}^2\\)  elsoc02$edad2 \u0026lt;-elsoc02$edad^2 fit05\u0026lt;-lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02) edad\u0026lt;-fit05$model$edad fit\u0026lt;-fit05$fitted.values data01 \u0026lt;-as.data.frame(cbind(edad,fit))  ggplot(data01, aes(x = edad, y = fit)) + theme_bw() + geom_point()+ geom_smooth()  Figure 2: Efecto cuadrático de la edad (Modelo 5)   Logaritmo: \\(\\log(\\text{ingreso})\\)  elsoc02$lningreso \u0026lt;-log(elsoc02$ing_pcap) elsoc02$lningreso \u0026lt;-set_label(elsoc02$lningreso,\u0026quot;log(ingreso per cap)\u0026quot;) fit06 \u0026lt;-lm(partpol~sexo+edad+edad2+lningreso+pospol,data=elsoc02) plot_frq(elsoc02$ing_pcap,type = \u0026quot;hist\u0026quot;,normal.curve = T, show.mean = T) plot_frq(elsoc02$lningreso,type = \u0026quot;hist\u0026quot;, normal.curve = T,show.mean = T) labs03 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,  \u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,  \u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;, \u0026quot;Edad²\u0026quot;,\u0026quot;Ingreso per cap (log)\u0026quot;)  htmlreg(list(fit04, fit05, fit06), doctype = FALSE,  custom.model.names = c(\u0026quot;Modelo 4\u0026quot;, \u0026quot;Modelo 5\u0026quot;, \u0026quot;Modelo 6\u0026quot;),  custom.coef.names = labs03) Statistical models     Modelo 4  Modelo 5  Modelo 6    Intercepto  7.05***  7.62***  4.98***     (0.11)  (0.24)  (0.46)    Sexo (mujer=1)  0.07  0.08  0.09     (0.05)  (0.05)  (0.05)    Edad  -0.03***  -0.06***  -0.06***     (0.00)  (0.01)  (0.01)    Quintil 2  0.11  0.11      (0.08)  (0.08)     Quintil 3  0.34***  0.34***      (0.08)  (0.08)     Quintil 4  0.32***  0.32***      (0.08)  (0.08)     Quintil 5  0.57***  0.57***      (0.08)  (0.08)     Quintil perdido  0.31*  0.31*      (0.13)  (0.13)     Izquierda (ref. derecha)  -0.65***  -0.65***  -0.63***     (0.07)  (0.07)  (0.08)    Centro  -0.71***  -0.70***  -0.70***     (0.08)  (0.08)  (0.08)    Idep./Ninguno  -1.14***  -1.13***  -1.12***     (0.07)  (0.07)  (0.07)    Edad²   0.00**  0.00**      (0.00)  (0.00)    Ingreso per cap (log)    0.24***       (0.03)    R2  0.18  0.19  0.19    Adj. R2  0.18  0.18  0.18    Num. obs.  3460  3460  3305    RMSE  1.48  1.47  1.48    p \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05    Interpretación: Vemos que el coeficiente de lningreso es de 0.24, sin embargo, debido a que la unidad de medida es logarítmica decimos que por una unidad de porcentaje (1%) de incremento en los ingresos per cápita del hogar, el promedio del índice de participación política aumenta en 0.24/100 = 0.0024, manteniendo todas las demás variables constantes. El coeficiente es estadísticamente significativo a uno 99.9% de confianza. En este caso particular, no es muy informativo, pero corresponde a una manera de especificar un modelo con los ingresos como una variable logaritmizada para hacernos cargo de posible problemas de linealidad.\nDebemos tener cautela al interpretar el ajuste del Modelo 5 y 6 debido a que las observaciones empleadas no son las mismas (3462 comparado con 3304) debido a que en el Modelo 5 se incluye la variable ingresos en quintiles con la categoría adicional para los casos perdidos. En este caso, realizamos la especificación a modo de ejemplo. Por lo tanto, seguiremos trabajando con el Modelo 5 para realizar los análisis posteriores.\n   Test homogeneidad de varianza car::ncvTest(fit05) ## Non-constant Variance Score Test ## Variance formula: ~ fitted.values ## Chisquare = 521.5278, Df = 1, p = \u0026lt; 2.22e-16 lmtest::bptest(fit05) ## ## studentized Breusch-Pagan test ## ## data: fit05 ## BP = 385.59, df = 11, p-value \u0026lt; 2.2e-16 Tanto el test Breush-Pagan como el de Cook-Weisberg nos indican que existen problemas con respecto a homogeneidad en la distribución de los residuos del modelo debido a que \\(p\u0026gt;0.05\\) en ambos casos. Es decir, se rechaza \\(H_0\\) donde se asume que la varianza del error es constante, lo cual nos indica que tenemos problemas de heterocedasticidad en los residuos.\nPara hacer frente a este problema, debemos calcular los errores estándar robustos para nuestra última estimación para corregir problemas de heterocedasticidad y así estimar el último modelo nuevamente:\nmodel_robust\u0026lt;-coeftest(fit05, vcov=vcovHC) Comparemos los resultados:\nlabs04 \u0026lt;-c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,  \u0026quot;Quintil 2\u0026quot;,\u0026quot;Quintil 3\u0026quot;,\u0026quot;Quintil 4\u0026quot;,\u0026quot;Quintil 5\u0026quot;,\u0026quot;Quintil perdido\u0026quot;,  \u0026quot;Izquierda (ref. derecha)\u0026quot;,\u0026quot;Centro\u0026quot;,\u0026quot;Idep./Ninguno\u0026quot;, \u0026quot;Edad²\u0026quot;)  htmlreg(list(fit04, fit05, model_robust), doctype = FALSE,  custom.model.names = c(\u0026quot;Modelo 4\u0026quot;,\u0026quot;Modelo 5\u0026quot;, \u0026quot;M5 Robust\u0026quot;), custom.coef.names = labs04) Statistical models     Modelo 4  Modelo 5  M5 Robust    Intercepto  7.05***  7.62***  7.62***     (0.11)  (0.24)  (0.27)    Sexo (mujer=1)  0.07  0.08  0.08     (0.05)  (0.05)  (0.05)    Edad  -0.03***  -0.06***  -0.06***     (0.00)  (0.01)  (0.01)    Quintil 2  0.11  0.11  0.11     (0.08)  (0.08)  (0.07)    Quintil 3  0.34***  0.34***  0.34***     (0.08)  (0.08)  (0.08)    Quintil 4  0.32***  0.32***  0.32***     (0.08)  (0.08)  (0.08)    Quintil 5  0.57***  0.57***  0.57***     (0.08)  (0.08)  (0.09)    Quintil perdido  0.31*  0.31*  0.31**     (0.13)  (0.13)  (0.12)    Izquierda (ref. derecha)  -0.65***  -0.65***  -0.65***     (0.07)  (0.07)  (0.09)    Centro  -0.71***  -0.70***  -0.70***     (0.08)  (0.08)  (0.09)    Idep./Ninguno  -1.14***  -1.13***  -1.13***     (0.07)  (0.07)  (0.08)    Edad²   0.00**  0.00**      (0.00)  (0.00)    R2  0.18  0.19     Adj. R2  0.18  0.18     Num. obs.  3460  3460     RMSE  1.48  1.47     p \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05    Los resultados del modelo con errores estándar robustos, nos indica que nuestras estimaciones son robustas a la presencia de heterocedasticidad en los residuos debido a que la significancia de los coeficientes se mantiene si lo comparamos con Modelo 4.\n Multicolinealidad car::vif(fit04) car::vif(fit05) ## GVIF Df GVIF^(1/(2*Df)) ## sexo 1.057775 1 1.028482 ## edad 1.012463 1 1.006212 ## quintilemiss 1.085365 5 1.008225 ## pospol 1.041316 3 1.006770 ## GVIF Df GVIF^(1/(2*Df)) ## sexo 1.058907 1 1.029032 ## edad 38.308809 1 6.189411 ## edad2 38.275011 1 6.186680 ## quintilemiss 1.087725 5 1.008444 ## pospol 1.042085 3 1.006894 Entonces, asumiendo que valores del VIF mayores a 2.5, vemos que en el modelo que no incorpora el término cuadrático de edad no tendríamos problemas de multicolinealidad. Sin embargo, al incorporar el término cuadrático, nos muestra un VIF de 6.2 en la variable edad y edad2.\nReferencias Darlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities\nDarlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships\n  Reporte de progreso Contestar aquí.\n Foro práctica 11  ","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"5594772ee389e3a8f923e29a8eccc9c3","permalink":"/assignment/11-code/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/assignment/11-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"df7a31a1291d87ad849bb7c3fb14d771","permalink":"/class/12-class/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/class/12-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","tags":null,"title":"12: Pendientes y complementos","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo Librerías Datos  Explorar datos  Estimación  Presentación de resultados Tabla de regresión  Regresión logística sin predictores Regresión logistica con variable binaria como predictor Regresión logística con variable continua como predictor Regresión logística con múltiples predictores   Medidas de Ajuste  Test de Devianza Pseudo-R2 de McFadden Presentación de resultados Referencias  Reporte de progreso Foro práctica 10    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo La siguiente práctica tiene el objetivo de introducir a los estudiantes en los modelos de regresión logística multivariada. Al igual que en la práctica anterior emplearemos una variable dependiente dicotómica, de modo tal que veremos de qué una serie de variables independientes nos permiten predecir la ocurrencia de un determinado evento. Para ello, utilizaremos la base de datos de la Encuesta sobre Conflicto y Cohesion Social en Chile 2014 para analizar los determinantes de la participación en las elecciones del año 2013.\n Librerías pacman::p_load(dplyr, summarytools, ggmosaic, sjPlot, texreg)  Datos La Encuesta sobre Conflicto y Cohesión Social en Chile (ENACOES 2014) es el primer estudio de este tipo que busca mapear los conflictos y la cohesión en el país. Su objetivo fundamental es aportar a la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto. La población objetivo son hombre y mujeres entre 15 y 75 años de edad con un alcance nacional, donde se obtuvo una muestra final de 2025 casos. Para el caso de este ejercicio, se trabajara con una submuestra de 1974 individuos que estuvieron habilitados para votar en el año 2013.\n#Cargamos la base de datos desde internet load(url(\u0026quot;https://multivariada.netlify.com/assignment/data/enacoes.RData\u0026quot;)) Explorar datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(enacoes, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 voto [factor] Vot\u0026#0243; en \u0026#0250;ltima elecci\u0026#0243;n 1. 0 2. 1 649(32.9%)1325(67.1%)  1974 (100%) 0 (0%)   2 sexo [factor] Sexo entrevistado 1. 0 2. 1 803(40.7%)1171(59.3%)  1974 (100%) 0 (0%)   3 edad [numeric] Edad entrevistado Mean (sd) : 45.1 (16) min 58 distinct values  1974 (100%) 0 (0%)   4 educ [factor] Nivel Educacional 1. 1 2. 2 3. 3 4. 4 5. 5 179(9.1%)167(8.5%)878(44.5%)513(26.0%)237(12.0%)  1974 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n Lo primero que debemos observar es la distribución de la participación electoral, donde 0 son quienes nos votaron en la última elección y 1 los que sí lo hicieron. En este caso, vemos que un 67,1% (1325) señaló haber participado en la última elección, en contraste de un 32,9% que no lo hizo. En este sentido, vemos que existen aproximadamente 2/3 de los individuos de la muestra que sí acudieron a votar, por tanto ahora vamos a revisar cómo se distribuyen estas respuestas según el sexo y el nivel educacional de el entrevistado.\nEn primera instancia nos centraremos en las variables sexo y voto. Como podemos notar la categoría de respuesta de estas variables son 0 y 1, es decir, estamos ante variables dicotómicas.\nEn segunda instancia, observaremos la distribución de participación electoral según el Nivel educacional (educ), la cual en este caso hemos recodificado en cinco niveles educacionales.\nCon la función tab_xtab del paquete sjPlot podemos realizar una tabla de contingencia donde se señala la proporción de la participación electoral según sexo.\ntab_xtab(var.row = enacoes$voto,enacoes$sexo,show.cell.prc = T,show.summary = F)  Votó en última\nelección  Sexo entrevistado  Total    Hombre  Mujer    No votó  254\n12.9 %  395\n20 %  649\n32.9 %    Votó  549\n27.8 %  776\n39.3 %  1325\n67.1 %    Total  803\n40.7 %  1171\n59.3 %  1974\n100 %    Teniendo en cuenta que existen 2/3 (67,1%) de las personas en Chile que han declarado haber votado en la última elección, la tabla anterior nos muestra que del total de personas que votan, las participación electoral es mayor en las mujeres, lo cual equivale a un 39,3% del total en desmedro del 27,8% que representado por los hombres.\ntab_xtab(var.row = enacoes$voto,enacoes$educ,  show.cell.prc = T,show.summary = F, encoding = \u0026quot; \u0026quot;)  Votó en última\nelección  Nivel Educacional  Total    Primaria incompleta\no menos  Primaria  Secundaria  Técnica Superior  Universitaria o\npostgrado    No votó  55\n2.8 %  47\n2.4 %  320\n16.2 %  182\n9.2 %  45\n2.3 %  649\n32.9 %    Votó  124\n6.3 %  120\n6.1 %  558\n28.3 %  331\n16.8 %  192\n9.7 %  1325\n67.2 %    Total  179\n9.1 %  167\n8.5 %  878\n44.5 %  513\n26 %  237\n12 %  1974\n100 %    Adicionalmente, la tabla anterior nos muestra la distribución de la participación electoral según cinco categorías de nivel educacional. Como podemos observar, la participación electoral se concentra en los niveles educacionales secundario con un 28,3% y superior técnica y universitaria, con un 16,8% y 9,7% respectivamente. Por otro lado, podemos observar una baja participación electoral de los grupos con nivel educacional más bajo, donde las personas con Primaria incompleta o menos representan un 6,3% y aquellas con Primaria completa son el 6,1%.\nAl igual que la práctica anterior, podemos representar gráficamente estas distribuciones a través del paquete ggmosaic que con su función geom_mosaic. A continuación se presentan dos gráficos para la participación electoral según sexo y nivel educacional.\nggplot(enacoes) + geom_mosaic(aes(x=product(voto, sexo), fill=sexo)) + geom_label(data = layer_data(last_plot(), 1),  aes(x = (xmin +xmax)/2,  y = (ymin +ymax)/2,  label = paste0(round((.wt/sum(.wt))*100,1),\u0026quot;%\u0026quot;))) + labs(y = \u0026quot;Voto última elección\u0026quot;,  x = \u0026quot;Sexo\u0026quot;) + scale_fill_discrete(name = \u0026quot;\u0026quot;,  labels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;))+ scale_y_continuous(breaks = c(0,1),  labels = c(\u0026quot;No votó\u0026quot;,\u0026quot;Votó\u0026quot;)) + theme(legend.position=\u0026quot;bottom\u0026quot;)   ggplot(enacoes) + geom_mosaic(aes(x=product(voto, educ), fill=educ)) + geom_label(data = layer_data(last_plot(), 1),  aes(x = (xmin +xmax)/2,  y = (ymin +ymax)/2,  label = paste0(round((.wt/sum(.wt))*100,1),\u0026quot;%\u0026quot;))) + labs(y = \u0026quot;Voto última elección\u0026quot;,  x = \u0026quot;Nivel Educacional\u0026quot;) + scale_fill_discrete(name = \u0026quot;\u0026quot;,  labels = c(\u0026quot;Primaria incompleta o menos\u0026quot;,  \u0026quot;Primaria\u0026quot;,  \u0026quot;Secundaria\u0026quot;, \u0026quot;Técnica o Superior\u0026quot;,  \u0026quot;Universitaria o postgrado\u0026quot;))+ scale_y_continuous(breaks = c(0,1),labels = c(\u0026quot;No votó\u0026quot;,\u0026quot;Votó\u0026quot;)) + theme(legend.position=\u0026quot;bottom\u0026quot;)  Figure 1: Participación electoral en 2013 según Sexo y Nivel Educacional    Estimación La función pincipal para la estimación de modelos de regresión logística es glm(), especificando el argumento family=\"binomial\", lo cual le indica a la función que estamos prediciendo una variable binaria. Al igual que con lm(), debemos especificar los predictores y la base de datos a emplear. A continuación, estimaremos una serie de modelos de regresión logística que nos permitan determinar de qué manera el sexo, la edad y el nivel educacional de las personas pueden predecir la participación electoral.\nAqui ecuacion del logit(p) = -- m00 \u0026lt;-glm(voto~1,data = enacoes,family = \u0026quot;binomial\u0026quot;) m01 \u0026lt;-glm(voto~sexo,data = enacoes,family = \u0026quot;binomial\u0026quot;) m02 \u0026lt;-glm(voto~edad,data = enacoes,family = \u0026quot;binomial\u0026quot;) m03 \u0026lt;-glm(voto~sexo+edad+educ,data = enacoes,family = \u0026quot;binomial\u0026quot;) Presentación de resultados Para construir una tabla de regresión podemos usar la librería texreg:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\nInstalar librería texreg. Si bien existe una versión en CRAN, no nos permite usar el argumento custom.gof.rows para agregar estadísticos de ajuste adicionales, así que para instalar:remotes::install_github(\"leifeld/texreg\")\n Existen tres variaciones para crear tablas:\n screenreg(): nos muestra la tabla en la consola de R htmlreg(): produce una tabla en formato html (como las que vemos en este documento) texreg(): produce una tabla en formato \\(\\LaTeX\\) para documentos en pdf.  Para que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n  ```{r results=\u0026#39;asis\u0026#39;, echo=FALSE} htmlreg(list(m01,m02,m03)) ``` Para personalizar nuestra tabla podemos ir agregando más información, tales como los nombres de los coeficientes o el nombre de los modelos:  ```{r results=\u0026#39;asis\u0026#39;, echo=FALSE} htmlreg(l = list(m00,m01,m02,m03), custom.coef.names=c(\u0026quot;Intercepto\u0026quot;,\u0026quot;Sexo (Mujer=1)\u0026quot;,\u0026quot;Edad\u0026quot;,\u0026quot;Primaria\u0026quot;,\u0026quot;Secundaria\u0026quot;, \u0026quot;Técnica o Superior\u0026quot;,\u0026quot;Universitaria o postgrado\u0026quot;), custom.model.names = c(\u0026quot;Modelo 0\u0026quot;,\u0026quot;Modelo 1\u0026quot;,\u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;)) ```   Tabla de regresión    Modelo 0  Modelo 1  Modelo 2  Modelo 3    Intercepto  0.71***  0.77***  -1.07***  -2.04***     (0.05)  (0.08)  (0.15)  (0.29)    Sexo (Mujer=1)   -0.10   -0.02      (0.10)   (0.10)    Edad    0.04***  0.05***       (0.00)  (0.00)    Primaria     0.34        (0.25)    Secundaria     0.47*        (0.19)    Técnica o Superior     0.88***        (0.22)    Universitaria o postgrado     1.53***        (0.25)    AIC  2502.30  2503.34  2334.32  2290.54    Log Likelihood  -1250.15  -1249.67  -1165.16  -1138.27    Deviance  2500.30  2499.34  2330.32  2276.54    Num. obs.  1974  1974  1974  1974    \\(^{***}\\) p \u0026lt; 0.001; \\(^{**}\\) p \u0026lt; 0.01; \\(^{*}\\) p \u0026lt; 0.05 Errores estándar entre paréntesis    En la tabla anterior podemos observar cuatro modelos distintos:\n  Modelo Predictores    Modelo 0 modelo nulo (sin predictores)  Modelo 1 Incluye sexo  Modelo 2 Incluye edad  Modelo 3 Incluye sexo, edad y nivel educacional    Regresión logística sin predictores \\[logit(p) = \\beta_{0}\\]\nEl modelo sin predictores nos permite conocer la probabilidad de votar. En este caso, vemos que se obtiene un intercepto de 0.71 correspondiente a \\(log(p/1-p)\\). En este caso \\(p\\) es la probabilidad de que una persona participe en las elecciones como votante (voto = 1). Miremos nuevamente la distribución de la participación electoral:\n     val label frq raw.prc valid.prc cum.prc    0 No votó 649 32.88 32.88 32.88  1 Votó 1325 67.12 67.12 100.00        Entonces, tenemos que \\(p =1325/1974 = .67\\). Por tanto, la odds calculadas corresponden a 0.67/(1-0.67) =2.03, lo cual en unidades de log(odds) corresponde al valore del intercepto que es 0.71. En otras palabras el intercepto del modelo sin predictores nos entrega la log-odds de votar en las elecciones. Adicionalmente, podemos transformar nuevamente a unidades de probabilidad de la siguiente manera: p = exp(0.71)/(1 + exp(0.71))= 0.67.\n Regresión logistica con variable binaria como predictor \\[logit(p) = \\beta_0 + \\beta_{mujer}\\]\nEl modelo con un predictor binario como sexo nos permite estimar la probabilidad de votar para las mujeres (sexo = 1), respecto a los hombres (sexo = 0). En este caso, los resultados muestran el valor del intercepto (0.77) y para sexo (-0.10). Antes de interpretar, demos una mirada a la distribución de la participación electoral según sexo:\n## sexo Hombre Mujer ## voto ## No votó 254 395 ## Votó 549 776 En nuestros datos, ¿cuáles son las chances (odds) de votar para los hombres y para las mujeres? Con la información de la tabla de contingencia podemos realizar los cálculos manualmente: para los hombres (sexo = 0), las odds de votar son (549/803)/(254/803) = 0.683 /0.316 = 2.16. A su vez, para las mujeres, las odds de votar son (776/1171)/(395/1171) = 0.662/0.337 = 1.96. Entonces, las odds ratio para las mujeres respecto de los hombres es (776/395)/(549/254) = (776x254)/(549x395) = 0.907, por lo tanto podemos decir que las odds de votar en las elecciones son son 9,5% (exp(-0.10)-1 = 0.908-1) más bajas para las mujeres respecto a los hombres.\nAhora, si observamos los resultados de la tabla de regresión vemos que el intercepto es 0.77, el cual representa las log-odds para los hombres en tanto corresponde a la categoría de referencia (sexo = 0). Usando las odds de votar para los hombres calculada en el apartado anterior, podemos confirmarlo: log(2.16) = 0.77. A su vez, el log-odds para las mujeres corresponde al log del odds-ratio de las odds de las mujeres y de los hombres calculado anteriormente: log(0.907) = -0.10. El output tradicional de R cuando usamos glm() nos entrega los coeficientes en unidades de log-odds, por tanto es necesario realizar la exponenciación de dichos coeficientes para realizar la interpretación en unidades de odds-ratio.\n Regresión logística con variable continua como predictor \\[logit(p) = \\beta_0 + \\beta_{edad}\\]\nAhora, estimaremos un modelo empleando la edad como predictor continuo. En este caso, el intercepto corresponde a los log-odds de una persona con “edad 0”. En otras palabras, las odds de votar cuando se tiene edad 0 es exp(-1.07) = 0.343. Lo importante es que si observamos la distribución de la variable edad, vemos que el valor mínimo es 18 años, por tanto, sabemos que este coeficiente no posee una interpretación sustantiva directamente. Lo más relevante es que el intercepto en ese modelo corresponde a los log-odds de votar en el hipotético caso de tener edad cero.\nEntonces, ¿cómo interpretamos el coeficiente de edad?. Para esto, lo ideal es tener en cuenta todos los valores de la ecuación:\n\\[logit(p) = -1.07 + 0.04 \\times edad\\]\nUna manera de hacerlo es fijar edad en algún valor, por ejemplo un sujeto de con 54 años. Entonces, el valor del log-odds para una persona con 54 años es:\n\\(logit(p_{edad54}) = -1.07 + 0.04 \\times 54 = 1.09\\)\nAhora, el valor de los log-odds para una persona con 55 años es:\n\\(logit(p_{edad55}) = -1.07 + 0.04 \\times 55 = 1.13\\)\nEntonces, podemos decir que el coeficiente para edad es la diferencia en el log-odds. En otras palabras, por una unidad de incremento en edad (1 año), el cambio esperado en los log-odds es de 0.04.\nAhora, ¿cómo traducimos este cambio en odds?. Tenemos que:\n\\(\\exp(logit(p_{edad55})-logit(p_{edad54}) = \\frac{\\exp(logit(p_{edad55}))}{\\exp(logit(p_{edad55}))}= \\frac{\\exp(1.13)}{\\exp(1.09)}=\\frac{3.09}{2.97} = 1.04\\)\nFinalmente, podemos decir que por el incremento de una unidad en edad (1 año), se espera ver un incremento aproximado de un 4% en las odds de ir a votar. Este porcentaje no depende de los valores en los cuales se mantenga edad.\n Regresión logística con múltiples predictores \\[logit(p) = \\beta_0 + \\beta_{\\text{mujer}}+ \\beta_{\\text{edad}}+ \\beta_{\\text{prim}}+ \\beta_{\\text{secu}}+ \\beta_{\\text{técn}}+ \\beta_{\\text{univ}}\\]\nEste ejemplo representa el modelo multivariado para participación electoral. Cada coeficiente prepresenta el cambio predicho en el log-odds de votar por un incremento/cambio en la variable, manteniendo todas las demás variables constantes. Cada coeficiente exponenciado (exp), representa el ratio de dos odds (por ejemplo, mujer respecto a hombre), o el cambio en las odds por el incremento de una unidad de la variable independiente (por ejemplo, un año de edad), manteniendo las demás variables constantes.\nEntonces, si observamos el coeficiente de sexo en el Modelo 3, vemos que el odds-ratio de las mujeres sobre los hombres es de exp(-0.02)= 0.98, es decir que las odds de votar en las elecciones son son 1,9% (exp(-0.02)-1 = 0.98-1) más bajas para las mujeres respecto a los hombres, manteniendo edad y el nivel educacional constante.\nLa variable nivel educacional posee 5 niveles, donde “Primaria incompleta o menos” es la categoría de referencia, por tanto, los coeficientes se deben interpretar respecto dicha categoría. Por ejemplo, tenemos que el odds-ratio para Primaria es de exp(0.34) = 1.40, por lo tanto las odds de votar en las elecciones son 40% (exp(-0.02)-1 = 1.40-1) más altas para las personas que completaron la educación primaria respecto a quienes tienen educación primaria incompleta o menos, manteniendo sexo y edad en valores constantes.\nAhora, observando el log-odds para las personas son educación Universitaria o postgrado podemos calcular que el odds-ratio para esta categoría es de exp(1.53) = 4.61, lo cual nos indica que las odds de votar son 361% exp(1.53)-1 = 4.61-1 más altas para las personas con educación universitaria o postgrado respecto a quienes tienen educación primaria incompleta o menos, manteniendo sexo y edad en valores constantes.\nOtra alternativa de interpretación es a través del cálculo de las probabilidades predichas. Por ejemplo ¿cuál es la probabilidad de votar según los distintos niveles educacionales manteniendo constante sexo y edad?. En este caso usaremos una persona hipotética que es mujer (sexo=1) de 55 años.\nTenemos nuestros coeficientes para el Modelo 3:\nm03$coefficients ## (Intercept) sexo1 edad educ2 educ3 educ4 ## -2.03578412 -0.02351809 0.04911213 0.33653007 0.46911435 0.88442909 ## educ5 ## 1.52605507 Calculamos las log-odds para cada caso:\n # Intercept sexo*1 edad*55 educ2 educ3 educ4 educ5 ed01\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*0)+(1.5260*0) # mujer 55 anios Primaria incompleta ed02\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*1)+(0.4691*0)+(0.8844*0)+(1.5260*0) # mujer 55 anios Primaria ed03\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*1)+(0.8844*0)+(1.5260*0) # mujer 55 anios Secundaria ed04\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*1)+(1.5260*0) # mujer 55 anios Tecnica ed05\u0026lt;--2.03578412+(-0.0235*1)+(0.0491*55)+(0.3365*0)+(0.4691*0)+(0.8844*0)+(1.5260*1) # mujer 55 anios Universitaria Calculamos las probabilidades predichas de la siguiente manera:\n\\[\\text{Probabilidad}= \\frac{\\exp(\\beta_0+\\beta_jX_j)}{1+\\exp(\\beta_0+\\beta_jX_j)} = \\frac{\\text{Odds}}{1+\\text{Odds}}\\]\npr.ed01\u0026lt;-exp(ed01)/(1+exp(ed01)) pr.ed02\u0026lt;-exp(ed02)/(1+exp(ed02)) pr.ed03\u0026lt;-exp(ed03)/(1+exp(ed03)) pr.ed04\u0026lt;-exp(ed04)/(1+exp(ed04)) pr.ed05\u0026lt;-exp(ed05)/(1+exp(ed05)) Finalmente, se presenta la tabla resumen a continuación:\n  Nivel educacional log-odds exp(log-odds) exp(odds)/(1-exp(odds)    Primaria incompleta o menos 0.641 1.899 0.655  Primaria 0.978 2.658 0.727  Secundaria 1.110 3.035 0.752  Técnica 1.526 4.598 0.821  Univsersitaria 2.167 8.734 0.897    La librería sjPlot posee la función plot_model() la cual, dentro de otras cosas, nos permite visualizar las probabilidades predichas para un modelo de regresión logística.\nplot_model(m03,type = \u0026quot;pred\u0026quot;,  terms = \u0026quot;educ\u0026quot;,  title = \u0026quot;Probabilidades predichas para Voto según nivel educacional\u0026quot;) +geom_line() En conjunto, podemos observar que en la medida que aumenta el nivel educacional de las personas, la probabilidad de que participen en las elecciones tiende a ser mayor, manteniendo edad y sexo constante.\n   Medidas de Ajuste El ajuste de los modelos de regresión logística puede ser evaluado de distintas maneras. Generalmente se realiza a través del contraste con otros modelos con más o menos predictores, lo cual nos permite elegir entre las mejores especificaciones. Adicionalmente, presentaremos la manera de incorporar estas medidas de ajuste a la tabla de regresión del apartado anterior.\nEn este ejercicio emplearemos (1) Test de Devianza y (2) Pseudo-R2 de McFadden.\nTest de Devianza Este test nos permite comparar las verosimilitudes del modelo con predictores, respecto a un modelo con menos predictores. En este caso, emplearemos la función anova() el cual realiza un test basado en la distribución chi-cuadrado donde se contrasta el modelo en cuestión respecto a un modelo sin predictores (modelo “nulo”).\nEn nuestro caso, comparamos nuestro modelo sin predictores con los posteriores modelos para sexo, edad y nivel educacional.\ntest01\u0026lt;-anova(m00,m01,test = \u0026quot;Chisq\u0026quot;) test02\u0026lt;-anova(m00,m02,test = \u0026quot;Chisq\u0026quot;) test03\u0026lt;-anova(m00,m03,test = \u0026quot;Chisq\u0026quot;) lrt01\u0026lt;-rbind(test01,test02,test03) %\u0026gt;%unique() row.names(lrt01) \u0026lt;-c(\u0026quot;Modelo nulo\u0026quot;,  \u0026quot;Modelo 1\u0026quot;,  \u0026quot;Modelo 2\u0026quot;,  \u0026quot;Modelo 3\u0026quot;) knitr::kable(lrt01,digits = 3, caption = \u0026quot;Test de devianza entre modelos\u0026quot;)  Table 1: Test de devianza entre modelos   Resid. Df Resid. Dev Df Deviance Pr(\u0026gt;Chi)    Modelo nulo 1973 2500.296     Modelo 1 1972 2499.342 1 0.954 0.329  Modelo 2 1972 2330.325 1 169.971 0.000  Modelo 3 1967 2276.545 6 223.751 0.000    Modelo nulo vs. Modelo 1: La diferencia entre los modelos no es estadísticamente significativa con una probabilidad \\(p\\) \u0026gt; 0.05. Por lo tanto el modelo que incluye sexo como predictor no ofrece un mejor ajuste a los datos que un modelo sin predictores.\n Modelo nulo vs. Modelo 2: La diferencia entre los modelos es estadísticamente significativa con una probabilidad \\(p\\) \u0026lt; 0.001. Por lo tanto el modelo que incluye la edad como predictor ofrece un mejor ajuste a los datos que un modelo sin predictores.\n Modelo nulo vs. Modelo 3: La diferencia entre los modelos es estadísticamente significativa con una probabilidad \\(p\\) \u0026lt; 0.001. Por lo tanto el modelo que incluye el sexo, edad y nivel educacional como predictores ofrece un mejor ajuste a los datos que un modelo sin predictores.\n  Podemos guardar los valores \\(p\\) de cada modelo para luego incorporarlos en la tabla de regresión:\ntest.pvalues1\u0026lt;-test01$`Pr(\u0026gt;Chi)`[2] test.pvalues2\u0026lt;-test02$`Pr(\u0026gt;Chi)`[2] test.pvalues3\u0026lt;-test03$`Pr(\u0026gt;Chi)`[2]  Pseudo-R2 de McFadden Esta medida de ajuste nos entrega una magnitud comparativa entre el modelo con predictores y el modelo nulo (sin predictores). Este se basda en los valores del loglikelihood de cada modelo.\n\\(1-\\frac{LL(LM)}{LL(L0)}\\)\n LL es el log likelihood del modelo LM es el modelo posterior (con predictores) L0 es el modelo nulo  Podemos calcularlos manualmente de la siguiente manera:\n1-(logLik(m01)[1]/logLik(m00)[1]) # modelo 1 vs modelo nulo 1-(logLik(m02)[1]/logLik(m00)[1]) # modelo 2 vs modelo nulo 1-(logLik(m03)[1]/logLik(m00)[1]) # modelo 3 vs modelo nulo ## [1] 0.0003817169 ## [1] 0.06798047 ## [1] 0.08948998 También, podemos utilizar la función PseudoR2() de la librería DescTools. A continuación los calculamos y guardamos para incluirlos en la tabla de regresión.\nmfr2.00 \u0026lt;-DescTools::PseudoR2(m00) mfr2.01 \u0026lt;-DescTools::PseudoR2(m01) mfr2.02 \u0026lt;-DescTools::PseudoR2(m02) mfr2.03 \u0026lt;-DescTools::PseudoR2(m03) r2\u0026lt;-as.data.frame(cbind(c(mfr2.00,mfr2.01,mfr2.02,mfr2.03))) rownames(r2) \u0026lt;-c(\u0026quot;Modelo nulo\u0026quot;,  \u0026quot;Modelo 1\u0026quot;,  \u0026quot;Modelo 2\u0026quot;,  \u0026quot;Modelo 3\u0026quot;) knitr::kable(r2,digits = 3, col.names = c(\u0026quot;McFadden R2\u0026quot;))    McFadden R2    Modelo nulo 0.000  Modelo 1 0.000  Modelo 2 0.068  Modelo 3 0.089    De esta manera, podemos observar que el cálculo del Pseudo R2 nos indica que el Modelo 1 no aporta mayor a la predicción, en contraste con el Modelo 2 y 3.\n Presentación de resultados Existen distintas librerías para presentar modelos de regresión, tales como las funciones tab_modeñ() o stargazer() que ya hemos revisado anteriormente. En este caso vamos a usar htmlreg() de la librería texreg. Por defecto, la función nos entrega la siguiente salida:\nhtmlreg(l = list(m03,m03)) \u0026lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”\u0026gt; Statistical models     Model 1  Model 2    (Intercept)  -2.04***  -2.04***     (0.29)  (0.29)    sexo1  -0.02  -0.02     (0.10)  (0.10)    edad  0.05***  0.05***     (0.00)  (0.00)    educ2  0.34  0.34     (0.25)  (0.25)    educ3  0.47*  0.47*     (0.19)  (0.19)    educ4  0.88***  0.88***     (0.22)  (0.22)    educ5  1.53***  1.53***     (0.25)  (0.25)    AIC  2290.54  2290.54    BIC  2329.66  2329.66    Log Likelihood  -1138.27  -1138.27    Deviance  2276.54  2276.54    Num. obs.  1974  1974    p \u0026lt; 0.001, p \u0026lt; 0.01, p \u0026lt; 0.05    Dentro de la misma función, existen más opciones para personalizar el reporte, incluyendo el argumento custom.gof.rows señalado en el apartado anterior, el cual emplearemos para incluirlos resultados delTest de Devianza y el Pseudo R2. En este caso, incluiremos una versión con coeficientes en log-odds del Modelo 3 y su posterior transformación a odds-ratio (OR), además de remplazar los errores estándar por intervalos de confianza.\nPara transformar los coeficientes de log-odds a odds-ratio realizamos lo siguiente:\nor \u0026lt;-texreg::extract(m03) or@coef \u0026lt;-exp(or@coef) htmlreg(l = list(m03,or), doctype = F,caption = \u0026quot;\u0026quot;,caption.above = T,  custom.model.names = c(\u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 3 (OR)\u0026quot;),  custom.coef.names = coef.labs,  ci.force = c(TRUE,TRUE),  override.coef = list(coef(m03),or@coef),  custom.gof.rows=list(\u0026quot;Deviance Test ($p$)\u0026quot; =c(test.pvalues3,  test.pvalues3),  \u0026quot;Pseudo R2\u0026quot; =c(mfr2.03,mfr2.03)),  custom.note = \u0026quot;$^{***}$ p \u0026lt; 0.001; $^{**}$ p \u0026lt; 0.01; $^{*}$ p \u0026lt; 0.05 \u0026lt;br\u0026gt; Errores estándar entre paréntesis. \u0026lt;br\u0026gt; **Nota**: La significancia estadística de los coeficientes en unidades de Odds ratio está calculada en base a los valores $t$, \u0026lt;br\u0026gt; los cuales a su vez se calculan en base a $log(Odds)/SE$\u0026quot;)    Modelo 3  Modelo 3 (OR)    Intercepto  -2.04*  0.13     [-2.60; -1.47]  [-0.43; 0.70]    Sexo (Mujer=1)  -0.02  0.98*     [-0.23; 0.18]  [0.77; 1.18]    Edad  0.05*  1.05*     [0.04; 0.06]  [1.04; 1.06]    Primaria  0.34  1.40*     [-0.15; 0.82]  [0.91; 1.89]    Secundaria  0.47*  1.60*     [0.09; 0.85]  [1.22; 1.98]    Técnica o Superior  0.88*  2.42*     [0.46; 1.31]  [2.00; 2.84]    Universitaria o postgrado  1.53*  4.60*     [1.03; 2.02]  [4.11; 5.09]    AIC  2290.54  2290.54    BIC  2329.66  2329.66    Log Likelihood  -1138.27  -1138.27    Deviance  2276.54  2276.54    Num. obs.  1974  1974    \\(^{***}\\) p \u0026lt; 0.001; \\(^{**}\\) p \u0026lt; 0.01; \\(^{*}\\) p \u0026lt; 0.05 Errores estándar entre paréntesis. Nota: La significancia estadística de los coeficientes en unidades de Odds ratio está calculada en base a los valores \\(t\\), los cuales a su vez se calculan en base a \\(log(Odds)/SE\\)    Una alternativa a las tablas de regresión son los coefplots. Como hemos visto en prácticas anteriores, este tipo de gráficos muestran el valor de coeficiente acompañados de sus intervalos de confianza. En este caso, vemos que la función plot_model nos entrega por defecto los coeficientes en unidades de odds-ratio, por tanto el valor 1 representa el límite para la significancia estadística, a diferencia del 0 cuando se encuentra en unidades de log-odds. En este caso, conforme a lo presentado en la tabla de regresión, el coeficiente de Edad y Educación Secundaria, Técnica superior y Universitaria poseen intervalos de confianza que no contienen el valor 1, por tanto son estadísticamente signficativos.\nplot02\u0026lt;-plot_model(m03,vline.color = \u0026quot;grey\u0026quot;) plot01\u0026lt;-plot_model(m03,vline.color = \u0026quot;grey\u0026quot;,transform = NULL) plot_grid(list(plot02,plot01),tags = c(\u0026quot; \u0026quot;,\u0026quot; \u0026quot;),  margin = c(0,0,0,0))  Figure 2: Modelo de regresión con y sin exponenciar (exp)   Referencias Camarero et al (2017) Regresión logística: Fundamentos y aplicación a la investigación sociológica (p.30-52)\nCerda, Vera y Rada (2017) Odds ratio: aspectos teóricos y prácticos.\n  Reporte de progreso Contestar aquí.\n Foro práctica 10  ","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"8ec314482bb68fedf05e4758dbbdc14d","permalink":"/assignment/10-code/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/assignment/10-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"187acf4fd964c835bff8f91f793da537","permalink":"/class/11-class/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/class/11-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","tags":null,"title":"11: Supuestos","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase - no disponible … falla de zoom :(   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase - no disponible … falla de zoom :(  ","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"3fea5612523ac7da2f3ba696739f7198","permalink":"/class/10-class/","publishdate":"2020-08-07T00:00:00Z","relpermalink":"/class/10-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase - no disponible … falla de zoom :(   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase - no disponible … falla de zoom :(  ","tags":null,"title":"10: Regresión logística (2)","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo Librerías Datos  Explorar datos  Conceptos centrales  Probabilidades Odds Odds Ratio (OR) Referencias  Reporte de progreso Foro práctica 9    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo La siguiente práctica tiene el objetivo de introducir a los estudiantes en los modelos de regresión logística, que es una técnica de análisis que nos permite tener una variable dependiente como dicotómica. Para ello, utilizaremos la base de datos del Titanic.\n Librerías pacman::p_load(dplyr, summarytools, ggmosaic, finalfit)  Datos ¿Qué es el titanic? El RMS Titanic fue un transatlántico británico, el mayor barco del mundo al finalizar su construcción, que se hundió en la madrugada del 15 de abril de 1912 durante su viaje inaugural desde Southampton a Nueva York. En el hundimiento del Titanic murieron 619 personas de las 1046 que iban a bordo, lo que convierte a esta tragedia en uno de los mayores naufragios de la historia ocurridos en tiempo de paz.\n#Cargamos la base de datos desde internet load(url(\u0026quot;https://multivariada.netlify.com/assignment/data/titanic.RData\u0026quot;)) Explorar datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(tt, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing     1 pclass [factor] 1. Clase Alta 2. Clase Intermedia 3. Clase Baja 284(27.2%)261(24.9%)501(47.9%)  1046 (100%) 0 (0%)   2 survived [factor] 1. No sobrevive 2. Sobrevive 619(59.2%)427(40.8%)  1046 (100%) 0 (0%)   3 sex [factor] 1. Hombre 2. Mujer 658(62.9%)388(37.1%)  1046 (100%) 0 (0%)   4 age [numeric] Mean (sd) : 29.9 (14.4) min 98 distinct values  1046 (100%) 0 (0%)   5 sibsp [numeric] Mean (sd) : 0.5 (0.9) min 0:685(65.5%)1:280(26.8%)2:36(3.4%)3:16(1.5%)4:22(2.1%)5:6(0.6%)8:1(0.1%)  1046 (100%) 0 (0%)   6 parch [numeric] Mean (sd) : 0.4 (0.8) min 0:768(73.4%)1:160(15.3%)2:97(9.3%)3:8(0.8%)4:5(0.5%)5:6(0.6%)6:2(0.2%)  1046 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n Para esta práctica nos centraremos en las variables sex y survived. Como podemos notar la categoría de respuesta de estas variables son 0 y 1, es decir, estamos ante variables dicotómicas.\nCon la función ctable del paquete summarytools podemos realizar una tabla de contingencia donde se señala la proporción de sobrevivientes según sexo\nCross-Tabulation, Row Proportions survived * sex Data Frame: tt     sex    survived  Hombre Mujer Total      No sobrevive  523 ( 84.5% ) 96 ( 15.5% ) 619 ( 100.0% )    Sobrevive  135 ( 31.6% ) 292 ( 68.4% ) 427 ( 100.0% )    Total  658 ( 62.9% ) 388 ( 37.1% ) 1046 ( 100.0% )    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n ctable(tt$survived, tt$sex) La tabla muestra que la mayoría de los tripulantes no sobrevivió (619 no sobreviven, mientras que 427 si sobreviven). A su vez, la mayoría de los no sobrevivientes corresponden a hombres (84.5%), mientras que solo un 15.5% de las mujeres no sobrevive. En relación a sobrevivientes, la mayoría de los sobrevivientes corresponden a mujeres (68,4%), en desmedro de hombres (31.6%).\nUna forma gráfica de verlo es por medio del paquete ggmosaic que con su función geom_mosaic permite construir visualizaciones para datos categóricos. El mosaico general corresponde al total de tripulantes del titanic. Como podrán notar, hay más hombres tripulantes que mujeres, por lo que las barras para hombres son mas anchas. Luego, gracias al comando fill del geom_mosaic podemos distinguir en hombres y mujeres la proporción de cuantos sobrevivieron y cuantos no sobrevivieron.\nggplot(data = tt) + geom_mosaic(aes(product(survived, sex), fill= survived)) +labs(y = \u0026quot;Sobreviviente\u0026quot;, x = \u0026quot;Sexo\u0026quot;)   Conceptos centrales Los dos conceptos centrales en regresión logística son las “chances” (o en inglés, odds) y la razón (o en inglés, ratio).\nProbabilidades Una probabilidad es la posibilidad de ocurrencia de un evento de interés, usando como referencia todos los eventos. Por ejemplo, la probabilidad de “ser sobreviviente en el titanic” se calcula en relación a todos los tripulantes del titanic.\nEn primera instancia, podríamos decir que del total de pasajeros, un 40.8% de ellos sobrevive, es decir, la probabilidad de sobrevivir es de 0.408\n\\[Probabilidades_{sobrevivientes} = \\frac{427}{1046} = 0.408\\] Mientras que un 59.2% de los tripulantes no sobrevive, es decir, la probabilidad de no sobrevivir es de 0.592\n\\[Probabilidades_{sobrevivientes} = \\frac{619}{1046} = 0.592\\]\nEn R se realiza a través de la función prop.table\nprop.table(table(tt$survived)) ## ## No sobrevive Sobrevive ## 0.5917782 0.4082218  Odds Una forma alternativa de representar una probabilidad es un odds que se definen como la división entre el número de ocurrencias (\\(\\pi\\)) y el numero de “no ocurrencias” (\\(1-\\pi\\)).\n\\[Odd = \\frac{\\pi}{1-\\pi}\\]\nSi seguimos el ejemplo del Titanic\n\\[Odds = \\frac{Sobrevivientes}{No{Sobrevivientes}}\\]\nLa función addmargins nos entrega las frecuencias marginales y absolutas para columnas (sexo) y filas (sobrevivencia)\naddmargins(table(tt$survived,tt$sex)) ## ## Hombre Mujer Sum ## No sobrevive 523 96 619 ## Sobrevive 135 292 427 ## Sum 658 388 1046 Si hacemos el cálculo de los odds obtenemos 0.68 (427/619), es decir, hay 0.68 sobrevivientes por cada no sobreviviente. Aunque parezca poco “lógico” hablar de 0.68 sobrevivientes, esto indica que la relación entre sobrevivientes y no sobrevivientes no es 1:1 y de hecho existen más chances de morir que de sobrevivir.\nOtra forma de leer este dato es decir que por cada 100 no sobrevivientes, hay 68 sobrevivientes.\nPodríamos también calcular el odds de sobrevivencia de hombres y mujeres\n\\[Odds{hombres} = \\frac{135}{523} = 0.258\\] \\[Odds{mujeres} = \\frac{292}{96} = 3.04\\]\nPara los hombres, hay más chances de no sobrevivir que de sobrevivir (odds \u0026lt; 1), mientras que para mujeres hay más chances de sobrevivir que de no sobrevivir (odds \u0026gt; 1)\nPropiedades de Odds\n Odds menores que 1, indican una chance negativa Odds mayores que 1, indican una chance positiva  En R esto podemos realizar este calculo directamente a través de las probabilidades marginales para cada sexo que entrega prop.table.El número 2 indica que las proporciones están calculadas por columna, es decir, las probabilidades indicadas se calculan considerando como total cada sexo.\nprop.table(table(tt$survived,tt$sex),2) ## ## Hombre Mujer ## No sobrevive 0.7948328 0.2474227 ## Sobrevive 0.2051672 0.7525773  Odds Ratio (OR) Ahora bien, con los datos hasta ahí podriamos llegar a la conclusión de que las mujeres tienen más chances de sobrevivir que los hombres. Pero, ¿cuánto más sobreviven las mujeres que los hombres?\nEsta pregunta implica la asociación entre sobrevivencia y sexo y ya no solo hablar de las chances de sobrevivencia de cada sexo por separado. Para hacer esa relación se requiere calcular los odds ratio o razón de chances.\n\\[Odds Ratio = \\frac{Odds_{mujeres}}{Odds_{hombres}} = \\frac{3.04}{0.258} = 11.78\\]\nEl resultado que obtenemos se lee de la siguiente manera: las chances de sobrevivir de las mujeres es 11.78 veces más grande que la de los hombres.\nEn consecuencia, la comparación de los Odds de dos grupos es conocido como Odds Ratio (OR). Formalmente:\n\\[Odds_{ratio}=\\frac{odds_{1}}{odds_{2}}=\\frac{\\pi_{1}/(1-\\pi_{1})}{\\pi_{2}/(1-\\pi_{2})}\\]\nPropiedades de Odds Ratio:\n Cuando X e Y son independientes \\(Odds_{ratio}\\) ya que \\(odds_{1}=odds_{2}\\)\n El rango de posibles valores es: \\(0\u0026lt;Odds_{ratio}\u0026lt;\\infty\\)\n Cuando los valores van de 0 a 1, \\(Odds_{ratio}\\) indica que \\(odds_{1}\u0026lt;odds_{2}\\)\n Cuando los valores van de 1 a \\(\\infty\\), \\(Odds_{ratio}\\) indica que \\(odds_{1}\u0026gt;odds_{2}\\)\n  Es una medida de magnitud de asociación simétrica: un \\(Odds_{ratio}=4\\) es una asociación positiva proporcional a la asociación negativa \\(Odds_{ratio}=1/4=0.25\\)\n  Los \\(Odds_{ratio}\\) se pueden graficar por medio de la funcion or_plor de finalfit. Para ello solo de debe indicar cuál es la variable predictora (o explanatory en inglés) y la variable dependiente.\nexplanatory =\u0026quot;sex\u0026quot; dependent =\u0026quot;survived\u0026quot;  tt %\u0026gt;%or_plot(dependent, explanatory) Como se puede ver, en el gráfico no solo se indican los \\(Odds_{ratio}\\) de sobrevivencia de las mujeres por sobre los hombres (11.78), sino que estos se grafican en relacióna qué tan cerca están del 0 (y por tanto, cuánto se aleja del rango de asociación negativa).\n Referencias Camarero et al (2017) Regresión logística: Fundamentos y aplicación a la investigación sociológica (p.1-29)\nCerda, Vera y Rada (2017) Odds ratio: aspectos teóricos y prácticos.\n  Reporte de progreso Contestar aquí.\n Foro práctica 9  ","date":1596326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"d1d31d6e8d02dd2e2bca57b081533945","permalink":"/assignment/09-code/","publishdate":"2020-08-02T00:00:00Z","relpermalink":"/assignment/09-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"6fce0ded8aa03d77081bcdf32570ef18","permalink":"/class/09-class/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/class/09-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","tags":null,"title":"9: Regresión logística (1)","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Librerías Datos Ajustes y descriptivos Modelos de regresión  Lógica de presentación de modelos Estimación Interpretación Ajuste global del modelo  Referencias Foro práctica 8    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  En el siguiente documento se presenta un ejemplo de análisis e interpretación de una tabla de regresión múltiple, para que sea considerado como referencia en la entrega de los informes 2 y 3. El ejemplo está adaptado de https://stats.idre.ucla.edu/stata/output/regression-analysis/\nLibrerías pacman::p_load(dplyr,readxl, summarytools, stargazer, equatiomatic)  Datos Los datos a utilizar corresponden a resultados de pruebas de conocimiento en distintas areas de 200 estudiantes de educación secundaria.\ndata \u0026lt;-read_excel(\u0026quot;https://multivariada.netlify.app/assignment/data/hsb2.xls\u0026quot;)  Ajustes y descriptivos Primero seleccionamos las variables que vamos a usar en el ejemplo y cambiamos las etiquetas de las variables a español.\nnames(data) ## [1] \u0026quot;id\u0026quot; \u0026quot;female\u0026quot; \u0026quot;race\u0026quot; \u0026quot;ses\u0026quot; \u0026quot;schtyp\u0026quot; \u0026quot;prog\u0026quot; \u0026quot;read\u0026quot; ## [8] \u0026quot;write\u0026quot; \u0026quot;math\u0026quot; \u0026quot;science\u0026quot; \u0026quot;socst\u0026quot; data \u0026lt;-data %\u0026gt;%select (science,math,female, socst, read) data \u0026lt;-data %\u0026gt;%rename(ciencia=science, matematicas =math, mujer=female, status=socst, lectura=read) print(dfSummary(data, headings = FALSE), method = \u0026quot;render\u0026quot;)   No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing     1 ciencia [numeric] Mean (sd) : 51.9 (9.9) min 34 distinct values  200 (100%) 0 (0%)   2 matematicas [numeric] Mean (sd) : 52.6 (9.4) min 40 distinct values  200 (100%) 0 (0%)   3 mujer [numeric] Min : 0 Mean : 0.5 Max : 1 0:91(45.5%)1:109(54.5%)  200 (100%) 0 (0%)   4 status [numeric] Mean (sd) : 52.4 (10.7) min 22 distinct values  200 (100%) 0 (0%)   5 lectura [numeric] Mean (sd) : 52.2 (10.3) min 30 distinct values  200 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n  Modelos de regresión Lógica de presentación de modelos La forma en que se presentan los modelos en regresión múltiple depende de las hipótesis que se estan contrastando, y de la definición del/a investigador/a sobre cuáles son los predictores principales y cuáles son las variables de control. Pensemos en este caso que nuestra hipótesis principal es que el puntaje de ciencias se puede predecir con los puntajes de matemáticas y lectura, pero queremos controlar estas asociaciones por sexo y estatus. En este caso, podríamos presentar dos modelos, uno solamente con los predictores principales, y luego un segundo modelo con los controles para ver si los efectos se mantienen. También podríamos pensar en tres modelos: uno con matemáticas, otro con ciencias, y otro con ambos y además controles. La decisión de cómo presentar los modelos depende principalmente de las hipótesis que se están contrastando, y también de que los resultados permitan hacer la mejor discusión posible.\n Estimación Vamos a estimar un primer modelo con las variables asociadas a la hipótesis principal, y luego un segundo con las variables control:\n\\[ \\operatorname{ciencia} = \\alpha + \\beta_{1}(\\operatorname{matematicas}) + \\beta_{2}(\\operatorname{lectura}) + \\epsilon \\]\\[ \\operatorname{ciencia} = \\alpha + \\beta_{1}(\\operatorname{matematicas}) + \\beta_{2}(\\operatorname{lectura}) + \\beta_{3}(\\operatorname{mujer}) + \\beta_{4}(\\operatorname{status}) + \\epsilon \\]\nPara estimar estos modelos en R:\nreg1 \u0026lt;-lm(ciencia ~matematicas +lectura, data=data) reg2 \u0026lt;-lm(ciencia ~matematicas +lectura +mujer +status, data=data) Para presentar los resultados de regresión existen diferentes librerías en R, como stargazer, texreg, sjPlot. En este caso vamos a utilizar la función tab_model de sjPlot:\nsjPlot::tab_model(list(reg1,reg2))   ciencia  ciencia    Predictors  Estimates  CI  p  Estimates  CI  p    (Intercept)  11.62  5.59 – 17.64  \u0026lt;0.001  12.33  6.03 – 18.62  \u0026lt;0.001    matematicas  0.40  0.26 – 0.54  \u0026lt;0.001  0.39  0.24 – 0.54  \u0026lt;0.001    lectura  0.37  0.23 – 0.50  \u0026lt;0.001  0.34  0.19 – 0.48  \u0026lt;0.001    mujer     -2.01  -4.03 – 0.01  0.051    status     0.05  -0.07 – 0.17  0.424    Observations  200  200    R2 / R2 adjusted  0.478 / 0.473  0.489 / 0.479    Esta tabla tiene las opciones por defecto. En general, para cada predictor hay dos piezas de información importante: la estimación del coeficiente de regresión \\(\\beta\\) (estimates), y una estimación referida a inferencia/significación estadística (en este caso CI, intervalo de confianza). Esta segunda información es en general el error estándar, pero también puede ser t (que es el coeficiente dividido por el error estándar), o el intervalo de confianza, dado usualmente por el \\(\\beta\\) +/- 1.96 SE para un 95% de confianza (como aparece en esta tabla). Según el output, la información de inferencia puede aparecer abajo del coeficiente, o al lado como en esta tabla.\nAbajo vamos a hacer algunos ajustes en la tabla, presentando el error estándar en lugar del intervalo, y reemplazando la columna del nivel de probabilidad de error (p) por asteriscos que indican el nivel de significación de cada coeficiente, lo cual hace más rápida la interpretación. También cambiamos algunas etiquetas de la tabla para que sea más fácil de leer:\nsjPlot::tab_model(list(reg1,reg2),  show.se=TRUE,  show.ci=FALSE,  digits=3,  p.style = \u0026quot;asterisk\u0026quot;,  dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;),  string.pred = \u0026quot;Predictores\u0026quot;,  string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2    Predictores  β  std. Error  β  std. Error    (Intercept)  11.616 ***  3.054  12.325 ***  3.194    matematicas  0.402 ***  0.073  0.389 ***  0.074    lectura  0.365 ***  0.066  0.335 ***  0.073    mujer    -2.010   1.023    status    0.050   0.062    Observations  200  200    R2 / R2 adjusted  0.478 / 0.473  0.489 / 0.479     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Y para presentar en forma de ecuaciones, quedaría de la siguiente manera:\n\\[ \\operatorname{\\widehat{ciencia}} = 11.62 + 0.4(\\operatorname{matematicas}) + 0.37(\\operatorname{lectura}) \\]\\[ \\operatorname{\\widehat{ciencia}} = 12.33 + 0.39(\\operatorname{matematicas}) + 0.34(\\operatorname{lectura}) - 2.01(\\operatorname{mujer}) + 0.05(\\operatorname{status}) \\]\nPara transformar automáticamente las estimaciones de regresión en R a ecuaciones:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\nInstalar librería equatiomatic. No está en CRAN, así que para instalar:remotes::install_github(\"datalorax/equatiomatic\")\n La función para extraer la ecuación es extract_eq, por ejemplo: extract_eq(reg1)\n Para que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n  ```{r results=\u0026#39;asis\u0026#39;, echo=FALSE} extract_eq(reg1) extract_eq(reg2) ``` Para presentar las ecuaciones con los coeficientes ya estimados, extract_eq(reg1, use_coefs = TRUE)    Interpretación Los coeficientes nos hablan de la relación entre las variables independientes y la variable dependiente. Nos muestran la magnitud del cambio predicho en el puntaje de ciencia por cada 1 unidad en que aumenta el predictor.\nPara matematica el coeficiente es de 0.402 en el modelo 1 y baja a 0.389 en el modelo 2. Entonces, por cada punto adicional en la prueba de matemáticas en el modelo 2 se presenta un incremento de 0.389 en el puntaje de ciencia, manteniendo todas las demás variables constantes. Respecto a la inferencia, existen distintas maneras de dar cuenta de la significación estadística. Por ejemplo, se puede decir que este valor es estadísticamente significativo con un 99,9% de confianza, o con una probabilidad de error p\u0026lt;0.001.\nPara reportar estos resultados de manera más resumida siguiendo las indicaciones de reporte de APA (American Psychological Association): El puntaje en matemáticas predice significativamente el puntaje de ciencias (modelo 1), b = -.40, SE = .07, p \u0026lt; .001, controlando por el puntaje en lectura. Al agregar los controles de sexo y estatus (modelo 2), el puntaje en matemáticas disminuye levemente pero mantiene su nivel de significación, b = -.39, SE = .07, p \u0026lt; .001.\n Con respecto a lectura, en el modelo 2 es posible observar un coeficiente de 0.335. Esto implica que por cada unidad que aumenta el puntaje de lectura se predice un incremento de 0.335 puntos en ciencia, manteniendo todas las demás variables contantes. El coeficiente es estadísticamente significativo con una probabilidad de error p\u0026lt;0.001.\nPara la variable mujer podemos observar que el coeficiente tiene un valor de -2.010 en el modelo 2. Al ser mujer una variable dicotómica donde 1 es mujer y 0 es hombre, la estimación nos indica que para las mujeres el puntaje predicho promedio en ciencias es -2.010 puntos más bajo con respecto al promedio de los hombres, manteniendo todas las demás variables constantes. En términos exclusivamente estadísticos, la variable mujer no es significativamente distinta de 0 cuando empleamos un nivel de confianza del 95%, debido a que el valor \\(p\\) es mayor a 0.05.\nSi observamos el coeficiente de status tenemos un valor de 0.050. Entonces, por cada unidad en que incrementa el estatus se predice un incremento de 0.050 puntos en ciencia, manteniendo todas las demás variables constantes. Sin embargo, no es estadísticamente significativo a un 95% de confianza.\nStd Error: Esta columna corresponde a los errores estándar de los coeficientes de regresión (Estimate). Estos errores estándar son empleados para testear en qué medida los coeficientes son distintos de 0. El procedimiento es dividir el coeficiente por su error estándar para obstener el valor \\(t\\), los que luego se contrastan con la tabla de valores críticos t para obtener la probabilidad de error (que ya aparece automáticamente en la tabla) . Además, los errores estándar pueden ser utilizados para calcular los intervalos de confianza.\nUna manera de presentar los resultados de un modelo de regresión es a través de la visualización de los coeficientes de regresión con sus respectivos intervalos de confianza. La ventaja de este tipo de gráficos es que podemos observar la magnitud del coeficiente y las “barras de error” que representan el intervalo de confianza inferior y superior. Utilizando un intervalo de confianza de 95% de confianza:\nsjPlot::plot_model(reg2,ci.lvl = c(0.95), title = \u0026quot;\u0026quot;,vline.color = \u0026quot;grey\u0026quot;,line.size = 1)  Figure 1: Modelo 2  Lo que nos muestra este gráfico es el valor del coeficiente en el punto, y en las líneas que salen del punto se extienden según su intervalo de confianza. De acuerdo a las reglas de inferencia en regresión, lo que estamos contrastando es que el valor de este coeficiente es distinto de 0 en la población, con un cierto valor de probabilidad. Por lo tanto, si agregamos un intervalo de confianza (valores probables) asociado a una probabilidad de error, entonces podemos decir que este coeficiente es estadísticamente distinto de 0 en la población. Y en el gráfico, esto sucede cuando los intervalos no tocan el 0.\n Ajuste global del modelo R2: El R2 (R-cuadrado) es la proporción de la varianza de la variable dependiente (ciencias) la cual puede ser predicha por las variables independientes (matemáticas, mujer, estatus, lectura). En la Tabla 1 tenemos que para el Modelo (1), este valor nos indica que un 47,7% de la varianza en el puntaje de ciencias se asocia a matemáticas. Luego, en el Modelo (2), el R-cuadrado nos indica que el 48,9% de la varianza de ciencias puede ser predicha conjuntamente por las variables independientes matemáticas, lectura, mujer y status. Como vemos, la incorporación de controles aporta levemente al R2, lo cual se relaciona con que estos predictores no son estadísticamente significativos.\nAdjusted R2: En la medida que se incorporan predictores al modelo, cada uno va contribuyendo a explicar la varianza de la variable dependiente. Así, se podría continuar agregando predictores al modelo, incrementando la capacidad explicativa pero también de cierto modo debido a la variabilidad adicional en una muestra particular con la que estemos trabajando. Por esta razón, el R-cuadrado ajustado busca demostrar un valor estimado más realista del R-cuadrado para la población bajo análisis, penalizando por la inclusión de predictores adicionales. En el caso del Modelo (2) de la Tabla 1, el valor del R-cuadrado es de 0.489, mientras que el R-cuadrado ajustado es de 0.479, el cual es calculado a través de la fórmula \\(1 – ((1 – R^2)((N – 1) /( N – k – 1))\\).\nEntonces, si el número de observaciones (\\(N\\)) es pequeño y el número de predictores (\\(k\\))es grande, tendremos una mayor discrepancia entre el R-cuadrado y el R-cuadrado ajustado. Por otro lado, cuando el número de observaciones es grande en contraste con el número de predictores tendremos que el valor del R-cuadrado y el R-cuadrado ajustado serán mucho más similares debido.\nPor lo tanto, al momento de realizar la intepretación corresponde basarse en los coeficientes del R2 ajustado.\n  Referencias Bruin, J. 2006. newtest: command to compute new test. UCLA: Statistical Consulting Group. https://stats.idre.ucla.edu/stata/ado/analysis/.\n Regression analysis annotated output\n   Foro práctica 8  ","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"e65d602e49caf322a4b3b2cc0350e50c","permalink":"/assignment/08-code/","publishdate":"2020-07-13T00:00:00Z","relpermalink":"/assignment/08-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","date":1594339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"a696c93d764e2bfb447300660fcf2be7","permalink":"/class/08-class/","publishdate":"2020-07-10T00:00:00Z","relpermalink":"/class/08-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase   ","tags":null,"title":"8: Inferencia en regresión (2)","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica  Predictores categóricos Predictores dicotómicos Librerías Datos Explorar base de datos Relacion entre variables Predictores con más de una categoría  Interpretación Variables dummy   Inferencia Resumen Práctica 7 Reporte de progreso Foro práctica 7    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Es esta práctica vamos a abordar dos temas:\nPredictores categóricos en regresión\n Inferencia estadística\n  Ambos temas corresponden a dos ámbitos independientes en el estudio de la regresión. Sin embargo, la inclusión de predictores categóricos de dos niveles (o variables dicotómicas) nos permitirá una aproximación a inferencia estadística que es directamente vinculable a los conocimientos sobre diferencia de promedios mediante la prueba t.\nPredictores categóricos Hasta ahora hemos trabajado solamente con predictores a los que asumimos un nivel de medición contínua (es decir, al menos intervalar). ¿Qué sucede con predictores donde se asume un distinto nivel de medición, como nominal u ordinal? En general este tipo de predictores requiere una interpretación y tratamiento distinto que los predictores continuos.\n Predictores dicotómicos Las variables dicotómicas son aquellas variables nominales u ordinales que poseen solo dos categorías de respuesta, por ejemplo hombre/mujer, sano/enfermo, deportista/sedentario. La inclusión de estas variables en un modelo de regresión no requiere un tratamiento especial, solo hay que considerar que su interpretación tiene un sentido distinto. A continuación, veremos un ejemplo respecto a cómo predictores categóricos (de dos o más niveles) permiten modelar el Estatus Social Subjetivo\n Librerías pacman::p_load(dplyr, #manipulacion de datos  sjPlot, #tablas  summarytools, #estadisticos descriptivos  fastDummies, # Crear variable dummy  sjlabelled, #etiquetas variables  ggplot2, #graficos  coefplot # graficos de coeficientes  )  Datos Primero, se cargará la base de datos\nload(url(\u0026quot;https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\u0026quot;)) # Cargar base de datos Los datos a utilizar corresponden a la base de datos ELSOC 2018 que incluye una muestra de 3784 mujeres y hombres adultos entre 18 y 75 años.\nVariables\n [ess]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\n [edcine]: ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente) - CINE 2011 (UNESCO).\n  [edad]: ¿Cuáles su edad? (años cumplidos).\n  view_df(elsoc_18,encoding = \u0026quot;\u0026quot;)  Data frame: elsoc_18   ID  Name  Label  Values  Value Labels    1  ess  Estatus Social Subjetivo  0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10  0 El nivel mas bajo\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10 El nivel mas alto    2  sexo  Sexo (1=Mujer)  0\n1  Hombre\nMujer    3  edad  Edad  range: 18-90    4  edcine  Educación  1\n2\n3\n4\n5  Primaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado     Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(elsoc_18, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing     1 ess [numeric] Estatus Social Subjetivo Mean (sd) : 4.4 (1.6) min 11 distinct values  3703 (100%) 0 (0%)   2 sexo [numeric] Sexo (1=Mujer) Min : 0 Mean : 0.4 Max : 1 0:2277(61.5%)1:1426(38.5%)  3703 (100%) 0 (0%)   3 edad [numeric] Edad Mean (sd) : 47 (15.5) min 70 distinct values  3703 (100%) 0 (0%)   4 edcine [numeric] Educaci\u0026#0243;n Mean (sd) : 3.2 (1.2) min 1:442(11.9%)2:365(9.9%)3:1589(42.9%)4:592(16.0%)5:715(19.3%)  3703 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n  Relacion entre variables Visualizar la asociación entre variables puede ser informativo. Sin embargo, en ocasiones es necesario prestar mayor atención al tipo de gráfico que utilizamos para esto. Por ejemplo, veamos un scatter de Estatus social Subjetivo \\(Y_\\text{estatus}\\) con sexo como independiente \\(X_\\text{sexo}\\) para comparar sus distribuciones y sus pendientes\nplot_scatter(data = elsoc_18,x = sexo,y = ess,fit.grps = \u0026quot;lm\u0026quot;) El scatterplot no es muy informativo debido a que nuestra variable independiente solamente posee dos niveles, de modo tal que la distribución de Estatus Social Subjetivo se separa en dos grandes grupos. Por esta razón, una alternativa para visualizar la distirbución es elaborar un gráfico de cajas para ambas categorías:\nplot_grpfrq(var.cnt = elsoc_18$ess,var.grp = elsoc_18$sexo,type = \u0026quot;box\u0026quot;) En este sentido, al tener solamente dos niveles en los valores de la variable X: 0 (Hombre) y 1 (Mujer). Obtenemos solamente dos medias condicionales.\nEntonces, si calculamos el promedio simple para Estatus Social Subjetivo por sexo tenemos:\nelsoc_18 %\u0026gt;% group_by(sexo) %\u0026gt;% summarise(mean_ess=mean(ess,na.rm = T)) ## # A tibble: 2 x 2 ## sexo mean_ess ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 4.34 ## 2 1 4.47 Segun esto el promedio para las mujeres es de 4.47 puntos en la escala de Estatus Social Subjetivo, mientras para los hombres es de 4.34.\nRealizando ahora la regresión:\nreg1\u0026lt;-lm(ess ~sexo, data=elsoc_18) sjPlot::tab_model(list(reg1), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,  dv.labels = c(\u0026quot;Modelo 1\u0026quot;))   Modelo 1    Predictores  β    (Intercept)  4.339 ***    Sexo(1=Mujer)  0.133 *    Observations  3703    R2 / R2 adjusted  0.002 / 0.001     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Entonces:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + \\beta_1 \\times \\text{Sexo} + \\epsilon \\] Tenemos que las mujeres (Sexo = 1) tienen un promedio 0.133 puntos más alto que los hombres (Sexo = 0) en la escala de estatus social subjetivo. En este caso, el grupo de los hombres corresponde a la categoría de referencia.\nPor lo tanto, ¿cuál es la predicción de estatus social subjetivo para la variable sexo?\nPara el caso de los hombres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 0 = 4.339\\] En cambio, para las mujeres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 1 = 4.472\\]\nEntonces cuando calculamos el promedio de Estatus social Subjetivo \\(Y_\\text{estatus}\\) para hombre (\\(X_\\text{sexo=0}\\)) mujer (\\(X_\\text{sexo=1}\\)), podemos observar que son los mismos valores que nos entrega la estimación de la regresión simple empleando Sexo como predictor de Estatus Social Subjetivo. Es decir:\n Al ingresar un regresor dicotómico en regresión simple lo que se obtiene es una estimación de la diferencia de promedios de ambas categorías en relación a la variable dependiente -en regresión múltiple esta diferencia se ajusta o controla por la presencia de otras variables, por ejemplo:  reg2\u0026lt;-lm(ess ~sexo+edad, data=elsoc_18) sjPlot::tab_model(list(reg1,reg2), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,  dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;))   Modelo 1  Modelo 2    Predictores  β  β    (Intercept)  4.339 ***  4.602 ***    Sexo(1=Mujer)  0.133 *  0.126 *    Edad   -0.006 ***    Observations  3703  3703    R2 / R2 adjusted  0.002 / 0.001  0.005 / 0.004     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{Y}_\\text{estatus} = 4.602 + 0.126 \\times \\text{Sexo} + -0.006 \\times \\text{Edad} + \\epsilon \\] Al controlar por la Edad de las personas, las mujeres tienen un promedio 0.126 más alto que el de los hombres en la escala de Estatus Social Subjetivo. Vemos que, en comparación con el Modelo 1, la diferencia en el promedio de estatus subjetivo de mujeres respecto de hombres se ajusta al incorporar la Edad. En este sentido, ¿por qué la diferencia en el promedio de estatus subjetivo entre mujeres y hombres puede verse afectada por la Edad?. Revisemos el promedio de Edad para hombres y mujeres:\nelsoc_18 %\u0026gt;% group_by(sexo) %\u0026gt;% summarise(mean_ess=mean(edad,na.rm = T)) ## # A tibble: 2 x 2 ## sexo mean_ess ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 47.5 ## 2 1 46.3 Esta información nos permite observar que los hombres tienen un promedio de edad de 1.2 años mayor que el de las mujeres. En este sentido, lo que vemos es que la diferencia promedio de estatus subjetivo entre hombres y mujeres disminuye de 0.136 a 0.126, es decir, se ajusta al considerar (controlar por) la edad de las personas.\n Predictores con más de una categoría Una de las características de estatus más importante es el nivel educacional de las personas. En este sentido, el nivel educacional puede considerarse como una variable contínua (p.ej: años de educación) o categórica (nivel/grado educacional), lo cual depende no solo de la distribución empírica de la variable sino que también del criterio de quien investiga.\nPara este ejercicio consideraremos la variable educación en base a las categorías de la Clasificación Internacional Normalizada de la Educación (UNESCO). La cual posee 5 niveles:\nsjmisc::frq(x = elsoc_18$edcine,show.na = F) ## ## Educación (x) \u0026lt;numeric\u0026gt; ## # total N=3703 valid N=2988 mean=3.21 sd=1.21 ## ## Value | Label | N | Raw % | Valid % | Cum. % ## -------------------------------------------------------------------- ## 1 | Primaria incompleta menos | 442 | 11.94 | 11.94 | 11.94 ## 2 | Primaria y secundaria baja | 365 | 9.86 | 9.86 | 21.79 ## 3 | Secundaria alta | 1589 | 42.91 | 42.91 | 64.70 ## 4 | Terciaria ciclo corto | 592 | 15.99 | 15.99 | 80.69 ## 5 | Terciaria y Postgrado | 715 | 19.31 | 19.31 | 100.00 Y se distribuye de esta manera:\nplot_frq(data = elsoc_18$edcine) Para poder incluir esta variable en la regresión como categórica en R la manera más simple es definirla como un factor. Primero necesitamos conocer la estructura de la variable, ya que puede venir previamente definida como factor:\nclass(elsoc_18$edcine) ## [1] \u0026quot;numeric\u0026quot; str(elsoc_18$edcine) ## num [1:3703] 2 3 3 4 3 3 3 4 5 2 ... ## - attr(*, \u0026quot;labels\u0026quot;)= Named num [1:5] 1 2 3 4 5 ## ..- attr(*, \u0026quot;names\u0026quot;)= chr [1:5] \u0026quot;Primaria incompleta menos\u0026quot; \u0026quot;Primaria y secundaria baja\u0026quot; \u0026quot;Secundaria alta\u0026quot; \u0026quot;Terciaria ciclo corto\u0026quot; ... ## - attr(*, \u0026quot;label\u0026quot;)= chr \u0026quot;Educación\u0026quot; Vemos que al emplear class, R nos indica que edcine es una variable numérica con 5 valores distintos. Además, al correr str se nos indica que dichos valores numéricos poseen atributos en forma de etiquetas (labels). Entonces, si estimamos la regresión con la variable tal cual como está, obtenemos lo siguiente:\nreg3\u0026lt;-lm(ess~edcine,data = elsoc_18) sjPlot::tab_model(list(reg3), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,  dv.labels = c(\u0026quot;Modelo 3\u0026quot;))   Modelo 3    Predictores  β    (Intercept)  3.329 ***    Educación  0.331 ***    Observations  3703    R2 / R2 adjusted  0.064 / 0.064     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     El coeficiente de regresión nos indica que por cada nivel adicional de educación, hay un aumento de 0.331 puntos en la escala de estatus social subjetivo. Sin embargo, dada la naturaleza de nuestra variable, decir “por cada nivel educacional” es poco informativo, por lo tanto la manera más adecuada de utilizar nuestra variable en la estimación de una regresión es transformarla en un factor empleando la función as_factor() De la librería sjlabelled .\nelsoc_18$edcine\u0026lt;-as_factor(elsoc_18$edcine) Nota: en R existe la función as.factor(), sin embargo, en esa ocasión usamos as_factor() debido a que es compatible los vectores numéricos etiquetados y nos permite matener todos los atributos de las variables, tales como las etiquetas de variable y valores.\n Teniendo nuestra variable transformada a factor, estimamos nuevamente la regresión:\nreg4 \u0026lt;-lm(ess~edcine,data = elsoc_18) sjPlot::tab_model(list(reg3,reg4), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,  dv.labels = c(\u0026quot;Modelo 3\u0026quot;,\u0026quot;Modelo 4\u0026quot;))   Modelo 3  Modelo 4    Predictores  β  β    (Intercept)  3.329 ***  3.794 ***    Educación  0.331 ***     Educación: Primaria y\nsecundaria baja   0.151     Educación: Secundaria\nalta   0.476 ***    Educación: Terciaria\nciclo corto   0.811 ***    Educación: Terciaria y\nPostgrado   1.279 ***    Observations  3703  3703    R2 / R2 adjusted  0.064 / 0.064  0.066 / 0.065     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Interpretación Al igual que en el modelo empleando Educación como variable continua, el modelo con Educación categórica muestra que a medida que aumenta el nivel educacional, el promedio de estatus subjetivo tiende a ser más alto. Por otro lado, en este caso la categoría de referenca es Primaria Incompleta o menos. Entonces:\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Primaria y Secundaria baja es 0.151 puntos más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Secundaria Alta es 0.476 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria ciclo corto es 0.811 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria y Postgrado es de 1.279 más alto con respecto a las personas con educación Primaria Incompleta o menos.\n Alternativamente es posible cambiar la categoría de referencia. Por ejemplo, si quisieramos que la referencia fuera el nivel educativo más alto “Terciaria y Postgrado” (5) debemos usar relevel(edcine, ref =5):  reg4.1 \u0026lt;-lm(ess~relevel(edcine,ref=5),data = elsoc_18) summary(reg4.1) ## ## Call: ## lm(formula = ess ~ relevel(edcine, ref = 5), data = elsoc_18) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.0727 -0.7941 0.0548 0.7300 6.2059 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.07273 0.05710 88.833 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)1 -1.27861 0.09239 -13.839 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)2 -1.12752 0.09823 -11.479 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)3 -0.80275 0.06876 -11.674 \u0026lt; 2e-16 *** ## relevel(edcine, ref = 5)4 -0.46800 0.08485 -5.516 3.71e-08 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.527 on 3698 degrees of freedom ## Multiple R-squared: 0.06634, Adjusted R-squared: 0.06533 ## F-statistic: 65.69 on 4 and 3698 DF, p-value: \u0026lt; 2.2e-16  Variables dummy La manera tradicional de incluir predictores categóricos de más de dos niveles (variable politómica) es a través de las denominadas variables dummy. Tal como vimos en el ejemplo anterior, se incluyen n-1 categorías en el modelo dado que siempre se mantiene una como categoría de referencia.\nPara explorar nuestra base de datos, usaremos la función head() que nos mostrará las primeras 6 filas de nuestra base de datos para observar la variable Educación.\nhead(elsoc_18) ## ess sexo edad edcine ## 1 9 0 66 2 ## 2 5 0 62 3 ## 3 5 0 28 3 ## 4 5 1 53 4 ## 5 5 1 63 3 ## 6 5 0 56 3 Para la construcción de las variables dummy, usaremos la función dummy_cols() de la librería fastDummies. En el argumento select_columns, le indicamos cuál es la variable que usaremos para construir las variables dummy:\nlibrary(fastDummies) elsoc_18 \u0026lt;-dummy_cols(elsoc_18,select_columns = \u0026quot;edcine\u0026quot;) Revisamos nuestra base de datos:\nhead(elsoc_18) ## ess sexo edad edcine edcine_1 edcine_2 edcine_3 edcine_4 edcine_5 ## 1 9 0 66 2 0 1 0 0 0 ## 2 5 0 62 3 0 0 1 0 0 ## 3 5 0 28 3 0 0 1 0 0 ## 4 5 1 53 4 0 0 0 1 0 ## 5 5 1 63 3 0 0 1 0 0 ## 6 5 0 56 3 0 0 1 0 0 Tal como se estimó en el modelo anterior, ahora lo que haremos es seleccionar cada dummy para las categorías 2, 3, 4 y 5 de la variable edcine. Esto implica que el nivel 1 (Primaria incompleta o menos) será la categoría de referencia.\nreg5 \u0026lt;-lm(ess~edcine_2+edcine_3+edcine_4+edcine_5,data = elsoc_18) sjPlot::tab_model(list(reg4, reg5), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;,string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;,digits = 3,  dv.labels = c(\u0026quot;Modelo 4\u0026quot;,\u0026quot;Modelo 5\u0026quot;))   Modelo 4  Modelo 5    Predictores  β  β    (Intercept)  3.794 ***  3.794 ***    Educación: Primaria y\nsecundaria baja  0.151      Educación: Secundaria\nalta  0.476 ***     Educación: Terciaria\nciclo corto  0.811 ***     Educación: Terciaria y\nPostgrado  1.279 ***     edcine 2   0.151     edcine 3   0.476 ***    edcine 4   0.811 ***    edcine 5   1.279 ***    Observations  3703  3703    R2 / R2 adjusted  0.066 / 0.065  0.066 / 0.065     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Si observamos la tabla de arriba, vemos que las estimaciones para el modelo 4 y 5 son idénticas. La única diferencia es que en el Modelo 5 empleamos dummies para cada categoría en vez de utilizar la variable como un factor.\n   Inferencia Una de las ideas fundamentales de la inferencia es determinar si nuestros análisis estadísticos pueden ser extrapolados a la población que estamos estudiando. En el contexto de regresión, queremos conocer la significación estadística del coeficiente \\(\\beta\\).\nQueremos saber :\n¿Es significativo el coeficiente del modelo de regresión?.\n Para ello, buscamos determinar la probabilidad de que \\(\\beta \\neq 0\\)\n El concepto fundamental es el Error.\n  Conceptos clave:\nDispersión Curva normal Error estándar  Ejemplo\nSupongamos que nuestra muestra de 3703 casos corresponde a la Población, de modo tal que vamos a extraer una serie de muestras aleatorias de esta “Población” a modo de ilustrar cambios en la dispersión de los datos en la medida que aumenta el tamaño muestral.\n Recordemos que la fórmula del Error Estándar para una muestra es : \\(\\frac{s}{\\sqrt{N}}\\) donde \\(s\\) es la desviación estándar y \\(N\\) es el tamaño de la muestra.\n Bajo el supuesto de que el promedio calculado para la muestra \\(\\bar{x}\\) posee una distribución normal con una \\(s = \\text{Error Estándar (SE)}\\), es posible calcular la probabilidad de error siguiendo dicha distribución. Donde \\(\\bar{x} \\pm 2\\text{ SE}\\) abarca el 95% de la distribución.\n  set.seed(123) elsoc_n30 \u0026lt;-sample_n(tbl = elsoc_18,size = 30 ) %\u0026gt;%mutate(dataset=30 ,mean_ess=mean(ess,na.rm = T)) elsoc_n50 \u0026lt;-sample_n(tbl = elsoc_18,size = 50 ) %\u0026gt;%mutate(dataset=50 ,mean_ess=mean(ess,na.rm = T)) elsoc_n75 \u0026lt;-sample_n(tbl = elsoc_18,size = 75 ) %\u0026gt;%mutate(dataset=75 ,mean_ess=mean(ess,na.rm = T)) elsoc_n100 \u0026lt;-sample_n(tbl = elsoc_18,size = 100) %\u0026gt;%mutate(dataset=100,mean_ess=mean(ess,na.rm = T)) elsoc_n200 \u0026lt;-sample_n(tbl = elsoc_18,size = 200) %\u0026gt;%mutate(dataset=200,mean_ess=mean(ess,na.rm = T)) elsoc_n300 \u0026lt;-sample_n(tbl = elsoc_18,size = 300) %\u0026gt;%mutate(dataset=300 ,mean_ess=mean(ess,na.rm = T)) elsoc_n400 \u0026lt;-sample_n(tbl = elsoc_18,size = 400) %\u0026gt;%mutate(dataset=400,mean_ess=mean(ess,na.rm = T)) elsoc_n700 \u0026lt;-sample_n(tbl = elsoc_18,size = 700) %\u0026gt;%mutate(dataset=700,mean_ess=mean(ess,na.rm = T)) elsoc_n800 \u0026lt;-sample_n(tbl = elsoc_18,size = 800) %\u0026gt;%mutate(dataset=800,mean_ess=mean(ess,na.rm = T)) elsoc_n900 \u0026lt;-sample_n(tbl = elsoc_18,size = 900) %\u0026gt;%mutate(dataset=900,mean_ess=mean(ess,na.rm = T)) elsoc_n1000\u0026lt;-sample_n(tbl = elsoc_18,size = 1000) %\u0026gt;%mutate(dataset=1000,mean_ess=mean(ess,na.rm = T)) elsoc_n1500\u0026lt;-sample_n(tbl = elsoc_18,size = 1500) %\u0026gt;%mutate(dataset=1500,mean_ess=mean(ess,na.rm = T)) elsoc_n2000\u0026lt;-sample_n(tbl = elsoc_18,size = 2000) %\u0026gt;%mutate(dataset=2000,mean_ess=mean(ess,na.rm = T)) elsoc_n2500\u0026lt;-sample_n(tbl = elsoc_18,size = 2500) %\u0026gt;%mutate(dataset=2500,mean_ess=mean(ess,na.rm = T)) # elsoc \u0026lt;- elsoc_18 %\u0026gt;% mutate(dataset=3703,mean_ess=mean(ess,na.rm = T))  fullmat\u0026lt;-bind_rows(elsoc_n30 ,elsoc_n50 ,elsoc_n75 ,elsoc_n100,elsoc_n200,elsoc_n300,elsoc_n400,elsoc_n700,elsoc_n800,elsoc_n900,elsoc_n1000,elsoc_n1500,elsoc_n2000,elsoc_n2500) fullmat \u0026lt;-fullmat %\u0026gt;%mutate(mean_ssta=mean(elsoc_18$ess,na.rm = T)) Luego de obtener las muestras, calculamos la media, desviación estándar y Error estándar:\ntab_full\u0026lt;-fullmat %\u0026gt;%group_by(dataset) %\u0026gt;%summarise(mean=mean(ess,na.rm = T), sd=sd(ess,na.rm = T),SE=sd/sqrt(n())) tab_full ## # A tibble: 14 x 4 ## dataset mean sd SE ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 30 4.07 1.41 0.258 ## 2 50 4.58 1.59 0.225 ## 3 75 4.39 1.60 0.185 ## 4 100 4.4 1.49 0.149 ## 5 200 4.46 1.47 0.104 ## 6 300 4.3 1.55 0.0893 ## 7 400 4.36 1.58 0.0789 ## 8 700 4.35 1.62 0.0611 ## 9 800 4.38 1.54 0.0544 ## 10 900 4.36 1.58 0.0525 ## 11 1000 4.40 1.57 0.0498 ## 12 1500 4.39 1.56 0.0403 ## 13 2000 4.42 1.56 0.0349 ## 14 2500 4.38 1.58 0.0317  Es posible observar que tanto la media como la desviación estándar van cambiando en la medida que aumenta el tamaño de la muestra, pero si observamos el Error Estándar, este va sistemáticamente disminuyendo en la medida que aumenta el tamaño muestral.  Para ilustrar cómo va cambiando la dispersión y la media “muestral” (rojo) con respecto a la “poblacional” (verde), se puede observar el siguiente gráfico:\n Este ejemplo sirve para ilustrar de qué manera el Error Estándar de la media \\(\\bar{x}\\) nos permite determinar la significancia estadística de un coeficiente de regresión \\(\\beta\\).\n En regresión nos interesa saber si las diferencias en Y con respecto a los distintos niveles o valores de X son significativas, es decir estadisticamente distintas de 0.\n  Volviendo nuestro ejemplo inicial: Estatus Social subjetivo según Sexo.\n Estimamos una regresión para cuatro de las muestras de distinto tamaño usando Sexo como predictor de Estatus subjetivo.  reg100 \u0026lt;-lm(ess~sexo,data=elsoc_n100) reg1500\u0026lt;-lm(ess~sexo,data=elsoc_n1500) reg2000\u0026lt;-lm(ess~sexo,data=elsoc_n2000) reg2500\u0026lt;-lm(ess~sexo,data=elsoc_n2500)  Nos interesa saber si el promedio de Mujeres respecto de Hombres es distinto de 0.\n La estimación de la regresión realiza este procedimiento a través del cálculo de la significación estadística. Los modelos entregan el resultado ya calculado en base al Error Estándar del \\(\\beta\\).\n Para determinar esto, se realiza una prueba de hipótesis nula. En regresión la hipótesis nula es:\n  \\[ H_0: \\beta =0\\] En relación a la hipótesis alternativa:\n\\[ H_1: \\beta \\neq 0\\]\n Este contraste se basa en el cálculo de un invervalo de confianza para el coeficiente, asumiendo +/- 2 SE (o al 95% de confianza). Entonces, si este intervalo no pasa por cero, entonces rechazamos \\(H_0\\).\n Entonces, ¿es estadísticamente significativa la diferencia del promedio de Estatus Subjetivo entre hombres y mujeres?. Revisemos para nuestras muestras de distinto tamaño:\n  rbind(broom::tidy(reg100)[2,1:3], # n=100  broom::tidy(reg1500)[2,1:3], # n=1500  broom::tidy(reg2000)[2,1:3], # n=2000  broom::tidy(reg2500)[2,1:3]) # n=2500 ## # A tibble: 4 x 3 ## term estimate std.error ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 sexo 0.0440 0.314 ## 2 sexo 0.0489 0.0829 ## 3 sexo 0.145 0.0715 ## 4 sexo 0.196 0.0649  Al igual que en ejemplo anterior, el error estándar va sistematicamente disminuyendo en la medida que empleamos una muestra más grande. Ahora, ¿son estas diferencias en el promedio entre mujeres respecto de hombres estadísticamente signifciativas al 95% de confianza?. Calculemos los intervalos de confianza:\n Para el caso de la muestra de 100 casos tenemos:\n  #Beta +/- 2*SE = IC 0.0440 -2*0.314 #intervalo confianza inferior 0.0440 +2*0.314 #intervalo confianza superior ## [1] -0.584 ## [1] 0.672  Para el caso de la muestra de 1500 casos tenemos:  0.0489 -2*0.0829 #intervalo confianza inferior 0.0489 +2*0.0829 #intervalo confianza superior ## [1] -0.1169 ## [1] 0.2147  Para el caso de la muestra de 2000 casos tenemos:  0.145 -2*0.0715 #intervalo confianza inferior 0.145 +2*0.0715 #intervalo confianza superior ## [1] 0.002 ## [1] 0.288  Para el caso de la muestra de 2500 casos tenemos:  0.196 -2*0.0649 #intervalo confianza inferior 0.196 +2*0.0649 #intervalo confianza superior ## [1] 0.0662 ## [1] 0.3258  Vemos que para las muestras de 100 y 1500, el intervalo inferior cruza el valor 0, por tanto no rechazamos \\(H_0\\). Lo cual implica que no hay diferencias estadísticamente significativas en el promedio de estatus social subjetivo de mujeres respecto de hombres.\n Por otro lado, en muestras de 2000 y 2500, el intervalo inferior no cruza el valor 0, por tanto rechazamos \\(H_0\\). Lo cual implica que la diferencia en el promedio de estatus social subjetivo de mujeres respecto de hombres es estadísticamente signficativa a un 95% de confianza.\n  Visualmente lo podemos ver en el siguiente gráfico usando la librería coefplot.\n Cada punto representa el coeficiente de Sexo (Mujer=1) para cada modelo. Las líneas horizontales representan los intervalos de confianza.  coefplot::multiplot(reg2500,reg2000,reg1500,reg100,  shorten = T,  intercept = F,  xlab = \u0026quot;\u0026quot;,title = \u0026quot;Modelos según tamaño de muestra\u0026quot;,  zeroColor = \u0026quot;black\u0026quot;,  linetype = 1) + scale_y_discrete(\u0026quot;\u0026quot;,labels = c(\u0026quot;Sexo (mujer=1)\u0026quot;)) + theme_bw() De manera resumida en una tabla podemos verlo así:\nsjPlot::tab_model(list(reg100,reg1500,reg2000,reg2500),  dv.labels = c(\u0026quot;n=100\u0026quot;,\u0026quot;n=1500\u0026quot;,\u0026quot;n=2000\u0026quot;,\u0026quot;n=2500\u0026quot;),  show.se = T,digits = 3,  string.est = \u0026quot;β\u0026quot;,show.intercept = F,  string.ci = \u0026quot;CI 95%\u0026quot;,string.se = \u0026quot;SE\u0026quot;,  show.p = F)   n=100  n=1500  n=2000  n=2500    Predictors  β  SE  CI 95%  β  SE  CI 95%  β  SE  CI 95%  β  SE  CI 95%    Sexo(1=Mujer)  0.044  0.314  -0.579 – 0.667  0.049  0.083  -0.114 – 0.212  0.145  0.072  0.004 – 0.285  0.196  0.065  0.069 – 0.323    Observations  100  1500  2000  2500    R2 / R2 adjusted  0.000 / -0.010  0.000 / -0.000  0.002 / 0.002  0.004 / 0.003     Resumen Práctica 7 En esta práctica revisamos los siguientes contenidos:\n Predictores categóricos Variables dummy Inferencia estadística Inferencia en Regresión   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica [https://forms.gle/ACUm93yHPQQpLco4A]\n Foro práctica 7  ","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"48f42589bcb94587b7dfcb568ba66719","permalink":"/assignment/07-code/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/assignment/07-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    ","date":1593734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"026700f4d4068083b37f98f89edf4682","permalink":"/class/07-class/","publishdate":"2020-07-03T00:00:00Z","relpermalink":"/class/07-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    ","tags":null,"title":"7: Categóricos / inferencia (1)","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"/class/06-class/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión múltiple 2","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica  Librerías Datos Explorar base de datos Modelo de regresión simple Relacion entre variables Modelo de regresión multiple Interpretación  Intercepto Coeficientes de regresion  Comparando el modelo de regresión simple con múltiple ¿Por qué utilizar R^2 ajustado?  Resumen Práctica 5: Reporte de progreso Foro práctica 5    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica nos enfocaremos en el concepto de regresión múltiple, a partir de la incorporación de dos o más predictores en el modelo. Para ello utilizaremos el ejemplo 3.1 de Wooldridge (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías pacman::p_load(ggpubr, #graficos  dplyr, #manipulacion de datos  sjPlot, #tablas  gridExtra, #unir graficos  texreg, #mostrar regresion multiple  summarytools, #estadisticos descriptivos  wooldridge) #paquete con los ejemplos del libro  Datos Los datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene vaiables - [\\(colGPA\\)]: promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos. - [\\(hsGPA\\)]: promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos - [\\(ACT\\)]: puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos Primero, se cargará la base de datos que contiene la librería wooldridge y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos gpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables  Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026#39;render\u0026#39;))  Modelo de regresión simple Si solo nos centramos en el análisis de regresión simple, intuitivamente partiremos por predecir las calificaciones de la universidad a partir del puntaje obtenido en la prueba de admisión a esta. Formalmente\n\\[\\widehat{colGPA} = b_{0} +b_{1}ACT \\]\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) #Crear regresion simple summary(col_actmodel) ## ## Call: ## lm(formula = colGPA ~ ACT, data = gpa1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.85251 -0.25251 -0.04426 0.26400 0.89336 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.40298 0.26420 9.095 8.8e-16 *** ## ACT 0.02706 0.01086 2.491 0.0139 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.3656 on 139 degrees of freedom ## Multiple R-squared: 0.04275, Adjusted R-squared: 0.03586 ## F-statistic: 6.207 on 1 and 139 DF, p-value: 0.0139 En formato publicable:\nsjPlot::tab_model(col_actmodel, show.ci=FALSE) #Tabla resumen de resultados   col GPA    Predictors  Estimates  p    (Intercept)  2.40  \u0026lt;0.001    ACT  0.03  0.014    Observations  141    R2 / R2 adjusted  0.043 / 0.036    En consecuencia, nuestro modelo que relaciona el promedio de calificaciones en la universidad solo con el puntaje obtenido en el examen de admisión señala que por cada punto adicional que se obtiene en la prueba de admisión, el promedio de la universidad aumenta en 0.027 (aproximado en la tabla de sjPlot a 0.03) puntos promedio.\n\\[\\widehat{colGPA} = 2.40 +0.0271ACT \\]\nAhora bien, si miramos nuestro \\(R^2\\) notaremos que \\(ACT\\) solo explica en un 4.3% la varianza de \\(colGPA\\). Por ello, incluiremos el promedio de las calificaciones de la enseñanza media (\\(hsGPA\\)) para intentar predecir mejor el promedio general de las calificaciones en la universidad.\n Relacion entre variables Se grafican las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus respectivas regresiones simples.\n#Grafico x1 = ACT gact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,  shape = 21, size = 3, # Forma y tamaño de puntos  add = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion  cor.coef = TRUE)# Agregar coeficiente correlacion #Grafico x2 = hsGPA ghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,  shape = 21, size = 3,  add = \u0026quot;reg.line\u0026quot;,  cor.coef = TRUE)  grid.arrange(gact, ghsGPA, nrow = 1) # Unir graficos Con el gráfico anterior podemos notar que si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente. Ahora bien, ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?\n Modelo de regresión multiple Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nGrabar / exportar tablas :Exportar tablas  modelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n col_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) col_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1) col_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1) sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3    Predictores  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***    ACT  0.03 *   0.01     hsGPA   0.48 ***  0.45 ***    Observations  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{colGPA} = 1.29 +0.0094 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n Interpretación ¿Cómo se interpreta esta ecuación general de \\(colGPA\\) con dos predictores?\nIntercepto  El intercepto 1.20 indica la predicción del promedio general de calificaciones en la universidad (\\(colGPA\\)) si \\(hsGPA\\) y \\(ACT\\) son ambos cero. Este intercepto no tiene mucho significado debido a que eso implica un individuo ficticio que no haya ni asistido a la universidad ni haya asistido a la enseñanza media, por lo cual no es parte de nuestra pregunta por las determinantes del promedio en la universidad.   Coeficientes de regresion  Fijémonos en los coeficientes de regresión de \\(hsGPA\\). Como era de esperar en función de los gráficos que habíamos presentado, existe una relación positiva entre \\(hsGPA\\) y \\(colGPA\\): con \\(ACT\\) constante, cada punto más en \\(hsGPA\\) se relaciona con un aumento en 0.453 puntos adicionales en \\(colGPA\\), es decir, casi medio punto.  En otras palabras, si se eligen dos estudiantes, A y B, y estos tienen la misma puntación en el exámen de admisión (\\(ACT\\)), pero el promedio en la enseñanza media de A es mayor al de B (\\(hsGPA\\)), entonces se predice que en la universidad el estudiante A tendrá un promedio general de 0.453 puntos más altos que el estudiante B.\n Fijémonos ahora en el coeficiente de regresión de \\(ACT\\): si \\(hsGPA\\) permanece constante, un aumento en un punto de \\(ACT\\) solo produce un aumento en 0.0094 puntos en \\(colGPA\\), es decir, un cambio muy pequeño.  De hecho, un cambio de 10 puntos en el examen de admisión \\(ACT\\) tendrá un efecto sobre \\(colGPA\\) de menos de una décima de punto, es decir, menor al cambio que tiene \\(hsGPA\\). Además, la posibilidad de tener un cambio de 10 puntos en \\(ACT\\) es muy grande pues como mostramos en los estadísticos descriptivos de nuestras variables el promedio de puntaje en \\(colGPA\\) es 24 puntos con una desviación estándar de 2.8, lo que hace poco posible ese cambio en la realidad.\nCon esto podemos decir que el puntaje en el examen de admisión \\(ACT\\) no es un fuerte predictor del promedio de calificaciones en la universidad \\(colGPA\\).\n  Comparando el modelo de regresión simple con múltiple Iniciamos este práctico mostrando un análisis de regresión simple con un predictor para el promedio de calificaciones en la universidad: el promedio en el examen de admisión (\\(ACT\\)).\nObtuvimos que por cada punto de aumento de \\(ACT\\), \\(colGPA\\) aumentaba en 0.0271 puntos sus calificaciones, es decir, casi el triple de lo que fue estimado en el modelo de regresión múltiple (tal como se señala en Modelo 1)\n¿Cuál de los dos modelos es más certero?\nEsto lo podemos definir a partir de la bondad de ajuste de nuestros modelos. Por un lado, el \\(R^2\\) del modelo 1 es de 4.3% mientras que en el modelo 3 el \\(R^2ajustado\\) es de 16%, es decir, las variables que se contienen en el modelo explican más la varianza de nuestra variable dependiente.\n ¿Por qué utilizar R^2 ajustado? Hasta ahora habíamos utilizado \\(R^2\\) que nos señalaba qué porcentaje de la variación de la variable dependiente es explicada por la variable independiente.\nAhora bien, es esperable que a medida que añadimos más variables a una regresión, el \\(R^2\\) tiende a aumentar a pesar de que la contribución de cada una de las variables nuevas no tenga relevancia estadística.\nPor ello, el \\(R^2\\) ajustado se utiliza en la regresión múltiple para analizar en conjunto la intensidad que tienen las variables independientes en explicar la variable dependiente. Es decir, el \\(R^2\\) ajustado nos dice qué porcentaje de variación de la variable dependiente es explicado colectivamente por todas las variables independientes.\nEn consecuencia, \\(R^2\\) ajustado nos permite determinar mejor si añadir una nueva variable al modelo permite explicar una mayor parte de la variación de la variable dependientE.\nEn el ejercicio anterior bien podemos hacer este análisis comparando los \\(R^2\\) de nuestros modelos 1 y 2 para luego mirar el resultado de nuestro \\(R^2\\) ajustado en nuestro modelo 3. Como podremos notar el \\(R^2\\) del modelo 2 es de 17%, mientras que el \\(R^2\\) es de 18% y el \\(R^2\\) ajustado de 16%.\nEn palabras más simples, si solo miramos el \\(R^2\\) llegaremos a la conclusión de que aunque por mínimo que sea, nuestro modelo 3 ajusta mejor que el modelo 2 pues la variable \\(ACT\\) permitiría predecir mejor \\(colGPA\\) en conjunto a \\(hsGPA\\). Sin embargo, \\(R^2 ajustado\\) del modelo 3 (16%) es menor que la del modelo 2 (17%) por lo que la incorporación de \\(ACT\\) al modelo múltiple no tiene un aporte significativo.\nDe hecho, un punto no menor es que \\(ACT\\) pierde significancia estadística en el modelo 3, mientras que \\(hsGPA\\) sigue siendo significativa con un 99% confianza (la significancia estadística lo revisaremos más adelante).\n  Resumen Práctica 5: En esta práctica revisamos los siguientes contenidos\n Repaso de regresión lineal simple Estimación de regresión lineal múltiple Interpretar regresión lineal múltiple Comparar regresión múltiple y simple Diferencia entre \\(R^2\\) ajustado y \\(R^2\\)   Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí.\n Foro práctica 5  ","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"e933840b45d355c28b7bb0057d254a85","permalink":"/assignment/05-code/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/assignment/05-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica  Librerías Datos Explorar base de datos Relacion entre variables Modelo de regresión multiple Interpretación  ¿Porqué se alteran los coeficientes de regresión?  Parcialización  Parcializar \\(ACT\\) de \\(hsGPA\\)  Control estadístico ¿Qué significa mantener todos los demás factores constantes?  Resumen Práctica 6: Reporte de progreso Foro práctica 6    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica nos enfocaremos en el significado de las parcializaciones en la regresión múltiple. Para ello utilizaremos el ejemplo 3.1 de Wooldrige (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\nLibrerías pacman::p_load(ggpubr, #graficos  dplyr, #manipulacion de datos  sjPlot, #tablas  gridExtra, #unir graficos  texreg, #mostrar regresion multiple  summarytools, #estadisticos descriptivos  wooldridge) #paquete con los ejemplos del libro library(wooldridge)  Datos Los datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene variables:\n \\(colGPA\\): promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\n \\(hsGPA\\) : promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\n \\(ACT\\) : puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\n  Primero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\ndata(\u0026#39;gpa1\u0026#39;) # Cargar base de datos gpa1 \u0026lt;-dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables  Explorar base de datos A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\nview(dfSummary(gpa1, headings = FALSE, method = \u0026quot;render\u0026quot;))   No Variable Stats / Values Freqs (% of Valid) Graph Valid Missing     1 colGPA [numeric] Mean (sd) : 3.1 (0.4) min 19 distinct values  141 (100%) 0 (0%)   2 hsGPA [numeric] Mean (sd) : 3.4 (0.3) min 16 distinct values  141 (100%) 0 (0%)   3 ACT [integer] Mean (sd) : 24.2 (2.8) min 15 distinct values  141 (100%) 0 (0%)    Generated by summarytools 0.9.6 (R version 4.0.2)2021-03-12\n  Relacion entre variables Se grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n#Grafico x1 = ACT y= colGPA gact \u0026lt;-ggscatter(gpa1, x = \u0026quot;ACT\u0026quot;, y = \u0026quot;colGPA\u0026quot;,  shape = 21, size = 3, # Forma y tamaño de puntos  add = \u0026quot;reg.line\u0026quot;, #Agregar recta de regresion  cor.coef = TRUE)# Agregar coeficiente correlacion #Grafico x2 = hsGPA y= colGPA ghsGPA \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;colGPA\u0026quot;,  shape = 21, size = 3,  add = \u0026quot;reg.line\u0026quot;,  cor.coef = TRUE)  #Grafico x2 = hsGPA x1 = ACT gact_hs \u0026lt;-ggscatter(gpa1, x = \u0026quot;hsGPA\u0026quot;, y = \u0026quot;ACT\u0026quot;,  shape = 21, size = 3,  add = \u0026quot;reg.line\u0026quot;,  cor.coef = TRUE)  grid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos Con el gráfico anterior podemos notar dos puntos relevantes:\n Si bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\n Como es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\n  En la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo\n Modelo de regresión multiple Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\nRegresión múltiple  modelo \u0026lt;- lm(y ~ x1 + x2 , data = data)\n Por fines de comparación, se estimaran primero dos regresiones simples con cada predictor, y luego la regresión múltiple en el Modelo 3:\ncol_actmodel\u0026lt;-lm(colGPA ~ACT, data=gpa1) col_hsmodel\u0026lt;-lm(colGPA ~hsGPA, data=gpa1) col_model \u0026lt;-lm(colGPA ~ACT +hsGPA, data = gpa1) sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3    Predictores  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***    ACT  0.03 *   0.01     hsGPA   0.48 ***  0.45 ***    Observations  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     \\[\\widehat{colGPA} = 1.29 +0.01 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n Interpretación ¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante Por otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n¿Porqué se alteran los coeficientes de regresión? Como vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).\n  Parcialización La forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en compun \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{2}\\triangle{hsGPA} \\]\nParcializar \\(ACT\\) de \\(hsGPA\\) ¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado po \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\nPaso 1: Estimar modelo model_act_hs =lm(ACT ~hsGPA, data = gpa1) #Crear regresion con predictores coef(model_act_hs) ## (Intercept) hsGPA ## 13.696763 3.074331 En consecuencia tenemos que \\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\n Paso 2: calcular valores predichos y residuos Sabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos res_act_hs=residuals(model_act_hs) #Calcular residuos gpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos head(gpa1) #Mostrar los primeros elementos de la base de datos ## colGPA hsGPA ACT fit_act_hs res_act_hs ## 1 3.0 3.0 21 22.91975 -1.9197550 ## 2 3.4 3.2 24 23.53462 0.4653787 ## 3 3.0 3.6 26 24.76435 1.2356469 ## 4 3.5 3.5 27 24.45692 2.5430797 ## 5 3.6 3.9 28 25.68665 2.3133472 ## 6 3.0 3.4 25 24.14949 0.8505125 Podemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n Paso 3: Crear regresión con variable parcializada Ahora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\nact_hs_model \u0026lt;-lm(colGPA ~res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT sjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \u0026quot;asterisk\u0026quot;, dv.labels = c(\u0026quot;Modelo 1\u0026quot;, \u0026quot;Modelo 2\u0026quot;, \u0026quot;Modelo 3\u0026quot;, \u0026quot;Modelo 4\u0026quot;),string.pred = \u0026quot;Predictores\u0026quot;, string.est = \u0026quot;β\u0026quot;)   Modelo 1  Modelo 2  Modelo 3  Modelo 4    Predictores  β  β  β  β    (Intercept)  2.40 ***  1.42 ***  1.29 ***  3.06 ***    ACT  0.03 *   0.01      hsGPA   0.48 ***  0.45 ***     res_act_hs     0.01     Observations  141  141  141  141    R2 / R2 adjusted  0.043 / 0.036  0.172 / 0.166  0.176 / 0.164  0.005 / -0.003     p\u0026lt;0.05 ** p\u0026lt;0.01 *** p\u0026lt;0.001     Lo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.\n   Control estadístico ¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\nplot_model(col_model, show.values = TRUE)+theme_sjplot() Como podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de qué variable enfatizar: esto dependen de las hipótesis que queremos probar con nuestros modelos.\n ¿Qué significa mantener todos los demás factores constantes? En la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recoltados de manera constante. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\). Más bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.\n  Resumen Práctica 6: En esta práctica revisamos los siguientes contenidos - Repaso de regresión lineal múltiple - Parcialización - Control estadístico\n Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica [https://forms.gle/mMmR8qZxVJ1uYeUw8]\n Foro práctica 6  ","date":1592524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"c721292a113c2490ec6624b75af80b46","permalink":"/assignment/06-code/","publishdate":"2020-06-19T00:00:00Z","relpermalink":"/assignment/06-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"/class/05-class/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión múltiple 1","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Librerías Datos Residuos Modelo y cálculo de parámetros Bondad de Ajuste: Residuos y \\(R^{2}\\) Suma de cuadrados y \\(R^{2}\\) Visualización El coeficiente de Regresión versus el coeficiente de correlación Reporte de progreso Foro    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica Basados en el cálculo de parámetros del modelo de regresión en la práctica anterior (intercepto y coeficiente de regresión o pendiente), en esta práctica nos abocamos a temas de ajuste, residuos y relación entre correlación y regresión. La práctica está basada en el ejemplo de Darlington \u0026amp; Hayes cap. 2 (The simple regression model), que utilizamos en clases.\n Librerías pacman::p_load(stargazer, ggplot2, dplyr,webshot)  Datos Los datos a utilizar son los mismos que los de la práctica 3, corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego: el número de veces que se ha jugado antes (X) y el número de puntos ganados (Y).\ndatos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;) datos ## id juegos_x puntos_y ## 1 1 0 2 ## 2 2 0 3 ## 3 3 1 2 ## 4 4 1 3 ## 5 5 1 4 ## 6 6 2 2 ## 7 7 2 3 ## 8 8 2 4 ## 9 9 2 5 ## 10 10 3 2 ## 11 11 3 3 ## 12 12 3 4 ## 13 13 3 5 ## 14 14 3 6 ## 15 15 4 3 ## 16 16 4 4 ## 17 17 4 5 ## 18 18 4 6 ## 19 19 5 4 ## 20 20 5 5 ## 21 21 5 6 ## 22 22 6 5 ## 23 23 6 6 También desde esta misma dirección web se pueden bajar los datos y llamarlos localmente\nDirectorio de trabajo :Directorio de trabajo \nPara el trabajo de análisis de datos se recomienda establecer claramente el directorio de trabajo, es decir, la carpeta que contiene los archivos de datos, los códigos y los resultados. Esta carpeta es el lugar donde uno se posiciona para hacer los análisis, llamar otros archivos y exportar archivos.\nPara esto, varias opciones:\n en RStudio, Session \u0026gt; Set Working Directory \u0026gt; Choose Directory o también vía consola con el comando setwd(ruta-hacia-la-carpeta-local)  Si se quiere verificar en qué carpeta se está trabajando, comando getwd()\nCon esto entonces, si los datos están guardados en la misma carpeta, entonces se llaman simplemente datos \u0026lt;- read.csv(\"tacataca.txt\", sep=\"\"). No se requiere dar la ruta completa justamente porque el programa ya sabe dónde uno está posicionado. Asimísmo, al momento de guardar/exportar algún resultado, automáticamente quedará en la carpeta de trabajo.\n Recordando la distribución de los datos y la recta de regresión:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() + geom_smooth(method=lm, se=FALSE) g2 Grabar / exportar gráficos :Exportar gráficos  Si se quiere grabar un gráfico para luego utilizarlo en algún documento fuera del entorno R, algunas alternativas:\n utilizar la función ggsave (para gráficos ggplot)  ggsave(\u0026quot;g2.png\u0026quot;, g2)  más genéricamente, para guardar como imagen cualquier cosa que aparece en el visor de RStudio:  png(file = \u0026quot;g2.png\u0026quot;) # se abre un archivo vacío g2 # se genera el gráfico a guardar en el archivo dev.off() # se cierra el archivo  El gráfico quedará grabado en el directorio de trabajo (ver arriba). Si se desea que se grabe en otra parte, dar la ruta completa hacia la carpeta correspondiente (“C:/[ruta-hacia-carpeta]/g2.png”)\n  Residuos En el gráfico anterior vemos que la línea resume la relación entre X e Y que se denomina recta de regresión, caracterizada por un intercepto y una pendiente.\nClaramente, esta recta es una simplificación que no abarca toda la variabilidad de los datos. Por ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exactamente su puntaje basado en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje.\nLo anterior tiene que ver con el concepto de residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\). Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina suma de residuos al cuadrado o \\(SS_{residual}\\) ya que como hay residuos positivos y negativos unos se cancelan a otros y la suma es 0. De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: residuos cuadrados ordinarios, o OLS (Ordinary Least Squares).\n Modelo y cálculo de parámetros Como vimos la práctica anterior, el modelo de regresión entonces se relaciona con una ecuación de la recta, o recta de regresión, que se puede definir en términos simples de la siguiente manera:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos) reg1 ## ## Call: ## lm(formula = puntos_y ~ juegos_x, data = datos) ## ## Coefficients: ## (Intercept) juegos_x ## 2.5 0.5 Podemos generar una tabla en un formato más publicable:\nstargazer(reg1, type=\u0026quot;text\u0026quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## puntos_y ## ----------------------------------------------- ## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## ----------------------------------------------- ## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## =============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 También es posible generar una tabla más resumida en formato publicable y visible en RStudio:\nsjPlot::tab_model(reg1, show.ci=FALSE)   puntos y    Predictors  Estimates  p    (Intercept)  2.50  \u0026lt;0.001    juegos_x  0.50  0.001    Observations  23    R2 / R2 adjusted  0.405 / 0.376    Grabar / exportar tablas :Exportar tablas \nMuchas de las tablas producidas con R son en formato html, es decir, archivos para ser publicados en formato web. Por lo tanto, en general las tablas se graban primero como html, y luego se convierten a formato imagen con la librería webshot.\nPara tablas generadas con stargazer\nstargazer(reg1, type=\u0026quot;html\u0026quot;, out = \u0026quot;reg1.html\u0026quot;) webshot(\u0026quot;reg1.html\u0026quot;,\u0026quot;reg1.png\u0026quot;) Alternativamente, para tablas de regresión con sjPlot:\nsjPlot::tab_model(reg1, show.ci=FALSE, file = \u0026quot;reg1_tab.html\u0026quot;) webshot(\u0026quot;reg1_tab.html\u0026quot;,\u0026quot;reg1_tab.png\u0026quot;)    Bondad de Ajuste: Residuos y \\(R^{2}\\) A partir del método de Mínimos Cuadrados Ordinarios obtenemos una recta que describe un conjunto de datos minimizando las diferencias entre el modelo y la distribución de los datos mismos.\nNo obstante, incluso cuando se ajusta el mejor modelo siempre existirá un grado de imprecisión, representado por las diferencias entre los datos observados y los valores predichos por la recta de regresión.\nLa precisión de nuestro modelo se relaciona con el concepto de Bondad de Ajuste, y se evalúa a partir del estadístico \\(R^2\\).\nEn el siguiente apartado se puede observar la manera de calcular la predicción de Y (puntos_y) en base a X (juegos_x), y almacenarlos en la base de datos, con los respectivos residuos.\n#summary(lm(puntos_y~juegos_x, data=datos)) #beta=0.5 intercepto=2.5  #Variable de valores predichos datos$estimado\u0026lt;-(2.5 +datos$juegos_x*0.5)  # Alternativa por comando #datos$estimado \u0026lt;- predict(reg1)  #Estimamos el residuo datos$residuo \u0026lt;-datos$puntos_y -datos$estimado  # Alternativa por comando #datos$residuo \u0026lt;- residuals(reg1)  datos %\u0026gt;%select(id, estimado, residuo) ## id estimado residuo ## 1 1 2.5 -0.5 ## 2 2 2.5 0.5 ## 3 3 3.0 -1.0 ## 4 4 3.0 0.0 ## 5 5 3.0 1.0 ## 6 6 3.5 -1.5 ## 7 7 3.5 -0.5 ## 8 8 3.5 0.5 ## 9 9 3.5 1.5 ## 10 10 4.0 -2.0 ## 11 11 4.0 -1.0 ## 12 12 4.0 0.0 ## 13 13 4.0 1.0 ## 14 14 4.0 2.0 ## 15 15 4.5 -1.5 ## 16 16 4.5 -0.5 ## 17 17 4.5 0.5 ## 18 18 4.5 1.5 ## 19 19 5.0 -1.0 ## 20 20 5.0 0.0 ## 21 21 5.0 1.0 ## 22 22 5.5 -0.5 ## 23 23 5.5 0.5  Suma de cuadrados y \\(R^{2}\\) Usando la media como modelo podemos calcular las diferencias entre los valores observados y los valores predichos por la media.\n Suma Total de Cuadrados: La suma de las diferencias del promedio de Y al cuadrado (asociado al concepto de varianza de Y)  \\[SS_{tot} = \\sum(y-\\bar{y})^2 \\] Y calculamos\nss_tot\u0026lt;-sum((datos$puntos_y-mean(datos$puntos_y))^2); ss_tot ## [1] 42  Suma de cuadrados de la regresión: se refiere a la suma de diferencias (al cuadrado) entre el valor estimado por el modelo de regresión y la media. Expresa cuanto de la varianza de Y alcanzamos a predecir con X  \\[SS_{reg} = \\sum(\\hat{y}-\\bar{y})^2\\]\nss_reg\u0026lt;-sum((datos$estimado-mean(datos$puntos_y))^2) ; ss_reg ## [1] 17  Suma de residuos al cuadrado: al contrario de el cálculo anterior, los residuos representan la parte de la varianza de Y que no alcanzamos a abarcar con nuestro modelo de regresión. Es decir, reprsentan el error en la predicción (diferencia entre lo estimado por el modelo y el valor observado)  \\[SS_{error} = \\sum(y-\\hat{y})^2\\]\nss_err\u0026lt;-sum((datos$puntos_y -datos$estimado)^2);ss_err ## [1] 25 A partir de las sumas de cuadrados anteriores es posible calcular el estadístico \\(R^{2}\\)\n\\[R^2=\\frac{SS_{reg}}{SS_{tot}}= 1- \\frac{SS_{error}}{SS_{tot}}\\]\n#Opción 1 ss_reg/ss_tot ## [1] 0.4047619 #Opción 2 1-ss_err/ss_tot ## [1] 0.4047619 #por comando summary(lm(puntos_y~juegos_x, data=datos))$r.squared ## [1] 0.4047619  Visualización En la siguiente sección se presentan distintas formas de visualizar los residuos a partir del paquete ggplot2.\n#Visualizacion library(ggplot2)  ggplot(datos, aes(x=juegos_x, y=puntos_y))+ geom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion geom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas geom_point() +#Capa 1 geom_point(aes(y=estimado), shape =1) + theme_bw() En esta segunda opción, se agrega tamaño y color a los residuos mayores:\nggplot(datos, aes(x=juegos_x, y=puntos_y))+ geom_smooth(method=\u0026quot;lm\u0026quot;, se=FALSE, color=\u0026quot;lightgrey\u0026quot;) +#Pendiente de regresion geom_segment(aes(xend=juegos_x, yend=estimado), alpha = .2) +#Distancia entre estimados y datos en lineas geom_point(aes(color = abs(residuo), size = abs(residuo))) + scale_color_continuous(low = \u0026quot;black\u0026quot;, high = \u0026quot;red\u0026quot;) + guides(color = FALSE, size = FALSE) + geom_point(aes(y=estimado), shape =1) + theme_bw()  El coeficiente de Regresión versus el coeficiente de correlación Tanto \\(r_{xy}\\) y \\(\\beta_1\\) son medidas de la relación entre X e Y. Ellas estan relacionadas con la formula de:\n\\[\\beta_1= r_{xy}(S_y/S_x)\\]\nEs decir:\nbeta\u0026lt;-cor(datos$juegos_x,datos$puntos_y)*(sd(datos$puntos_y)/sd(datos$juegos_x));beta ## [1] 0.5 reg1$coefficients[2] #llamamos al coeficiente beta (en posición 2) en el objeto reg1 ## juegos_x ## 0.5 Del mismo modo existe una relación entre \\(r_{xy}\\) y \\(R^2\\)\n#Correlación (Pearson) entre juegos_x y puntos_y (r) cor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 #Correlación entre juegos_x y puntos_y al cuadrado. (cor(datos$juegos_x,datos$puntos_y))^2 ## [1] 0.4047619 La correlación entre X e Y es la misma que entre Y e X,\ncor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 cor(datos$puntos_y,datos$juegos_x) ## [1] 0.636209 … mientras la regresión entre X e Y no es la misma que entre Y e X\nlm(datos$puntos_y~datos$juegos_x)$coefficients ## (Intercept) datos$juegos_x ## 2.5 0.5 lm(datos$juegos_x~datos$puntos_y)$coefficients ## (Intercept) datos$puntos_y ## -0.2380952 0.8095238  Reporte de progreso Completar el reporte de progreso aquí.\n Foro  ","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"0b905da0b361a42246b0f7d03e970a84","permalink":"/assignment/04-code/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/assignment/04-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"/class/04-class/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de la clase    Lecturas Moore: Residuos (144-154)\n ","tags":null,"title":"Regresión simple 2","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Objetivo de la práctica Sobre hoja de código Librerías Datos  Verificación y descriptivos Experiencia en juegos y puntuación Medias condicionales Residuos Modelo de regresión y cálculo de parámetros Cálculo de los parámetros del modelo de regresión  Estimación del modelo de regresión simple en R Reporte de progreso Archivo de código Foro práctica 3    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Objetivo de la práctica En esta práctica se desarrollan ejercicios iniciales de regresión simple, que fueron presentados en la clase respectiva. El ejemplo a utilizar es del libro de Darlington \u0026amp; Hayes cap. 2 (The simple regression model).\n Sobre hoja de código Como vimos en la práctica anterior, al momento de analizar los datos separamos el trabajo en dos hojas de código distintas: preparacion.R (práctica 1) y analisis.R (práctica 2). Recordar nombres de archivos y directorios sin tildes, espacios ni ñEn este caso, los datos son simples y como es un ejemplo no realizaremos código de preparación, solo el correspondiente a análisis. Antes de comenzar, sugerimos crear un archivo de código en R con el nombre analisis: R: File-\u0026gt; New File -\u0026gt; RScript, o simplemente Ctrl + Shift + N.\n Librerías pacman::p_load(stargazer, ggplot2, dplyr)  Datos Los datos a utilizar corresponden a un ejemplo ficticio de 23 casos (individuos) y sus datos en dos variables relacionadas con un juego (originalmente de mini-golf en el texto de referencia … pero pensemos en un ejemplo más cercano, de taca-taca). Las dos variables de esta base de datos son el número de veces que se ha jugado antes (juegos_x) y el número de goles o puntos ganados (puntos_y). El archivo de datos es tacataca.txt.\nVamos a cargar estos datos en nuestro espacio de trabajo en R dándole el nombre simple de datos Dos opciones de cargar los datos en R:\n bajarlos al computador local desde este link y luego llamarlos desde el directorio respectivo donde se guardaron:  datos \u0026lt;-read.csv(\u0026quot;( ...ruta hacia el archivo ...)\\tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;)  llamarlos directamente desde su ubicación en la web:  datos \u0026lt;-read.csv(\u0026quot;https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\u0026quot;, sep=\u0026quot;\u0026quot;) Como es un archivo de texto simple (txt), los cargamos con la función read.csv, para datos guardados en texto simple separados por coma. Como en el caso de nuestros datos la separación es por espacios en lugar de comas, agregamos esta información con la instrucción sep=\"\" Para abrirlos datos recordemos que en la lógica de R se debe generar un objeto donde se guardan los datos. Este objeto puede tener cualquier nombre, en este caso lo llamaremos simplemente “datos”.\nRutas: ¿Cómo identifico la ruta hacia mi archivo? Dos maneras:\n Botón derecho sobre el archivo -\u0026gt; propiedades, ahí aparece la ruta completa. Copiar y pegar donde corresponde en el archivo de R, no olvidar agregar al final el nombre completo del archivo.  Más fácil: mouse sobre archivo, boton derecho, copiar (o ctrl+c); luego, en el archivo de R, en el lugar que corresponde dar la ruta pegar (o ctrl+v)    Verificación y descriptivos Verificamos si los datos fueron correctamente cargados:\nView(datos) Tenemos entonces tres columnas:}\n id: número único que identifica a cada sujeto\n juegos_x: número de veces que ha jugado previamente\n puntos_y: numero de puntos que obtuvo en el juego actual\n  Generamos una tabla de descriptivos básicos con lo aprendido en la práctica de descripción de datos:\nY para publicar, usando la librería stargazer\nstargazer(datos, type = \u0026quot;text\u0026quot;) ## ## ====================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## ------------------------------------------------------ ## id 23 12.000 6.782 1 6.5 17.5 23 ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## ------------------------------------------------------ En la tabla vemos los estadísticos básicos de las variables juegos y puntos, y además aparece la variable id, que es el identificador y por lo tanto no tiene sentido que salga en la tabla. Para corregir, seleccionamos las variables de interés de datos con el operador pipa %\u0026gt;% operador pipa %\u0026gt;%. Este operador permite unir distintas funciones en una misma línea de código, y es muy utilizado por librerías de manejo de datos como dplyr. Por ejemplo, ahora la instrucción es “de la base de datos datos” %\u0026gt;% “selecciona solo las columnas juegos y puntos”:\nstargazer(datos %\u0026gt;%select(juegos_x,puntos_y) , type = \u0026quot;text\u0026quot;) ## ## ===================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## ----------------------------------------------------- ## juegos_x 23 3.000 1.758 0 2 4 6 ## puntos_y 23 4.000 1.382 2 3 5 6 ## -----------------------------------------------------  Experiencia en juegos y puntuación La pregunta que nos hacemos para este ejercicio de demostración es: ¿tiene relación la experiencia previa (juegos jugados previamente) con el desempeño actual (puntos obtenidos)?\nVeamos un gráfico de nube de puntos / scatter de ambas variables. Para eso, primero cargamos la librería ggplotde R. Recordar que hay que instalarla primero si es que no se ha hecho previamente con install.packages(\"ggplot\")ggplot.\ng=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() g Primero, sobre librerías y visualización: lo que hicimos fue crear un objeto gráfico scatterplot g con la librería ggplot..\nEn términos de correlación se observa una posible asociación positiva, que podemos corroborar con la función cor:\ncor(datos$juegos_x,datos$puntos_y) ## [1] 0.636209 Tenemos una correlación positiva (dirección de la relación) y de un tamaño de efecto grande (magnitud de la relación), para ciencias sociales. Es decir, existe una asociación positiva entre ambas variables: a medida que aumenta la experiencia en juegos, aumentan también los puntos obtenidos en el partido de taca taca. Ahora bien, ¿cómo se relaciona más específcamente la experiencia en juegos con los puntos obtenidos posteriormente?\n Medias condicionales Antes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nComo sabemos el promedio de Y (puntos) es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Como lo conocemos, si el sujeto nos dice que ha jugado antes 6 veces, dada la información que conocemos probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y:\ng2=ggplot(datos, aes(x=juegos_x, y=puntos_y)) + geom_point() + geom_smooth(method=lm, se=FALSE) g2  Residuos En el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n Para realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\n De la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n   Modelo de regresión y cálculo de parámetros El nombre regresión hace alusión a investigaciones sobre estaturas de padres e hij_s en el S.XIX. La estatura de hij_s de padres muy altos es en promedio menor, y si sus padres son baj_s, es mayor (en comparación con sus padres). Este fenómeno se conoce como “regresión hacia el promedio” \nEl modelo de regresión se representa con una ecuación de la recta, o recta de regresión. Esta recta representa los valores predichos para Y según los distintos valores de X:\n\\[\\widehat{Y}=b_{0} +b_{1}X \\]\nDonde\n \\(\\widehat{Y}\\) es el valor estimado/predicho de \\(Y\\) \\(b_{0}\\) es el intercepto de la recta (el valor de Y cuando X es 0) \\(b_{1}\\) es el coeficiente de regresión, que nos dice cuánto aumenta Y por cada punto que aumenta X (pendiente)   Cálculo de los parámetros del modelo de regresión \\(b_{1}\\), o comunmente llamado “beta de regresión” se obtiene de la siguiente manera:\n\\[b_{1}=\\frac{Cov(XY)}{VarX}\\] En términos más suntantivos se puede entender como qué parte de la covariación que hay entre X e Y se relaciona con (la varianza de) X. Especificando la fórmula:\n\\[b_{1}=\\frac{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {n-1}}{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})} {n-1}}\\] Y simplificando\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}\\]\nComo sabemos, la base para todos estos cálculos es el valor de cada variable menos su promedio. Vamos a crear un vector en nuestra base de datos difx=\\(x-\\bar{x}\\) y dify=\\(y-\\bar{y}\\)\ndatos$difx=datos$juegos_x-mean(datos$juegos_x) datos$dify=datos$puntos_y-mean(datos$puntos_y) Y ahora con esto podemos obtener la diferencia de productos cruzados dif_cru=\\((x-\\bar{x})*(y-\\bar{y})\\), así como la diferencia de X de su promedio al cuadrado SSx=\\((x-\\bar{x})^2\\)\ndatos$difcru=datos$difx*datos$dify datos$difx2=datos$difx^2 datos ## id juegos_x puntos_y difx dify difcru difx2 ## 1 1 0 2 -3 -2 6 9 ## 2 2 0 3 -3 -1 3 9 ## 3 3 1 2 -2 -2 4 4 ## 4 4 1 3 -2 -1 2 4 ## 5 5 1 4 -2 0 0 4 ## 6 6 2 2 -1 -2 2 1 ## 7 7 2 3 -1 -1 1 1 ## 8 8 2 4 -1 0 0 1 ## 9 9 2 5 -1 1 -1 1 ## 10 10 3 2 0 -2 0 0 ## 11 11 3 3 0 -1 0 0 ## 12 12 3 4 0 0 0 0 ## 13 13 3 5 0 1 0 0 ## 14 14 3 6 0 2 0 0 ## 15 15 4 3 1 -1 -1 1 ## 16 16 4 4 1 0 0 1 ## 17 17 4 5 1 1 1 1 ## 18 18 4 6 1 2 2 1 ## 19 19 5 4 2 0 0 4 ## 20 20 5 5 2 1 2 4 ## 21 21 5 6 2 2 4 4 ## 22 22 6 5 3 1 3 9 ## 23 23 6 6 3 2 6 9 Y con esto podemos obtener la suma de productos cruzados y la suma de cuadrados de X\nsum(datos$difcru) ## [1] 34 sum(datos$difx2) ## [1] 68 Reemplazando en la fórmula\n\\[b_{1}=\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {\\sum_{i=1}^{n}(x_i - \\bar{x})(x_i - \\bar{x})}=\\frac{34}{68}=0.5\\]\nY con esto podemos obtener el valor de \\(b_{0}\\)\n\\[b_{0}=\\bar{Y}-b_{1}\\bar{X}\\] \\[b_{0}=4-(3 * 0.5)=2.5\\]\nCompletando la ecuación:\n\\[\\bar{Y}=2.5+0.5X\\]\nEsto nos permite estimar el valor de \\(Y\\) (o su media condicional) basado en el puntaje \\(X\\). Por ejemplo, cuál es el valor estimado de \\(Y\\) dado \\(X=5\\)?\n  Estimación del modelo de regresión simple en R La función para estimar regresión en R es lm (linear model). Su forma general es:\nobjeto=lm(dependiente ~ independiente, data=datos) Donde\n objeto: el nombre (cualquiera) que le damos al objeto donde se guardan los resultados de la estimación dependiente / independiente: los nombres de las variables en los datos data = el nombre del objeto de nuestros datos en R  Ejemplo con los datos de taca taca:\nreg1 \u0026lt;-lm(puntos_y ~juegos_x, data = datos) Con esta operación ya estimamos nuestra primera regresión simple. Para ver la estimación de los parámetros principales (intercepto y pendiente) simplemente ejecutamos el nombre del objeto:\nreg1 ## ## Call: ## lm(formula = puntos_y ~ juegos_x, data = datos) ## ## Coefficients: ## (Intercept) juegos_x ## 2.5 0.5 Y obtenemos los valores que calculamos previamente.\nPodemos tener un output en un formato más apropiado utilizando la librería stargazer\nstargazer(reg1, type = \u0026quot;text\u0026quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## puntos_y ## ----------------------------------------------- ## juegos_x 0.500*** ## (0.132) ## ## Constant 2.500*** ## (0.458) ## ## ----------------------------------------------- ## Observations 23 ## R2 0.405 ## Adjusted R2 0.376 ## Residual Std. Error 1.091 (df = 21) ## F Statistic 14.280*** (df = 1; 21) ## =============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 Vemos que en la tabla aparecen una serie de elementos adicionales, además de \\(b_{1}\\) (juegos) y el intercepto o constante (“Constant”). Esto será tema de la siguiente sesión.\n Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí\n Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Foro práctica 3  ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615831292,"objectID":"0c86205acf7811fbfe8648206a8418ff","permalink":"/assignment/03-code/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/assignment/03-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de la clase   Documento presentación   Video de la clase \n   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616426360,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"/class/01-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":"  Índice  Documento presentación Video de la clase   Documento presentación   Video de la clase \n   ","tags":null,"title":"Presentación del curso","type":"docs"},{"authors":null,"categories":null,"content":"  Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase    Lecturas  Moore: 2. Análisis de relaciones (97-131)   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"/class/03-class/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":"  Índice  Documento presentación Video de clase Lecturas   Documento presentación Para ver en pantalla completa click aquí. Para guardar/imprimir (en modo pantalla completa): botón derecho, imprimir/guardar como pdf. \n  Video de clase    Lecturas  Moore: 2. Análisis de relaciones (97-131)   ","tags":null,"title":"Regresión simple 1","type":"docs"},{"authors":null,"categories":null,"content":"    pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { background-color: #f8f8f8; } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ef2929; } /* Alert */ code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #c4a000; } /* Attribute */ code span.bn { color: #0000cf; } /* BaseN */ code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4e9a06; } /* Char */ code span.cn { color: #000000; } /* Constant */ code span.co { color: #8f5902; font-style: italic; } /* Comment */ code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */ code span.dt { color: #204a87; } /* DataType */ code span.dv { color: #0000cf; } /* DecVal */ code span.er { color: #a40000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #0000cf; } /* Float */ code span.fu { color: #000000; } /* Function */ code span.im { } /* Import */ code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #204a87; font-weight: bold; } /* Keyword */ code span.op { color: #ce5c00; font-weight: bold; } /* Operator */ code span.ot { color: #8f5902; } /* Other */ code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */ code span.sc { color: #000000; } /* SpecialChar */ code span.ss { color: #4e9a06; } /* SpecialString */ code span.st { color: #4e9a06; } /* String */ code span.va { color: #000000; } /* Variable */ code span.vs { color: #4e9a06; } /* VerbatimString */ code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */  Índice  Presentación  Objetivo de la práctica Antecedentes de los datos a utilizar  Preparación de datos ELSOC 2016  1. Librerías principales (de R) a utilizar en el análisis 2. Cargar base de datos 3. Selección de variables a utilizar 4. Procesamiento de variables  4.1 Percepción de meritocracia 4.3. Estatus subjetivo 4.4. Sexo 4.5 Edad  5. Generación de base de datos procesada para el análisis  Archivo de código Reporte de progreso Foro    addClassKlippyTo(\"pre.r, pre.markdown\"); addKlippy('right', 'bottom', 'auto', '1', 'Copy code', 'Copied!');  Presentación Objetivo de la práctica El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n Preparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\n Análisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n  Los procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema: Tanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada en un archivo de código. Los detalles de este tipo de archivos se pueden revisar aquí. Archivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File \u0026gt; New File \u0026gt; R Script (o ctrl+shift+N), y para grabarlo File \u0026gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento Librerías: cargar librerías a utilizar Datos: carga de datos Selección de variables a utilizar Procesamiento de variables: en este punto, por cada variable se realiza lo siguiente: Descriptivo básico Recodificación: (datos perdidos y valores (en caso de ser necesario) Etiquetamiento: de variable y valores (en caso de ser necesario) Otros ajustes  Generación de base de datos preparada para el análisis.  Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de meritocracia y estatus (objetivo y subjetivo) utilizando los datos de la encuesta ELSOC .\n  Antecedentes de los datos a utilizar El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar longitudinalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades. Para ello, junto con variables de meritocracia, consideraremos también variables de estatus (educación y estatus subjetivo), y variables de caracterización sociodemográfica (sexo y edad).\n  Preparación de datos ELSOC 2016 1. Librerías principales (de R) a utilizar en el análisis Como sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\ninstall.packages(\u0026quot;pacman\u0026quot;) Y en adelante, las librerías se cargan así pacman::p_load(libreria1,libreria2,libreriaX) :\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer) Para esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n dplyr: ajuste general de datos sjmisc: descripción y exploración de base de datos car: principalmente la función recode para recodificar/agrupar valores de variable stargazer: para tabla descriptiva   2. Cargar base de datos Ajustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\nrm(list=ls()) # borrar todos los objetos en el espacio de trabajo options(scipen=999) # valores sin notación científica La función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: ELSOC_W01_v3.10.RData.\n#cargamos la base de datos desde internet load(url(\u0026quot;https://multivariada.netlify.com/assignment/data/original/ELSOC_W01_v3.10.RData\u0026quot;)) La base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 2927 casos y 383 variables).\ndim(elsoc_2016) # dimension de la base ## [1] 2927 383 Y si se quiere revisar en formato de planilla de datos:\nView(elsoc_2016)  3. Selección de variables a utilizar Este paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto esfuerzo:  find_var(data = elsoc_2016,\u0026quot;esfuerzo\u0026quot;) ## col.nr var.name ## 1 158 c18_09 ## var.label ## 1 Grado de acuerdo: Las personas son recompensadas por sus esfuerzos Nos informa que esta variable es la c18_09.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_elsoc, donde “proc” hace referencia a base procesada:\nproc_elsoc \u0026lt;-elsoc_2016 %\u0026gt;%select(c18_09, # percepción meritocracia esfuerzo  c18_10, # percepción meritocracia talento  d01_01, # estatus social subjetivo  m01, # nivel educacional  m0_sexo,# sexo  m0_edad)# edad  # Comprobar names(proc_elsoc) ## [1] \u0026quot;c18_09\u0026quot; \u0026quot;c18_10\u0026quot; \u0026quot;d01_01\u0026quot; \u0026quot;m01\u0026quot; \u0026quot;m0_sexo\u0026quot; \u0026quot;m0_edad\u0026quot; Mediante el comando get_label obtenemos el atributo label de las variables.\nsjlabelled::get_label(proc_elsoc) ## c18_09 ## \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; ## c18_10 ## \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; ## d01_01 ## \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; ## m01 ## \u0026quot;Nivel educacional\u0026quot; ## m0_sexo ## \u0026quot;Sexo del entrevistado\u0026quot; ## m0_edad ## \u0026quot;Edad del entrevistado\u0026quot; Podemos ver que son muy largas, por lo tanto, es necesario cambiarlas por etiquetas más cortas.\n 4. Procesamiento de variables Para el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\nDescriptivo general Recodificación: de casos perdidos y otros valores (en caso necesario) Etiquetado: cambio de nombres de variables y valores (en caso necesario) Otros ajustes  Y se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n4.1 Percepción de meritocracia En ELSOC, las variables que permiten medir la percepción de las personas con respecto al funcionamiento de la meritocracia en Chile son las siguientes:\n [c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo) [c18_10]: “Grado de acuerdo: Las personas son recompensadas por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)  a. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\nfrq(proc_elsoc$c18_09) ## ## Grado de acuerdo: Las personas son recompensadas por sus esfuerzos (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=-3.06 sd=71.66 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 4 0.14 0.14 0.14 ## -888 No Sabe (no leer) 14 0.48 0.48 0.61 ## 1 Totalmente en desacuerdo 357 12.20 12.20 12.81 ## 2 En desacuerdo 1331 45.47 45.47 58.28 ## 3 Ni de acuerdo ni en desacuerdo 497 16.98 16.98 75.26 ## 4 De acuerdo 646 22.07 22.07 97.34 ## 5 Totalmente de acuerdo 78 2.66 2.66 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA frq(proc_elsoc$c18_10) ## ## Grado de acuerdo: Las personas son recompensada por su inteligencia (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=-3.42 sd=74.36 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 2 0.07 0.07 0.07 ## -888 No Sabe (no leer) 18 0.61 0.61 0.68 ## 1 Totalmente en desacuerdo 288 9.84 9.84 10.52 ## 2 En desacuerdo 1163 39.73 39.73 50.26 ## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.10 69.35 ## 4 De acuerdo 814 27.81 27.81 97.16 ## 5 Totalmente de acuerdo 83 2.84 2.84 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA En ambas variables vemos valores asociados a la opción “No responde” (-999) y “No sabe” (-888), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en orden, así que en la recodificiación solo nos haremos cargo de los casos perdidos.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\nproc_elsoc$c18_09 \u0026lt;-recode(proc_elsoc$c18_09, \u0026quot;c(-888,-999)=NA\u0026quot;) proc_elsoc$c18_10 \u0026lt;-recode(proc_elsoc$c18_10, \u0026quot;c(-888,-999)=NA\u0026quot;) c - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\nproc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;mesfuerzo\u0026quot;=c18_09, # meritocracia esfuerzo  \u0026quot;mtalento\u0026quot; =c18_10) # meritocracia talento Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$mesfuerzo) ## [1] \u0026quot;Grado de acuerdo: Las personas son recompensadas por sus esfuerzos\u0026quot; proc_elsoc$mesfuerzo \u0026lt;-set_label(x = proc_elsoc$mesfuerzo,label = \u0026quot;Recompensa: esfuerzo\u0026quot;)  get_label(proc_elsoc$mtalento) ## [1] \u0026quot;Grado de acuerdo: Las personas son recompensada por su inteligencia\u0026quot; proc_elsoc$mtalento \u0026lt;-set_label(x = proc_elsoc$mtalento, label = \u0026quot;Recompensa: talento\u0026quot;) d. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los dos items de meritocracia.\nproc_elsoc$pmerit \u0026lt;-(proc_elsoc$mesfuerzo+proc_elsoc$mtalento)/2 summary(proc_elsoc$pmerit) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 2.000 2.500 2.654 3.500 5.000 29 get_label(proc_elsoc$pmerit) ## [1] \u0026quot;Recompensa: esfuerzo\u0026quot; Vemos que todavía tiene la etiqueta de la variable “Recompensa: esfuerzo”\nproc_elsoc$pmerit \u0026lt;-set_label(x = proc_elsoc$pmerit, label = \u0026quot;Meritocracia promedio\u0026quot;) Revisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\nfrq(proc_elsoc$mesfuerzo) ## ## Recompensa: esfuerzo (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2909 mean=2.57 sd=1.05 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1 Totalmente en desacuerdo 357 12.20 12.27 12.27 ## 2 En desacuerdo 1331 45.47 45.75 58.03 ## 3 Ni de acuerdo ni en desacuerdo 497 16.98 17.08 75.11 ## 4 De acuerdo 646 22.07 22.21 97.32 ## 5 Totalmente de acuerdo 78 2.66 2.68 100.00 ## NA \u0026lt;NA\u0026gt; 18 0.61 NA NA frq(proc_elsoc$mtalento) ## ## Recompensa: talento (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2907 mean=2.74 sd=1.06 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1 Totalmente en desacuerdo 288 9.84 9.91 9.91 ## 2 En desacuerdo 1163 39.73 40.01 49.91 ## 3 Ni de acuerdo ni en desacuerdo 559 19.10 19.23 69.14 ## 4 De acuerdo 814 27.81 28.00 97.14 ## 5 Totalmente de acuerdo 83 2.84 2.86 100.00 ## NA \u0026lt;NA\u0026gt; 20 0.68 NA NA frq(proc_elsoc$pmerit) ## ## Meritocracia promedio (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2898 mean=2.65 sd=0.97 ## ## val label frq raw.prc valid.prc cum.prc ## -999.0 No Responde (no leer) 0 0.00 0.00 0.00 ## -888.0 No Sabe (no leer) 0 0.00 0.00 0.00 ## 1.0 Totalmente en desacuerdo 243 8.30 8.39 8.39 ## 1.5 1.5 79 2.70 2.73 11.11 ## 2.0 En desacuerdo 1041 35.57 35.92 47.03 ## 2.5 2.5 222 7.58 7.66 54.69 ## 3.0 Ni de acuerdo ni en desacuerdo 536 18.31 18.50 73.19 ## 3.5 3.5 169 5.77 5.83 79.02 ## 4.0 De acuerdo 528 18.04 18.22 97.24 ## 4.5 4.5 38 1.30 1.31 98.55 ## 5.0 Totalmente de acuerdo 42 1.43 1.45 100.00 ## NA \u0026lt;NA\u0026gt; 29 0.99 NA NA 4.2. Educación  [m01] = ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente).  a. Descriptivo\nfrq(proc_elsoc$m01) ## ## Nivel educacional (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=4.57 sd=26.34 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 2 0.07 0.07 0.07 ## -888 No Sabe (no leer) 0 0.00 0.00 0.07 ## 1 Sin estudios 37 1.26 1.26 1.33 ## 2 Educacion Basica o Preparatoria incompleta 322 11.00 11.00 12.33 ## 3 Educacion Basica o Preparatoria completa 297 10.15 10.15 22.48 ## 4 Educacion Media o Humanidades incompleta 394 13.46 13.46 35.94 ## 5 Educacion Media o Humanidades completa 857 29.28 29.28 65.22 ## 6 Tecnica Superior incompleta 102 3.48 3.48 68.71 ## 7 Tecnica Superior completa 381 13.02 13.02 81.72 ## 8 Universitaria incompleta 186 6.35 6.35 88.08 ## 9 Universitaria completa 303 10.35 10.35 98.43 ## 10 Estudios de posgrado (magister o doctorado) 46 1.57 1.57 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación\n Datos perdidos:  proc_elsoc$m01 \u0026lt;-recode(proc_elsoc$m01, \u0026quot;c(-888,-999)=NA\u0026quot;)  Valores  Recodificación de acuerdo a las categorías CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1 2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1 3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2 4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3 5. Educacion Media o Humanidades completa = [CINE 3 ] = 3 6. Tecnico Superior incompleta = [CINE 5 ] = 4 7. Tecnico Superior completa = [CINE 5 ] = 4 8. Universitaria incompleta = [CINE 6 ] = 5 9. Universitaria completa = [CINE 6 ] = 6 10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6 # recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car proc_elsoc$m01 \u0026lt;-car::recode(proc_elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) Comprobar con un nuevo descriptivo:\nfrq(proc_elsoc$m01) ## ## Nivel educacional (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2925 mean=3.18 sd=1.21 ## ## val label frq raw.prc valid.prc ## -999 No Responde (no leer) 0 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 ## 1 Sin estudios 359 12.27 12.27 ## 2 Educacion Basica o Preparatoria incompleta 297 10.15 10.15 ## 3 Educacion Basica o Preparatoria completa 1251 42.74 42.77 ## 4 Educacion Media o Humanidades incompleta 483 16.50 16.51 ## 5 Educacion Media o Humanidades completa 535 18.28 18.29 ## 6 Tecnica Superior incompleta 0 0.00 0.00 ## 7 Tecnica Superior completa 0 0.00 0.00 ## 8 Universitaria incompleta 0 0.00 0.00 ## 9 Universitaria completa 0 0.00 0.00 ## 10 Estudios de posgrado (magister o doctorado) 0 0.00 0.00 ## NA \u0026lt;NA\u0026gt; 2 0.07 NA ## cum.prc ## 0.00 ## 0.00 ## 12.27 ## 22.43 ## 65.20 ## 81.71 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## 100.00 ## NA Se observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 5), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\nproc_elsoc$m01 \u0026lt;-set_labels(proc_elsoc$m01,  labels=c( \u0026quot;Primaria incompleta menos\u0026quot;=1,  \u0026quot;Primaria y secundaria baja\u0026quot;=2,  \u0026quot;Secundaria alta\u0026quot;=3,  \u0026quot;Terciaria ciclo corto\u0026quot;=4,  \u0026quot;Terciaria y Postgrado\u0026quot;=5)) Luego renombramos la variable con un nombre más sustantivo\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edcine\u0026quot;=m01) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edcine) ## [1] \u0026quot;Nivel educacional\u0026quot; proc_elsoc$edcine \u0026lt;-set_label(x = proc_elsoc$edcine,label = \u0026quot;Educación\u0026quot;)   4.3. Estatus subjetivo a. Descriptivo\n [d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)  frq(proc_elsoc$d01_01) summary(proc_elsoc$d01_01) ## ## Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=0.63 sd=57.67 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 1 0.03 0.03 0.03 ## -888 No Sabe (no leer) 11 0.38 0.38 0.41 ## 0 0 El nivel mas bajo 44 1.50 1.50 1.91 ## 1 1 84 2.87 2.87 4.78 ## 2 2 207 7.07 7.07 11.86 ## 3 3 439 15.00 15.00 26.85 ## 4 4 677 23.13 23.13 49.98 ## 5 5 975 33.31 33.31 83.29 ## 6 6 310 10.59 10.59 93.88 ## 7 7 116 3.96 3.96 97.85 ## 8 8 37 1.26 1.26 99.11 ## 9 9 4 0.14 0.14 99.25 ## 10 10 El nivel mas alto 22 0.75 0.75 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA ## ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -999.0000 3.0000 5.0000 0.6338 5.0000 10.0000 b. Recodificación\nproc_elsoc$d01_01 \u0026lt;-recode(proc_elsoc$d01_01, \u0026quot;c(-888,-999)=NA\u0026quot;) c. Etiquetado\n Cambio de nombre de variable a etiqueta más sustantiva ess (estatus social subjetivo)  proc_elsoc \u0026lt;-proc_elsoc %\u0026gt;%rename(\u0026quot;ess\u0026quot;=d01_01) # estatus social subjetivo Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$ess) ## [1] \u0026quot;Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena\u0026quot; proc_elsoc$ess \u0026lt;-set_label(x = proc_elsoc$ess,label = \u0026quot;Estatus Social Subjetivo\u0026quot;)  4.4. Sexo  [m0_sexo] = Indicar el sexo del entrevistado.  a. Descriptivo\nfrq(proc_elsoc$m0_sexo) ## ## Sexo del entrevistado (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=1.60 sd=0.49 ## ## val label frq raw.prc valid.prc cum.prc ## 1 Hombre 1163 39.73 39.73 39.73 ## 2 Mujer 1764 60.27 60.27 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\nproc_elsoc$m0_sexo \u0026lt;-car::recode(proc_elsoc$m0_sexo, \u0026quot;1=0;2=1\u0026quot;) c. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\nproc_elsoc$m0_sexo \u0026lt;-set_labels(proc_elsoc$m0_sexo,  labels=c( \u0026quot;Hombre\u0026quot;=0,  \u0026quot;Mujer\u0026quot;=1)) También el nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;sexo\u0026quot;=m0_sexo) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$sexo) ## [1] \u0026quot;Sexo del entrevistado\u0026quot; proc_elsoc$sexo \u0026lt;-set_label(x = proc_elsoc$sexo,label = \u0026quot;Sexo\u0026quot;) Revisar con un nuevo descriptivo:\nfrq(proc_elsoc$sexo) ## ## Sexo (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=0.60 sd=0.49 ## ## val label frq raw.prc valid.prc cum.prc ## 0 Hombre 1163 39.73 39.73 39.73 ## 1 Mujer 1764 60.27 60.27 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA  4.5 Edad  [m0_edad] = ¿Cuáles su edad? (años cumplidos).  a. Descriptivo\nfrq(proc_elsoc$m0_edad) ## ## Edad del entrevistado (x) \u0026lt;numeric\u0026gt; ## # total N=2927 valid N=2927 mean=46.09 sd=15.29 ## ## val label frq raw.prc valid.prc cum.prc ## -999 No Responde (no leer) 0 0.00 0.00 0.00 ## -888 No Sabe (no leer) 0 0.00 0.00 0.00 ## 18 18 19 0.65 0.65 0.65 ## 19 19 32 1.09 1.09 1.74 ## 20 20 26 0.89 0.89 2.63 ## 21 21 39 1.33 1.33 3.96 ## 22 22 49 1.67 1.67 5.64 ## 23 23 44 1.50 1.50 7.14 ## 24 24 51 1.74 1.74 8.88 ## 25 25 46 1.57 1.57 10.45 ## 26 26 44 1.50 1.50 11.96 ## 27 27 51 1.74 1.74 13.70 ## 28 28 58 1.98 1.98 15.68 ## 29 29 47 1.61 1.61 17.29 ## 30 30 66 2.25 2.25 19.54 ## 31 31 48 1.64 1.64 21.18 ## 32 32 64 2.19 2.19 23.37 ## 33 33 55 1.88 1.88 25.25 ## 34 34 55 1.88 1.88 27.13 ## 35 35 67 2.29 2.29 29.42 ## 36 36 70 2.39 2.39 31.81 ## 37 37 46 1.57 1.57 33.38 ## 38 38 57 1.95 1.95 35.33 ## 39 39 37 1.26 1.26 36.59 ## 40 40 57 1.95 1.95 38.54 ## 41 41 58 1.98 1.98 40.52 ## 42 42 67 2.29 2.29 42.81 ## 43 43 54 1.84 1.84 44.65 ## 44 44 45 1.54 1.54 46.19 ## 45 45 53 1.81 1.81 48.00 ## 46 46 77 2.63 2.63 50.63 ## 47 47 56 1.91 1.91 52.55 ## 48 48 72 2.46 2.46 55.01 ## 49 49 53 1.81 1.81 56.82 ## 50 50 69 2.36 2.36 59.17 ## 51 51 55 1.88 1.88 61.05 ## 52 52 69 2.36 2.36 63.41 ## 53 53 57 1.95 1.95 65.36 ## 54 54 76 2.60 2.60 67.95 ## 55 55 72 2.46 2.46 70.41 ## 56 56 76 2.60 2.60 73.01 ## 57 57 53 1.81 1.81 74.82 ## 58 58 57 1.95 1.95 76.77 ## 59 59 44 1.50 1.50 78.27 ## 60 60 57 1.95 1.95 80.22 ## 61 61 33 1.13 1.13 81.35 ## 62 62 33 1.13 1.13 82.47 ## 63 63 49 1.67 1.67 84.15 ## 64 64 39 1.33 1.33 85.48 ## 65 65 60 2.05 2.05 87.53 ## 66 66 39 1.33 1.33 88.86 ## 67 67 39 1.33 1.33 90.19 ## 68 68 35 1.20 1.20 91.39 ## 69 69 32 1.09 1.09 92.48 ## 70 70 37 1.26 1.26 93.75 ## 71 71 29 0.99 0.99 94.74 ## 72 72 28 0.96 0.96 95.70 ## 73 73 42 1.43 1.43 97.13 ## 74 74 39 1.33 1.33 98.46 ## 75 75 37 1.26 1.26 99.73 ## 77 77 1 0.03 0.03 99.76 ## 78 78 3 0.10 0.10 99.86 ## 80 80 1 0.03 0.03 99.90 ## 81 81 1 0.03 0.03 99.93 ## 88 88 2 0.07 0.07 100.00 ## NA \u0026lt;NA\u0026gt; 0 0.00 NA NA b. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio del nombre de la variable a algo más simple:\nproc_elsoc \u0026lt;-rename(proc_elsoc,\u0026quot;edad\u0026quot;=m0_edad) Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.\nget_label(proc_elsoc$edad) ## [1] \u0026quot;Edad del entrevistado\u0026quot; proc_elsoc$edad \u0026lt;-set_label(x = proc_elsoc$edad,label = \u0026quot;Edad\u0026quot;)   5. Generación de base de datos procesada para el análisis Antes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nstargazer(proc_elsoc, type=\u0026quot;text\u0026quot;) ## ## ============================================================== ## Statistic N Mean St. Dev. Min Pctl(25) Pctl(75) Max ## -------------------------------------------------------------- ## mesfuerzo 2,909 2.573 1.047 1.000 2.000 3.000 5.000 ## mtalento 2,907 2.739 1.060 1.000 2.000 4.000 5.000 ## ess 2,915 4.330 1.567 0.000 3.000 5.000 10.000 ## edcine 2,925 3.184 1.207 1.000 3.000 4.000 5.000 ## sexo 2,927 0.603 0.489 0 0 1 1 ## edad 2,927 46.091 15.287 18 33 58 88 ## pmerit 2,898 2.654 0.969 1.000 2.000 3.500 5.000 ## --------------------------------------------------------------  Guardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como \"C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar  save(proc_elsoc,file = \u0026quot;[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\u0026quot;) En este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\nsave(proc_elsoc,file = \u0026quot;content/assignment/data/proc/ELSOC_ess_merit2016.RData\u0026quot;)   Archivo de código El archivo de código R de esta práctica se puede descargar aquí\n Reporte de progreso Completar el reporte de progreso correspondiente a esta práctica aquí. El plazo para contestarlo es antes que se publique la siguiente práctica el día viernes después de clases.\n Foro  ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616091116,"objectID":"9f719bf107561ff88768da3264c94b73","permalink":"/assignment/01-code/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/assignment/01-code/","section":"assignment","summary":"pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.","tags":null,"title":"Práctica 1. Preparación de datos en R","type":"docs"},{"authors":null,"categories":null,"content":" Presentación El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevante para el estudio de la Percepción de Meritocracia, entendida como el grado en que los individuos consideran que su sociedad cumple con los principios de una meritocracia, es decir, que funciona como un sistema que asigna recompensas en función del esfuerzo y las habilidades.\n Preparacion de datos con ELSOC 2016 Librerías y configuración library(dplyr) ## ## Attaching package: \u0026#39;dplyr\u0026#39; ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## filter, lag ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## intersect, setdiff, setequal, union rm(list=ls()) # borrar todos los objetos en el enviorment options(scipen=999) #sin notacion cientifica Cargar base de datos  Ejemplo de ruta, debe remplazarla por la de su computador.  setwd(\u0026quot;C:/usuario/usted/multivariada/materiales/01material\u0026quot;)  # buscammos la sub carpeta ... datos/original/ELSOC_W01_v3.10.RData load(\u0026quot;data/original/ELSOC_W01_v3.10.RData\u0026quot;) elsoc \u0026lt;- elsoc_2016; remove(elsoc_2016) # load(\u0026quot;link/ELSOC_W01_v3.10.RData\u0026quot;)  Datos perdidos  En ELSOC todos los valores -888 y -999 corresponden a valores para las categorias “No sabe” y “No responde”, respectivamente. Decidimos dejarlas como valores perdidos (NA)  for (i in 1:ncol(elsoc)) { elsoc[,i][elsoc[,i] == c(-888)] \u0026lt;- NA #Missing elsoc[,i][elsoc[,i] == c(-999)] \u0026lt;- NA #Missing }   Recodificacion Variables percepcion de meritocracia  [c18_09]: “Grado de acuerdo: Las personas son recompensadas por sus esfuerzos” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo) [c18_10]: “Grado de acuerdo: Las personas son recompensada por su inteligencia” (1 = Totalmente en desacuerdo; 5 = Totalmente de acuerdo)  elsoc$c18_09 \u0026lt;- as.numeric(elsoc$c18_09) elsoc$c18_10 \u0026lt;- as.numeric(elsoc$c18_10) # Variables meritocracia promedio ----------------------------------------- elsoc \u0026lt;- rename(elsoc,meffort=c18_09) # cambio de nombre de la variable c18_09 a uno mas sustantivo elsoc \u0026lt;- rename(elsoc,mtalent=c18_10) # cambio de nombre de la variable c18_10 a uno mas sustantivo # creamos un indice promedio de percepcion de meritocracia usando ambas preguntas elsoc$merit \u0026lt;- (elsoc$meffort+elsoc$mtalent)/2 # re escalamos la variable de 1-5 a una de 0 a 100 (para facilitar interpretacion) elsoc$merit \u0026lt;- (elsoc$merit-min(elsoc$merit,na.rm=T))/(max(elsoc$merit,na.rm=T)-min(elsoc$merit,na.rm=T))*100  Recodificacion variable Estatus subjetivo  [d01_01]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)  elsoc$ess \u0026lt;- as.numeric(elsoc$d01_01) # Estatus Social Subjetivo table(elsoc$ess) summary(elsoc$ess) ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 44 84 207 439 677 975 310 116 37 4 22 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0.00 3.00 5.00 4.33 5.00 10.00 12  Recodificacion variables Estatus objetivo Ingresos del hogar summary(elsoc$m29) # ingresos total ; NA == 587 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 0 267500 420000 2477852 700000 4000000000 587 summary(elsoc$m30) # ingresos tramos  ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 1.000 3.000 6.000 7.415 11.000 20.000 2479 summary(elsoc$nhogar1) # tamannio del hogar ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 3.077 4.000 14.000 elsoc$m29[elsoc$m29==0] \u0026lt;- NA # Remplazar NA por media de categorias Ingreso -------------------------------# elsoc$mean_tramos \u0026lt;- NA # creamos una variable vacia # remplazamos ... elsoc$mean_tramos[elsoc$m30==1] \u0026lt;-110000 elsoc$mean_tramos[elsoc$m30==2] \u0026lt;-250000.5 elsoc$mean_tramos[elsoc$m30==3] \u0026lt;-305000.5 elsoc$mean_tramos[elsoc$m30==4] \u0026lt;-355000.5 elsoc$mean_tramos[elsoc$m30==5] \u0026lt;-400000.5 elsoc$mean_tramos[elsoc$m30==6] \u0026lt;-445000.5 elsoc$mean_tramos[elsoc$m30==7] \u0026lt;-490000.5 elsoc$mean_tramos[elsoc$m30==8] \u0026lt;-535000.5 elsoc$mean_tramos[elsoc$m30==9] \u0026lt;-585000.5 elsoc$mean_tramos[elsoc$m30==10]\u0026lt;-640000.5 elsoc$mean_tramos[elsoc$m30==11]\u0026lt;-700000.5 elsoc$mean_tramos[elsoc$m30==12]\u0026lt;-765000.5 elsoc$mean_tramos[elsoc$m30==13]\u0026lt;-845000.5 elsoc$mean_tramos[elsoc$m30==14]\u0026lt;-935000.5 elsoc$mean_tramos[elsoc$m30==15]\u0026lt;-1040000.5 elsoc$mean_tramos[elsoc$m30==16]\u0026lt;-1180000.5 elsoc$mean_tramos[elsoc$m30==17]\u0026lt;-1375000.5 elsoc$mean_tramos[elsoc$m30==18]\u0026lt;-1670000.5 elsoc$mean_tramos[elsoc$m30==19]\u0026lt;-2275000.5 elsoc$mean_tramos[elsoc$m30==20]\u0026lt;-3726106 table(elsoc$mean_tramos) # chequeamos ## ## 110000 250000.5 305000.5 355000.5 400000.5 445000.5 490000.5 535000.5 ## 49 42 36 35 33 33 38 21 ## 585000.5 640000.5 700000.5 765000.5 845000.5 935000.5 1040000.5 1180000.5 ## 26 16 18 15 11 14 19 13 ## 1375000.5 1670000.5 2275000.5 3726106 ## 4 10 8 7 elsoc$m29 \u0026lt;- ifelse(test = (is.na(elsoc$m29)),#¿es el valor un NA? yes = elsoc$mean_tramos, #Si es verdadero, remplazar por el valor de mean_tramos no = elsoc$m29)# Si es falso, remplazar por el valor del m29 summary(elsoc$m29) # NA = 147 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 20000 280000 445000 2182986 700000 4000000000 147 # cambiamos el nombre de las variables inghogar = m29; nhogar=nhogar1 elsoc \u0026lt;- rename(elsoc, inghogar=m29, nhogar=nhogar1) # ingreso neto = ingreso del hogar / numero de personas en el hogar elsoc$ingneto \u0026lt;- as.numeric(elsoc$inghogar/elsoc$nhogar) # logaritmo natural del ingreso neto (para normalizar la distribucion sesgada del ingreso) elsoc$lningneto \u0026lt;- log(elsoc$ingneto) summary(elsoc$ingneto) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 7500 95000 150000 1028152 267500 2000000000 147 summary(elsoc$lningneto) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA\u0026#39;s ## 8.923 11.462 11.918 12.006 12.497 21.416 147 #---Deciles (ingreso per capita hogar)------------------------------------------------ elsoc \u0026lt;- elsoc %\u0026gt;% mutate(inc10h = ntile(inghogar, 10)) # Crear Deciles de ingreso elsoc$D10h \u0026lt;- factor(elsoc$inc10h, levels = c(1,2,3,4,5,6,7,8,9,10), labels = c(\u0026quot;D01\u0026quot;,\u0026quot;D02\u0026quot;,\u0026quot;D03\u0026quot;,\u0026quot;D04\u0026quot;,\u0026quot;D05\u0026quot;, \u0026quot;D06\u0026quot;,\u0026quot;D07\u0026quot;,\u0026quot;D08\u0026quot;,\u0026quot;D09\u0026quot;,\u0026quot;D10\u0026quot;));table(elsoc$D10h) ## ## D01 D02 D03 D04 D05 D06 D07 D08 D09 D10 ## 278 278 278 278 278 278 278 278 278 278  Educación table(elsoc$m01) # Educacion en ELSOC ## ## 1 2 3 4 5 6 7 8 9 10 ## 37 322 297 394 857 102 381 186 303 46 Recodificación CINE 2011 (UNESCO)\n1. Sin estudios = [CINE 0 ] = 1 2. Educacion Basica o Preparatoria incompleta = [CINE 0 ] = 1 3. Educacion Basica o Preparatoria completa = [CINE 1,2 ] = 2 4. Educacion Media o Humanidades incompleta = [CINE 3 ] = 3 5. Educacion Media o Humanidades completa = [CINE 3 ] = 3 6. Tecnico Superior incompleta = [CINE 5 ] = 4 7. Tecnico Superior completa = [CINE 5 ] = 4 8. Universitaria incompleta = [CINE 6 ] = 5 9. Universitaria completa = [CINE 6 ] = 6 10. Estudios de posgrado (magister o doctorado) = [CINE 7, 8] = 6 # recodificacion usando funcion \u0026#39;recode\u0026#39; de la libreria car elsoc$edcine \u0026lt;- car::recode(elsoc$m01, \u0026quot;c(1,2)=1; c(3)=2;c(4,5)=3;c(6,7)=4;c(8,9,10)=5\u0026quot;) round(prop.table(table(elsoc$edcine)), 3) ## ## 1 2 3 4 5 ## 0.123 0.102 0.428 0.165 0.183 elsoc$edcine \u0026lt;- factor(elsoc$edcine, levels = c(1,2,3,4,5), labels=c(\u0026quot;Primaria incompleta menos\u0026quot;, \u0026quot;Primaria y secundaria baja\u0026quot;, \u0026quot;Secundaria alta\u0026quot;, \u0026quot;Terciaria ciclo corto\u0026quot;, \u0026quot;Terciaria y Postgrado\u0026quot;)) table(elsoc$edcine) #chequeamos ## ## Primaria incompleta menos Primaria y secundaria baja ## 359 297 ## Secundaria alta Terciaria ciclo corto ## 1251 483 ## Terciaria y Postgrado ## 535   Variables control #---Sexo---- elsoc$sexo \u0026lt;- car::recode(elsoc$m0_sexo, \u0026quot;1=1;2=0\u0026quot;) elsoc$sexo \u0026lt;- factor(elsoc$sexo, levels = c(0,1), labels = c(\u0026quot;Hombre\u0026quot;,\u0026quot;Mujer\u0026quot;)) # Sexo #Hombre=0 #Mujer=1 #---Edad---- elsoc$edad \u0026lt;- as.numeric(elsoc$m0_edad) #Edad #---Posicion Politica---- # PREGUNTA: \u0026quot;Autoubicacion escala izquierda-derecha\u0026quot; # (0 = izquierda; 10 = Derecha; 11 = Independiente; 12 =Ninguno) elsoc$ppolcat \u0026lt;- car::recode(elsoc$c15, \u0026quot;c(0,1,2,3,4)=1;5=2;c(6,7,8,9,10)=3;11=4;12=5\u0026quot;) elsoc$ppolcat \u0026lt;- factor(elsoc$ppolcat, levels = c(1,2,3,4,5), labels = c(\u0026quot;Izquierda/Centro Izquierda\u0026quot;, \u0026quot;Centro\u0026quot;, \u0026quot;Derecha/Centro Derecha\u0026quot;, \u0026quot;Independiente\u0026quot;, \u0026quot;Ninguno\u0026quot;))   Mantener variables relevantes # selecccionamos las variables relevantes elsoc_16 \u0026lt;- elsoc %\u0026gt;% dplyr::select(merit,ess,edcine,lningneto,D10h, sexo, edad,ppolcat) # dejamos solamente los casos con informacion completa (listwise deletion) elsoc_16 \u0026lt;- na.omit(elsoc_16) names(elsoc_16) # comprobamos los nombres de variables ## [1] \u0026quot;merit\u0026quot; \u0026quot;ess\u0026quot; \u0026quot;edcine\u0026quot; \u0026quot;lningneto\u0026quot; \u0026quot;D10h\u0026quot; \u0026quot;sexo\u0026quot; ## [7] \u0026quot;edad\u0026quot; \u0026quot;ppolcat\u0026quot; head(elsoc_16) #chequear ## merit ess edcine lningneto D10h sexo edad ppolcat ## 1 75.0 5 Primaria incompleta menos 11.22524 D03 Hombre 64 Independiente ## 2 75.0 5 Secundaria alta 12.42922 D06 Hombre 60 Ninguno ## 3 50.0 3 Secundaria alta 11.31040 D06 Hombre 26 Ninguno ## 4 75.0 6 Terciaria y Postgrado 13.54763 D08 Mujer 51 Ninguno ## 5 62.5 4 Secundaria alta 13.10216 D06 Mujer 69 Ninguno ## 6 75.0 5 Secundaria alta 13.10216 D06 Mujer 62 Independiente # Guardar base de datos procesada --------------------------------------------------------------- save(elsoc_16,file = \u0026quot;data/proc/ELSOC_ess_merit2016.RData\u0026quot;)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585881306,"objectID":"96782a7dad874126bc6358fdb483b41e","permalink":"/assignment/01material/prep-datos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/01material/prep-datos/","section":"assignment","summary":"Presentación El Estudio Longitudinal Social de Chile (ELSOC) es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena.\nUno de los módulos de ELSOC es “Desigualdad y Legitimidad”. Este módulo busca estudiar las percepciones y atribuciones asociadas a las desigualdades sociales. Se ve motivado por el interés de comprender cómo las personas perciben, legitiman y reproducen las diferencias de ingresos, estatus y poder presentes en el Chile contemporáneo.","tags":null,"title":"Material 1. Procesamiento de datos en R","type":"assignment"},{"authors":null,"categories":null,"content":"  Los dos componentes centrales del curso son las sesiones de clases y las actividades prácticas.\n Las clases son sesiones online/sincrónicas donde se exponen y explican los contenidos programados. Se realizan los días Viernes 10:15-11:30\n Las prácticas consisten en tareas semanales relacionadas con los contenidos de la semana, que se basan en el desarrollo de una guía de trabajo. Se espera que estas prácticas sean desarrolladas de manera autónoma por cada alumno durante la semana siguiente a la presentación de los contenidos. Se realizan los días Jueves (Sección 1) y Viernes (Sección 2) 8:30-10:00.\n        Clases  Prácticas y evaluaciones  Lecturas y material adicional    Marzo      Viernes 19 1. Presentación e introducción Práctica 1: Preparación de datos Revisión: Jueves 25   Viernes 26 2. Bases/Repaso - Datos y variables - Preparación y descripción - Varianza y covarianza - Correlación (descriptiva) Práctica 2: Descripción de variables - Lizon (2006) Estadística y causalidad en sociología - Moore: 1.Comprensión de los datos (1-54)  Abril      Viernes 2 FERIADO Repaso bases \u0026amp; lecturas   Viernes 9 3. Regresión simple I (Clase sincrónica no obligatoria por semana mechona) Distribución condicional\nMínimos cuadrados y recta de regresión Práctica 3: Correlación y regresión - Salgado (2009) Construyendo explicaciones en sociología- Moore: 2. Análisis de relaciones (97-131)   Viernes 16 4. Regresión simple II Regresión vs correlación Residuos y ajuste general (R2) Presentación pauta de Trabajo del curso Practica 4: Residuos y ajuste - *Linares (2018) Sociología y teoría social analíticas, cap. 2: La explicación en ciencias sociales - Moore: Residuos (144-154)  Viernes 23 Semana preparación Informe 1 Informe 1: Regresión simple (individual) 20%, entrega Jueves 29 Ejemplo de informe aquí  Viernes 30 5. Regresión múltiple 1 - Introducción Práctica 5: Tabla de regresión múltiple - Esser 2010 Sociología de las Variables - Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)  Mayo      Viernes 7 Semana de receso    Viernes 14 6. Regresión múltiple 2 - Coeficientes de regresión parcial - Correlación parcial y semiparcial  Práctica 6: Parcialización y control estadístico - * Wooldridge (2010) Cap 3 (parcial): Análisis de regresión múltiple: estimación (68-80)  Viernes 21 Semana preparación informe 2 Informe 2: Regresión múltiple (grupal) 30%, entrega Jueves 3 - * Wooldridge (2010) Cap 19: Realización de un proyecto empírico (668-694)  Viernes 28 7. Regresión e inferencia - Conceptos y supuestos - Tabla ANOVA - Inferencia sobre coeficientes Práctica 7: Inferencia - Moore 7: Inferencia para medias (482-543)  Junio      Viernes 4 8. Regresión logística I - Probabilidades - Odds ratios Práctica 8: Probabilidades y Odds Camarero et al (2017) Regresión logística (1-29)   Viernes 11 Semana de Receso    Viernes 18 9. Regresión logística II - Estimación de parámetros - Inferencia - Predicción Práctica 9: Estimación logística - Camarero et al (2017) Regresión logística (30-52)  Viernes 25 10. Supuestos y chequeos de robustez - Relaciones no lineales -Transformaciones - Centrado Práctica 10: Transformación de variables y supuestos de regresión Preparación Informe 3 - Darlington \u0026amp; Hayes 2016 Cap16 Detecting and Managing Irregularities - Darlington \u0026amp; Hayes 2016 Cap12 Nonlinear relationships  Julio      Viernes 2 11. Repaso, pendientes y cierre de los contenidos  Entrega Informe 3: Regresión logística, predictores categóricos y supuestos (grupal) 50% Wooldridge cap 6 Temas adicionales  Lunes 12 - Examen final     ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616763664,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Los dos componentes centrales del curso son las sesiones de clases y las actividades prácticas.\n Las clases son sesiones online/sincrónicas donde se exponen y explican los contenidos programados. Se realizan los días Viernes 10:15-11:30\n Las prácticas consisten en tareas semanales relacionadas con los contenidos de la semana, que se basan en el desarrollo de una guía de trabajo. Se espera que estas prácticas sean desarrolladas de manera autónoma por cada alumno durante la semana siguiente a la presentación de los contenidos.","tags":null,"title":"Planificación","type":"page"},{"authors":null,"categories":null,"content":"   Concepto del curso (nuevo) Propósito general del curso Competencias a las que contribuye el curso  Sub-Competencias  Resultados de Aprendizaje Saberes / contenidos  UNIDAD 1: Introducción al modelamiento de datos sociales UNIDAD 2: Regresión Lineal Simple y Múltiple UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Metodología Evaluación (detalles en pestaña Trabajos) Requisitos de aprobación Bibliografía  Textos principales. MODELOS CIENTÍFICOS (Unidad 1) MODELOS DE REGRESIÓN LINEAL (Unidad 2) MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3) Links \u0026amp; otras recomendaciones  Software Plataformas de comunicación y discusión VARIOS Programación de sesiones   Concepto del curso (nuevo) A pesar de su nombre, este no es un curso de (mera) estadística. Es un curso que enseña algunas técnicas de análisis cuantitativo orientadas al contraste empírico de teoría sociológica, para lo cual se vale de técnicas estadísticas como la regresión múltiple. En este contexto, los métodos son considerados funcionales a preocupaciones sustantivas y relevantes del mundo social\n Además de las herramientas de análisis, el curso pone también énfasis en el reporte y comunicación de resultados. Los análisis de datos son siempre realizados en relación a otr_s, quienes tienen ser capaz de entender lo que se está presentando. Este aspecto se relaciona con tener en cuenta la relevancia y aporte del conocimiento científico en temas sociales.\n Un tercer énfasis transversal en el curso es la apertura del proceso de investigación. Para poder realizar investigación de manera eficiente y generativa es importante no “reinventar la rueda”, preocupándose de que nuestros análisis sean comprensibles para los demás (y para nosotr_s en el futuro). Por ello utilizamos programas de análisis de código abierto (como R) y promovemos que los códigos de análisis sean reproducibles.\n   Propósito general del curso Al finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico multivariado.\nSe espera que los estudiantes sean capaces de:\n identificar las principales técnicas de análisis estadístico multivariado utilizadas en la investigación sociológica\n depurar y preparar datos para la aplicación de distintas técnicas de análisis estadístico multivariado; corroborar las condiciones de aplicación de distintas técnicas de análisis estadístico multivariado\n utilizar software de análisis estadístico\n contrastar hipótesis de investigación\n elaborar reportes de resultados y conclusiones a partir de la aplicación de diferentes técnicas de análisis estadístico multivariado.\n  Complementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos.\n Competencias a las que contribuye el curso  Diseñar y desarrollar estrategias de investigación social.\n Comunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos.\n  Sub-Competencias  Diseñar y aplicar diversas técnicas de recolección y producción de información empírica, pertinentes al objeto de estudio.\n Interpretar información empírica aplicando diversas técnicas, en función de un plan de análisis.\n Diseñar estrategias para comunicar los saberes disciplinares considerando las características de distintos contextos y audiencias.\n Comunicar en forma oral y escrita los saberes disciplinares considerando distintos contextos y audiencias, haciendo un uso creativo de distintas estrategias.\n    Resultados de Aprendizaje Al finalizar el curso, los estudiantes:\n Serán capaces de explicar los conceptos y fundamentos teóricos y estadísticos de la investigación social basada en modelos predictivos para variables observadas y serán capaces de explicar su utilidad para la sociología.\n Serán capaces de preparar y depurar bases de datos para su análisis utilizando técnicas multivariadas, evaluando la pertinencia y la presencia de condiciones para la aplicación de modelos predictivos para variables observadas.\n Serán capaces de manejar software especializado y reportar los resultados de modelos predictivos para variables observadas cuantitativas y no cuantitativas.\n   Saberes / contenidos UNIDAD 1: Introducción al modelamiento de datos sociales  Tipos de investigación (descriptiva vs relacional y explicativa) y su materialización en el análisis estadístico. La explicación en ciencias sociales: su relación con el concepto de covariación; la explicación como dependencia robusta y como cadena causal y el trabajo con modelos. El trabajo con modelos: tipos de modelos (modelo teórico, modelo normativo, modelo científico, modelo estadístico); la vinculación entre los modelos científicos y los modelos teóricos; los modelos estadísticos como tipo de modelo científico. Ciencia abierta y modelamiento: transparencia, reproducibilidad y replicación.   UNIDAD 2: Regresión Lineal Simple y Múltiple  Bases: varianza, covarianza y correlación. Usos y aplicaciones en ciencias sociales de la regresión lineal. Supuestos y condiciones de aplicación de la regresión lineal. Manejo de casos influyentes Procedimientos de estimación e interpretación de parámetros. Introducción de variables de control estadístico. Criterios de validez, capacidad predictiva y evaluación del ajuste de la regresión lineal. Temas avanzados de regresión lineal: introducción de predictores categóricos, estimación de efectos de interacción y mediación, y uso de herramientas gráficas como apoyo a la interpretación y análisis de datos.   UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Limitaciones de la regresión lineal y potencialidades de la introducción de variables dependientes categóricas. Concepto y sentido de la función logística y funciones afines. Supuestos y condiciones de aplicación de la regresión para variables categóricas. Procedimientos de estimación e interpretación de parámetros de regresión logística. Criterios de validez, capacidad predictiva y evaluación del ajuste de la regresión Logística. Generalización de modelos de regresión logística: modelo de regresión logística multinomial y ordinal. Empleo de otras matrices de correlación (tetracórica, biserial y policórica).    Metodología En las circunstancias excepcionales de este semestre dada la crisis sanitaria, se han realizado una serie de ajustes metodológicos. En este contexto, tendremos tres espacios principales de aprendizaje:\nSesiones de clases lectivas, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana vía Zoom. Tanto el documento de presentación como el video de la clase se encontrará disponible en la pestaña de Contenidos de este sitio.\n Prácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana en grupos pequeños con supervisión de ayudantes para dar mayor oportunidad de participación y resolver las dudas respectivas. Existe un reporte de progreso asociado a estas guías que deberá ser completado semanalmente con fines de monitoreo y retroalimentación.\n Trabajos: se desarrollarán trabajos de investigación durante el semestre (ver sección evaluación abajo) que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados principalmente por ayudantes que se asignarán a cada grupo.\n   Evaluación (detalles en pestaña Trabajos) El curso tendrá tres instancias de evaluación:\n Trabajo 1 (individual): Correlación y regresión simple (20%). Trabajo 2 (grupal): Regresión multiple e inferencia estadística (30%) Trabajo 3 (grupal): Regresión logística, predictores categóricos y supuestos (50%)  La nota ponderada de los trabajos equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\n Requisitos de aprobación Nota mínima de aprobación: 4,0 (en escala de 1 a 7).\nRequisitos de eximición de examen:\ncontar con un promedio ponderado igual o superior a 5.5. no tener nota bajo 4 en ninguno de los trabajos  Requisitos para presentación a examen:\n Podrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\n El examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0.\n   Bibliografía La bibliografía obligatoria para cada semana se presenta en la planificación del curso, desde donde se puede acceder directamente a los documentos. De todas maneras, abajo algunos textos comentados y referencias para cada unidad.\nTextos principales. Hay cuatro referencias principales recomendadas para este curso:\n Moore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch. Explica de manera bastante clara (y en español) una serie de análisis estadísticos que sirven de base para este curso.\n Darlington, R. B., \u0026amp; Hayes, A. F. (2017). Regression analysis and linear models: concepts, applications, and implementation. Guilford Press. Este libro me parece un muy buen texto para acompañar un curso de regresión en ciencias sociales, lamentablemente está en inglés y por lo tanto solo es bibliografía sugerida.\n Wooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning. Libro clásico de regresión para economístas, la ventaja es que está en español, la desventaja (para nosotros) es que en ocasiones utiliza un lenguaje y ejemplos lejanos a la sociología.\n Wickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly. Libro con enfoque en el aprendizaje de R con técnicas que ciertamente van más allá del curso, pero muy util como referencia general. Además, está disponible también en español como “R para ciencia de datos”.\n  Abajo bilbiografía recomendada para cada unidad\n MODELOS CIENTÍFICOS (Unidad 1)  García-Ferrando, M. (1985). Análisis y modelización causal en sociología. Reis, 29(1), 143-164. Goldthorpe, J. H. (2001). Causation, statistics, and sociology. European Sociological Review, 17(1), 1-20. Ramón, L., \u0026amp; Ángeles, M. (2006). Estadística y causalidad en la sociología empírica del XX. Papers: revista de sociología, 80(1), 223-255. Salgado, M. (2009). Construyendo explicaciones: el uso de modelos en sociología. Persona y Sociedad, 30 (3), 29-60.   MODELOS DE REGRESIÓN LINEAL (Unidad 2)  Etxeberria, J. (1999). Regresión múltiple. Madrid: La Muralla. Fox, J. \u0026amp; Weisberg, S. (2011) An R Companion to Applied Regression (149-183). London: Sage. Pértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal múltiple. Cuadernos de atención primaria, 7(3), 173-176. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331162 Pértega-Díaz, S., \u0026amp; Pita-Fernández, S. (2000). Técnicas de regresión: Regresión lineal simple. Cuadernos de atención primaria, 7(2), 91-94. En: https://dialnet.unirioja.es/servlet/articulo?codigo=2331559 Grolemund, G. \u0026amp; Wickam, H. (2017) R for Data Science. Disponible en: https://r4ds.had.co.nz/   MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3)  Silva LC, Barroso J. (2004). Regresión Logística. Cuaderno 27. Madrid: La Muralla. Silva LC. (1995). Excursión a la regresión logística en ciencias de la salud. Madrid: Díaz de Santos; 1995. Jovell, A.J. (1995). Análisis de regresión logística, Cuadernos Metodológicos del CIS. Madrid.   Links \u0026amp; otras recomendaciones  Econometrics with R    Software Usaremos R 4.0 a través de la interfaz de RStudio. También realizaremos ejercicios y prácticas online en RCloud.\n Plataformas de comunicación y discusión  Foros Ucursos Disqus   VARIOS  Las clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Materiales, y están desarrollados con base en Rmarkdown/XaringanRmarkdown/ Xaringan. Estos documentos no son:\n “la clase” autoexplicativos (ni aspiran a serlo) “el ppt” (ni mucho menos “la ppt”)  Políticas de participación y trato: se espera y enfatiza la participación por distintos canales disponibles. También se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo estan siendo, se solicita reportar para solucionar la situación.\n   Programación de sesiones Visitar la página de Planificación.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616091116,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/programa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/programa/","section":"","summary":"Concepto del curso (nuevo) Propósito general del curso Competencias a las que contribuye el curso  Sub-Competencias  Resultados de Aprendizaje Saberes / contenidos  UNIDAD 1: Introducción al modelamiento de datos sociales UNIDAD 2: Regresión Lineal Simple y Múltiple UNIDAD 3: Regresión múltiple para variables dependientes categóricas  Metodología Evaluación (detalles en pestaña Trabajos) Requisitos de aprobación Bibliografía  Textos principales. MODELOS CIENTÍFICOS (Unidad 1) MODELOS DE REGRESIÓN LINEAL (Unidad 2) MODELOS DE REGRESIÓN PARA VARIABLES CATEGÓRICAS (Unidad 3) Links \u0026amp; otras recomendaciones  Software Plataformas de comunicación y discusión VARIOS Programación de sesiones   Concepto del curso (nuevo) A pesar de su nombre, este no es un curso de (mera) estadística.","tags":null,"title":"Programa","type":"page"},{"authors":null,"categories":null,"content":"  Required  Chapter 1 in Kieran Healy, Data Visualization [@Healy:2019] Chapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615479945,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"/reading/01-reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":"  Required  Chapter 1 in Kieran Healy, Data Visualization [@Healy:2019] Chapters 2 and 3 in Alberto Cairo, The Truthful Art [@Cairo:2016] (skim the introduction and chapter 1)   ","tags":null,"title":"Truth, Beauty, and Data","type":"reading"}]